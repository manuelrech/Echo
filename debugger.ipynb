{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.database.sql import SQLDatabase\n",
    "\n",
    "db = SQLDatabase('echo.db')\n",
    "\n",
    "emails_df, tweets_df, concepts_df = db.get_tables_in_dataframes()\n",
    "emails_df: pd.DataFrame\n",
    "tweets_df: pd.DataFrame\n",
    "concepts_df: pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepSeek-V3 Open-Source Model\n",
      "Links: https://github.com/deepseek-ai/DeepSeek-V3\n",
      "Concept Text: DeepSeek recently launched DeepSeek-V3, an open-source language model that boasts a remarkable 671 billion parameters. Unlike many closed-source models, DeepSeek-V3 activates only 37 billion parameters per token, significantly reducing computational requirements while maintaining strong performance across various tasks. Trained on a staggering 14.8 trillion tokens, this model is designed to optimize resource usage through its Mixture-of-Experts (MoE) architecture. It activates only a subset of parameters based on the input, enhancing efficiency without sacrificing accuracy. Additionally, the training process utilized 2.8 million GPU hours, which is notably lower than that of many comparable models. With features like Auxiliary-Loss-Free Load Balancing and FP8 mixed precision, DeepSeek-V3 stands out as one of the most efficient large-scale models available, making it a compelling choice for developers working in AI.\n",
      "Keywords: DeepSeek, open-source, language model, Mixture-of-Experts, MoE architecture\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Qwen's Visual Reasoning Model\n",
      "Links: https://qwenlm.github.io/blog/qvq-72b-preview/\n",
      "Concept Text: Qwen has introduced QVQ, a new visual reasoning model that significantly enhances deep thinking and provides step-by-step predictions. This model is designed to outperform existing competitors like GPT-4o and Claude Sonnet 3.5 in tasks requiring visual reasoning capabilities. By leveraging advanced techniques in visual processing, QVQ aims to offer more accurate and reliable outcomes when interpreting visual data. This innovation is a part of a growing trend in artificial intelligence where models are increasingly expected to reason not just in text but also in visual contexts. As visual reasoning becomes a critical skill for AI applications, Qwen's development represents a significant advancement in how machines can understand and interact with visual information.\n",
      "Keywords: Qwen, visual reasoning, deep thinking, step-by-step predictions\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Meta's Large Concept Models\n",
      "Links: https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/\n",
      "Concept Text: Meta's FAIR team has unveiled Large Concept Models (LCM), a groundbreaking approach to AI that processes concepts rather than relying solely on traditional tokenization methods. This innovative model is trained on 7.7 trillion tokens, allowing it to better understand and generate language based on the underlying concepts rather than just sequences of tokens. By separating reasoning from language, LCM aims to enhance the AI's ability to comprehend complex ideas and relationships, leading to more nuanced and contextually relevant outputs. This development is part of a broader movement in AI research that seeks to create models capable of deeper reasoning and understanding, potentially revolutionizing how AI systems interact with human language and concepts.\n",
      "Keywords: Meta, Large Concept Models, tokenization, reasoning, language processing\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Cognition's Devin Update\n",
      "Links: https://x.com/cognition_labs/status/1872290789050712165\n",
      "Concept Text: Cognition has released an update for its AI software engineer, Devin 1.1, which now includes full API support and boasts a 10% increase in performance for code-editing tasks. This update addresses previous limitations and enhances the usability of Devin as a coding assistant, allowing developers to streamline their workflows more efficiently. With custom workflows and improved speed, Devin aims to become an indispensable tool for software engineers looking to leverage AI in their development processes. This reflects a growing trend in the industry where AI tools are being integrated into daily coding practices, helping to reduce manual effort and improve productivity for developers.\n",
      "Keywords: Cognition, Devin, AI software engineer, coding assistant, API support\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Hugging Face GGUF Integration\n",
      "Links: https://huggingface.co/docs/hub/en/ollama\n",
      "Concept Text: Hugging Face has recently integrated with Ollama, facilitating the use of private GGUF models that can be run with a simple SSH setup. This integration simplifies the deployment of custom models, making it easier for developers to fine-tune and quantify their AI applications. By providing a streamlined process for utilizing GGUF models, Hugging Face continues to support the growing demand for accessible AI tools that empower developers to customize their machine learning workflows. The ability to run models privately enhances security and control over one's AI implementations, aligning with the industry's shift towards more user-centric AI solutions.\n",
      "Keywords: Hugging Face, Ollama, GGUF models, SSH setup\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Microsoft AIOpsLab\n",
      "Links: https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/\n",
      "Concept Text: Microsoft Research has launched AIOpsLab, an open-source framework designed to refine AI agents for enhanced reliability in cloud systems. This tool is aimed at developers and organizations looking to optimize their AI operations within cloud environments. By providing a structured approach to testing and improving AI agents, AIOpsLab seeks to address common challenges in cloud AI deployments, such as performance consistency and scalability. This initiative reflects Microsoft's commitment to advancing AI technologies that not only improve operational efficiency but also ensure that AI systems are robust and reliable in real-world applications, paving the way for a more dependable AI infrastructure in the cloud.\n",
      "Keywords: Microsoft Research, AIOpsLab, open-source, AI agents, cloud systems\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Amazon Nova\n",
      "Links: https://aws.amazon.com/ai/generative-ai/nova/\n",
      "Concept Text: Amazon has launched Nova, a comprehensive suite of multimodal AI models designed to compete directly with established models like GPT and Claude. This lineup includes various models tailored for different applications, ranging from text-only processing to video generation capabilities. Nova emphasizes reduced costs and latency while catering to enterprise workloads, making it an appealing option for businesses seeking advanced AI solutions. The models can handle diverse inputs such as text, images, and video, and are accessible through the Bedrock API, allowing for extensive data processing and high-quality generative content creation. Notably, Nova Pro is priced significantly lower than its competitors while offering impressive performance metrics across various benchmarks, positioning Amazon as a formidable player in the AI landscape.\n",
      "Keywords: Amazon, Nova, AI models, multimodal, GPT, Claude\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AI Agents by ElevenLabs\n",
      "Links: https://elevenlabs.io/conversational-ai\n",
      "Concept Text: ElevenLabs has introduced advanced AI agents capable of engaging in speech within minutes, showcasing low latency and full configurability. This development signifies a significant advancement in the practical application of AI agents, optimizing their scalability for various uses. These agents can be integrated into different platforms and services, allowing for seamless interactions in customer support, content creation, and other fields that benefit from quick and efficient communication. The ability to configure these agents fully means that businesses can tailor their functionalities to meet specific requirements, enhancing user experience and operational efficiency.\n",
      "Keywords: ElevenLabs, AI agents, speech, latency, configurability\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: SmallCon GenAI Virtual Conference\n",
      "Links: https://predibase.com/smallcon?utm_medium=3rdparty&utm_source=alphasignal_primaryad\n",
      "Concept Text: The SmallCon GenAI Virtual Conference is set to take place on December 11th, featuring leading figures from major AI companies such as Meta, Mistral, and HuggingFace. This free event aims to provide attendees with in-depth discussions about the latest trends and technologies in Generative AI. The agenda includes topics on the future of small models, enterprise transformations through GenAI, and insights on deploying AI agents effectively. By attending, participants can gain valuable knowledge on building the GenAI stack of the future and learn practical strategies to implement their AI models in production settings, making it a must-attend event for AI enthusiasts and professionals alike.\n",
      "Keywords: SmallCon, GenAI, conference, Meta, HuggingFace\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: QwQ-32B Model\n",
      "Links: https://huggingface.co/Qwen/QwQ-32B-Preview\n",
      "Concept Text: QwQ-32B-Preview is touted as the most intelligent open model available, excelling in complex analytical and reasoning tasks. This model has been designed to tackle challenging problems in mathematics and programming, demonstrating superior performance on various benchmarks such as GPQA and MATH-500. The capabilities of QwQ-32B make it an essential tool for developers and researchers looking to leverage advanced AI for problem-solving and data analysis. Its open-access nature allows for widespread use, fostering innovation and collaboration within the AI community as users explore its potential across numerous applications.\n",
      "Keywords: QwQ-32B, open model, AI, analytical tasks, reasoning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google's GenAI Intensive Course\n",
      "Links: https://www.kaggle.com/learn-guide/5-day-genai#GenAI\n",
      "Concept Text: Google has launched a comprehensive 5-day GenAI Intensive Course aimed at equipping participants with essential knowledge and skills in Generative AI. This self-paced course covers a wide range of topics, including foundational models, prompt engineering, and embedding techniques. Each day focuses on different aspects of AI development, culminating in practical applications and deployment strategies. The course includes assignments, whitepapers, and code labs, providing a hands-on learning experience for individuals eager to enhance their expertise in the rapidly evolving field of AI. This initiative reflects the growing demand for skilled professionals in generative technologies and aims to empower learners with the tools needed to excel.\n",
      "Keywords: Google, GenAI, course, Generative AI, training\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: DeepMind's Genie 2 Model\n",
      "Links: https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/\n",
      "Concept Text: DeepMind has unveiled Genie 2, a groundbreaking foundation world model that excels in generating an extensive range of playable 3D environments. This innovative model allows users to create diverse worlds from a single text or image prompt, seamlessly integrating user inputs such as keyboard and mouse controls. Notably, Genie 2 maintains the consistency of these generated environments for up to one minute, providing a stable platform for interaction and exploration. The model operates through an autoregressive latent diffusion framework, trained on a vast video dataset, which enables it to produce new frames dynamically through a transformer model. This capability makes it a powerful tool for training embodied agents in various AI applications, allowing researchers to simulate a variety of scenarios and tasks within the generated environments.\n",
      "Keywords: DeepMind, Genie 2, 3D environments, AI training, autoregressive model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: NVIDIA GH200 and Cost Efficiency\n",
      "Links: https://lambdalabs.com/blog/putting-the-nvidia-gh200-grace-hopper-superchip-to-good-use-superior-inference-performance-and-economics?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=2024-11-gh200-larger-model-inference&utm_content=ad-3\n",
      "Concept Text: The introduction of the NVIDIA GH200 Grace Hopper Superchip marks a significant advancement in AI model inference, particularly for large language models (LLMs). This cutting-edge hardware is designed to enhance throughput and reduce costs associated with running large models that typically struggle to fit within the memory constraints of a single GPU. With a reported 7.6 times higher throughput compared to the previous generation H100 SXM and an impressive 8 times lower cost per token, the GH200 eliminates the need for costly multi-GPU instances and mitigates performance issues caused by CPU offloading. This technology provides a unified memory architecture that allows for seamless model loading, enabling developers to focus on deploying their models without facing the usual bottlenecks. The GH200 is now available on-demand through Lambda’s Public Cloud, making it an accessible option for AI developers aiming to optimize their workflows and reduce operational costs.\n",
      "Keywords: NVIDIA GH200, cost efficiency, LLM inference, AI hardware, Lambda Cloud\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI's Livestream Launch\n",
      "Links: https://x.com/sama/status/1864335461268754712\n",
      "Concept Text: OpenAI has initiated an exciting series titled '12 Days of OpenAI,' where the company will host livestream events showcasing various product launches and demonstrations over a span of 12 weekdays. This initiative, announced by Sam Altman, aims to engage the AI community by providing real-time insights into the latest advancements and offerings from OpenAI. Each session is designed to highlight new features, capabilities, and applications of OpenAI’s technologies, fostering a deeper understanding of how these tools can be leveraged in various fields. By inviting developers and enthusiasts to participate in this interactive experience, OpenAI is reinforcing its commitment to transparency and collaboration within the AI landscape, encouraging feedback and discussions that can shape future developments.\n",
      "Keywords: OpenAI, livestream, product launch, Sam Altman, AI community\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Liquid AI's STAR Model Architecture\n",
      "Links: https://venturebeat.com/ai/liquid-ais-new-star-model-architecture-outshines-transformer-efficiency/#:~:text=In%20tests%20conducted%20during%20their,Transformer%2B%2B%20and%20hybrid%20models.\n",
      "Concept Text: Liquid AI has introduced its new STAR model architecture, which has been highlighted for its superior performance compared to traditional Transformer models. This innovative architecture aims to address some of the limitations observed in existing models, particularly in terms of efficiency and scalability. By leveraging advanced techniques and a reimagined structure, the STAR model is designed to deliver enhanced processing capabilities while maintaining flexibility for a variety of AI applications. This development signifies a pivotal shift in model design, promising improved results for tasks such as natural language processing, computer vision, and more. As AI developers continue to seek more effective solutions, Liquid AI's STAR model stands out as a promising alternative in the rapidly evolving landscape of machine learning architectures, paving the way for future innovations.\n",
      "Keywords: Liquid AI, STAR model, Transformer architecture, AI efficiency, machine learning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Generative AI and Video Models\n",
      "Links: https://cloud.google.com/blog/products/ai-machine-learning/introducing-veo-and-imagen-3-on-vertex-ai\n",
      "Concept Text: Google has broadened access to its generative video model, Veo, alongside the launch of Imagen 3 on Vertex AI. This move represents a significant step forward in the field of generative AI, enabling users to create high-quality video content from textual descriptions or other prompts. The advancements in these models not only enhance creative possibilities for developers but also open new avenues for applications in media, entertainment, and beyond. By providing tools that simplify the video creation process, Google is empowering creators to experiment with generative techniques, potentially revolutionizing the way content is produced and consumed. With the increasing demand for dynamic and engaging media, the integration of such generative models into workflows is likely to become a norm, further solidifying the role of AI in content production.\n",
      "Keywords: Google, Veo, generative video, Imagen 3, AI content creation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AWS Bedrock Updates\n",
      "Links: \n",
      "Concept Text: AWS has recently unveiled significant updates to its Bedrock platform during the re:Invent 2024 conference. These enhancements are primarily designed to improve efficiency and reduce latency in AI model deployment. Key features include Intelligent Prompt Routing, which can lower inference latency by up to 85%, and Prompt Caching, which helps to cut costs dramatically by storing common queries. Additionally, the platform supports advanced Retrieval-Augmented Generation (RAG) workflows, allowing users to handle both structured and unstructured data seamlessly without the need for extensive custom coding. These updates position AWS Bedrock as a robust solution for enterprises looking to enhance their AI capabilities while managing costs effectively.\n",
      "Keywords: AWS, Bedrock, Latency, AI, Updates\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AWS SageMaker Enhancements\n",
      "Links: \n",
      "Concept Text: AWS SageMaker has introduced a series of enhancements aimed at unifying data and AI capabilities into a single platform. This update allows users to connect various data sources—both structured and unstructured—streamlining the development of AI applications. It boasts over 140 features that facilitate seamless workflows and accelerate model deployment. A notable addition is the HyperPod task governance system, which prioritizes workloads for training, inference, and fine-tuning, significantly boosting GPU utilization by reducing idle time. These improvements are expected to streamline the AI development process, making it more efficient and cost-effective for enterprises looking to scale their operations.\n",
      "Keywords: AWS, SageMaker, AI, Data Hub, Enhancements\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI Usage API\n",
      "Links: \n",
      "Concept Text: OpenAI has launched a new Usage API that allows users to track their API usage and costs in real-time. This tool provides detailed insights and filtering options, enabling better management of resources for developers and enterprises utilizing OpenAI's services. By offering a transparent view of API consumption, the Usage API helps users make informed decisions about their usage patterns and budgeting. This is particularly valuable for businesses that rely on OpenAI's capabilities for various applications, as it ensures they can optimize their expenses and enhance their operational efficiency.\n",
      "Keywords: OpenAI, API, Usage Tracking, Cost Management, Insights\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AI-Powered Weather Forecasting\n",
      "Links: \n",
      "Concept Text: DeepMind has introduced GenCast, an AI-driven weather forecasting model that promises significant advancements in predictive analysis. This system is capable of delivering 15-day weather forecasts in a matter of minutes, outperforming traditional forecasting methods on 97% of metrics. By leveraging advanced machine learning techniques, GenCast aims to provide more accurate and timely weather information, which can be crucial for various sectors, including agriculture, disaster management, and everyday decision-making. The launch of GenCast reflects the growing trend of utilizing AI to enhance predictive analytics across different domains.\n",
      "Keywords: DeepMind, GenCast, Weather Forecasting, AI, Predictive Analysis\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: RAG Enhancements in AI Workflows\n",
      "Links: \n",
      "Concept Text: Retrieval-Augmented Generation (RAG) is becoming increasingly important in the development of large language models and AI applications. The recent advancements in RAG tools, particularly with AWS Bedrock, allow for the integration of knowledge bases and automated SQL query generation. This streamlines complex data tasks and enhances the accuracy of AI models by enabling them to access and utilize vast amounts of information effectively. The ability to work with both structured and unstructured data without extensive coding requirements is a significant leap forward for developers, as it simplifies the integration of advanced AI capabilities into their applications.\n",
      "Keywords: RAG, AI Workflows, Data Integration, Knowledge Bases, AWS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI o3 Launch\n",
      "Links: https://link.alphasignal.ai/Jyqtx6\n",
      "Concept Text: OpenAI has recently unveiled its latest reasoning model, dubbed o3, marking a significant advancement in artificial intelligence. This model has achieved a remarkable score of 87.5% on the ARC-AGI benchmark, which is designed to assess reasoning and generalization capabilities. The o3 model is built on a hybrid neural-symbolic framework, enabling it to move beyond traditional pattern matching. This allows o3 to generate solutions dynamically, thereby showcasing its ability to tackle complex and unseen problems effectively. The introduction of o3 represents a major step forward in AI development, highlighting OpenAI's commitment to pushing the boundaries of what AI can achieve in reasoning tasks.\n",
      "Keywords: OpenAI, o3, reasoning model, ARC-AGI\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: ByteDance's Monolith Framework\n",
      "Links: https://github.com/bytedance/monolith\n",
      "Concept Text: ByteDance has launched Monolith, an innovative open-source framework aimed at enhancing the scalability of recommender systems. This framework is designed to assist developers in building robust systems that can efficiently handle vast amounts of data and user interactions. By providing a scalable architecture, Monolith enables organizations to optimize their recommendation algorithms, ensuring that users receive personalized content that meets their needs. The release of Monolith underscores ByteDance's commitment to advancing AI technologies and making them accessible to developers, facilitating the creation of intelligent systems that can adapt and evolve with user preferences.\n",
      "Keywords: ByteDance, Monolith, recommender systems, open-source\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Genesis Physics Engine\n",
      "Links: https://genesis-embodied-ai.github.io/\n",
      "Concept Text: A team of researchers has introduced Genesis, an open-source physics engine that allows for the rapid creation of 4D environments specifically tailored for robotics and AI applications. This groundbreaking technology is capable of generating environments at an astonishing speed, operating 430,000 times faster than real-time. Genesis provides developers with the tools needed to simulate complex physical interactions in a highly efficient manner, thereby facilitating advancements in robotic training and AI-driven simulations. The availability of Genesis as an open-source project represents a significant contribution to the field, empowering other researchers and developers to leverage this technology in their own projects.\n",
      "Keywords: Genesis, physics engine, 4D environments, robotics, AI\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google's Gemini 2.0 Flash Thinking Model\n",
      "Links: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Faistudio.google.com%2Fprompts%2Fnew_chat%3Fmodel%3Dgemini-2.0-flash-thinking-exp-1219&followup=https%3A%2F%2Faistudio.google.com%2Fprompts%2Fnew_chat%3Fmodel%3Dgemini-2.0-flash-thinking-exp-1219&ifkv=AeZLP99LSRyaKSjsx6Q6RlQT1l0o_AtWvs5GlrQ9Yiz6LOLAZwYW-XARETVOX14c8ErSWM2P8YNC&passive=1209600&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1647826217%3A1735399482185467\n",
      "Concept Text: Google has unveiled Gemini 2.0 Flash Thinking, a new reasoning model that demonstrates advanced problem-solving capabilities. This model excels in providing insights into its thought process while solving problems, making it a unique tool for developers and researchers alike. Gemini 2.0 is designed to be user-friendly and accessible, allowing for real-time interactions and dynamic responses. By prioritizing transparency in its reasoning processes, Gemini 2.0 sets a new standard for AI models, paving the way for further innovations in the field of artificial intelligence. This model's capabilities have positioned it as a leading tool for those looking to enhance their AI applications.\n",
      "Keywords: Google, Gemini 2.0, reasoning model, AI\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Qwen 2.5 Technical Report\n",
      "Links: https://arxiv.org/abs/2412.15115\n",
      "Concept Text: The Qwen team has published a technical report detailing the Qwen 2.5 model, which includes a series of open-weight large language models (LLMs). This report outlines the capabilities of Qwen 2.5, emphasizing its general-purpose functionality as well as its applications in coding and vision-language modeling (VLM). The release of this report is significant for developers and researchers interested in leveraging open-weight models for their projects, as it provides critical insights into the model's architecture and performance. The transparency offered by the Qwen team aims to foster collaboration and innovation within the AI community.\n",
      "Keywords: Qwen, Qwen 2.5, technical report, LLMs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI o1 API\n",
      "Links: https://link.alphasignal.ai/vKAZzV\n",
      "Concept Text: OpenAI has launched the o1 API, a reasoning model designed for complex, multi-step problem-solving tasks. This model is particularly noteworthy for its advanced capabilities, including function calling that connects to external data and APIs, structured outputs that comply with custom JSON schemas, and vision capabilities that allow it to process visual inputs. The o1 API is optimized for efficiency, achieving a 60% reduction in reasoning token usage, which translates to significant cost savings and improved latency. Developers can utilize the model for a variety of applications, including science, manufacturing, and coding, making it a versatile tool in the AI ecosystem.\n",
      "Keywords: OpenAI, API, reasoning model, complex problem-solving, cost-efficiency\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Lambda Inference API\n",
      "Links: https://lambdalabs.com/inference?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=2024-12-inference&utm_content=ad-1-main\n",
      "Concept Text: Lambda has introduced its Inference API, which promises low-cost and scalable AI processing capabilities. This API is designed to run AI inference without limits, providing access to top-tier models while maintaining cost transparency. Users can expect costs as low as $0.02 per million tokens, and the service is built specifically for high-performance AI workloads. The infrastructure is optimized to support seamless scaling, making it an ideal choice for developers looking to prototype, test, and deploy AI applications without facing rate limits. This service significantly simplifies the process of scaling AI projects, allowing developers to focus on innovation rather than infrastructure concerns.\n",
      "Keywords: Lambda, Inference API, scalability, cost-efficiency, AI processing\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: GitHub Copilot Free Tier\n",
      "Links: https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot\n",
      "Concept Text: GitHub has announced a free tier for its Copilot service, which provides developers with access to advanced coding assistance tools powered by AI. This initiative includes access to models like GPT-4o and Claude 3.5, allowing users to receive up to 2,000 code completions per month at no cost. The introduction of this free tier is a significant step toward democratizing access to AI coding tools, enabling a broader range of developers to leverage AI for enhancing their coding efficiency and productivity. This move reflects a growing trend of making advanced AI tools more accessible to developers, fostering innovation and collaboration in the coding community.\n",
      "Keywords: GitHub, Copilot, free tier, coding assistance, AI tools\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google DeepMind FACTS Benchmark\n",
      "Links: https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/\n",
      "Concept Text: Google DeepMind has released the FACTS Grounding benchmark, an important tool for assessing the factual accuracy and grounding of large language models (LLMs) in real-world contexts. This benchmark aims to evaluate how effectively LLMs can understand and process factual information, thereby addressing some of the challenges associated with AI-generated content. The introduction of this benchmark is a critical step in the ongoing efforts to improve the reliability and accountability of AI systems, ensuring that models provide accurate information. With the FACTS benchmark, researchers and developers can better assess and enhance the performance of their models in real-world applications, ultimately contributing to the advancement of trustworthy AI.\n",
      "Keywords: Google DeepMind, FACTS benchmark, LLMs, factual accuracy, AI reliability\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: NVIDIA Jetson Orin Nano\n",
      "Links: https://developer.nvidia.com/blog/nvidia-jetson-orin-nano-developer-kit-gets-a-super-boost/\n",
      "Concept Text: NVIDIA has upgraded its Jetson Orin Nano platform, a significant enhancement for edge AI applications, particularly those involving generative AI. The upgraded version boasts a 70% performance boost, providing developers with more powerful capabilities for deploying AI solutions at the edge. This development is crucial as it allows for more efficient processing of AI tasks in environments where resources may be limited, such as in robotics or IoT devices. The Jetson Orin Nano's improvements are tailored to meet the growing demand for efficient, powerful computing solutions in the AI landscape, making it a valuable tool for developers looking to harness the power of AI in real-time applications.\n",
      "Keywords: NVIDIA, Jetson Orin Nano, edge AI, generative AI, performance boost\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Dynamiq Low-Code Platform\n",
      "Links: https://www.getdynamiq.ai/?utm_source=AlphaSignal&utm_medium=mainAd&utm_campaign=agents\n",
      "Concept Text: Dynamiq's low-code platform allows users to prototype, test, and maintain Generative AI applications seamlessly within their own infrastructure. This platform is designed to empower developers by enabling rapid deployment of applications in under an hour using an intuitive interface. With features that support single or multi-agent systems, Dynamiq ensures that organizations can automate tasks efficiently while also providing enterprise-grade security for data management across various environments, whether on-premise or in the cloud.\n",
      "Keywords: Dynamiq, low-code platform, Generative AI, application development, automation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AI Integration in Apple Ecosystem\n",
      "Links: https://link.alphasignal.ai/KRQ3Ao\n",
      "Concept Text: OpenAI has successfully integrated ChatGPT into Apple's ecosystem, enhancing various OS-native applications with advanced writing and vision capabilities. This integration signifies a major step towards embedding AI tools into everyday applications, providing users with enhanced functionalities that leverage natural language processing and image recognition. By bringing sophisticated AI features directly into Apple's products, OpenAI aims to improve user experience and productivity, showcasing the potential of AI to transform how users interact with technology.\n",
      "Keywords: OpenAI, ChatGPT, Apple, AI integration, OS-native apps\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Midjourney Patchwork\n",
      "Links: https://updates.midjourney.com/patchwork-user-guide/\n",
      "Concept Text: Midjourney has unveiled Patchwork, a multiplayer worldbuilding tool that allows users to collaboratively create stories in a shared canvas environment. This innovative tool is designed for storytellers and creators, enabling them to brainstorm, visualize, and construct narratives together in real-time. With its interactive interface, Patchwork fosters creativity and collaboration, making it an exciting addition to the toolkit of writers and game designers looking to craft immersive worlds and narratives collaboratively.\n",
      "Keywords: Midjourney, Patchwork, multiplayer, worldbuilding, story creation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI Canvas\n",
      "Links: https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/\n",
      "Concept Text: OpenAI Canvas is an innovative tool designed to streamline the writing and coding process, allowing users to edit text and code side-by-side with the assistance of AI. This hands-on course, led by experts from DeepLearning.ai, teaches users how to leverage the Canvas interface for efficient brainstorming, drafting, and iterating. The platform supports various functionalities, from adjusting tone and enhancing code to generating Python code from images, thus providing a comprehensive workspace for creative and technical tasks alike.\n",
      "Keywords: OpenAI, Canvas, writing, coding, AI tools\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Encord's Multimodal Data Pipelines\n",
      "Links: https://lu.ma/jwj3apvn?utm_medium=affiliate&utm_source=newsletter&utm_campaign=alpha-signal\n",
      "Concept Text: Encord is hosting a webinar on December 16th to discuss the use of agents in building scalable multimodal data pipelines, focusing on automation in data preparation. As generative AI increasingly shifts towards multimodal frameworks, the need for high-quality datasets becomes paramount. Encord's Data Agents are positioned as essential tools that assist machine learning practitioners in automating the curation and annotation processes required for multimodal AI systems. Participants will learn about best practices for utilizing foundational models like PaliGemma 2 and GPT-4o, thereby streamlining workflows and enhancing the quality of data preparation efforts.\n",
      "Keywords: Encord, multimodal data, automation, webinar, data agents\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: DeepSeek's LLM Upgrade\n",
      "Links: https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210\n",
      "Concept Text: DeepSeek has announced an upgrade to its open-source large language model, DeepSeek-V2.5, which now incorporates real-time internet search capabilities. This enhancement has resulted in an impressive 8% improvement in performance across various tasks, including mathematics, coding, and writing. By leveraging real-time data, DeepSeek aims to provide users with more accurate and contextually relevant responses, enhancing the overall utility of the model. This upgrade is indicative of the ongoing trend in AI towards integrating real-time information to bolster the effectiveness of language models in practical applications.\n",
      "Keywords: DeepSeek, LLM upgrade, real-time search, performance improvement, open-source\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Nous Research Simulators\n",
      "Links: https://sims.nousresearch.com/\n",
      "Concept Text: Nous Research has launched a series of simulators designed to explore human behaviors and interactions with artificial intelligence within digital environments. These simulators aim to understand the dynamics of human-AI interaction, providing valuable insights that could inform the development of more intuitive and effective AI systems. By analyzing how users engage with AI, Nous Research seeks to identify best practices for designing AI tools that enhance user experience and foster more productive collaborations between humans and machines. This initiative highlights the growing importance of human-centric approaches in AI development.\n",
      "Keywords: Nous Research, simulators, human-AI interaction, digital environments, user experience\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google's Gemini Flash API\n",
      "Links: https://ai.google.dev/pricing#1_5flash\n",
      "Concept Text: Google has rolled out the Gemini Flash API, a lightweight and rapid multimodal model that offers lower rate limits for testing purposes. This new API is designed to facilitate developers' access to advanced AI capabilities while enabling them to experiment with various use cases without incurring high costs. With up to 1 million tokens of free caching, Gemini Flash aims to accelerate the integration of multimodal functionalities across applications. This move reflects Google’s commitment to making AI technologies more accessible to developers and encouraging innovation in the use of AI across different sectors.\n",
      "Keywords: Google, Gemini Flash API, multimodal model, testing, free caching\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Hugging Face's TGI 3.0\n",
      "Links: https://huggingface.co/docs/text-generation-inference/conceptual/chunking\n",
      "Concept Text: Hugging Face has introduced TGI 3.0, a new inference engine that significantly enhances the handling of long prompts and increases token capacity. This upgrade provides a 13 times faster processing speed for long prompts and a three times higher token capacity, making it easier for developers to work with larger datasets and more complex queries. TGI 3.0 represents a substantial advancement in AI performance optimization, streamlining workflows for developers and researchers who rely on efficient processing of large volumes of text data. This improvement is particularly beneficial for applications that involve extensive language model interactions, such as chatbots and automated content generation.\n",
      "Keywords: Hugging Face, TGI 3.0, inference engine, performance optimization, token capacity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI's Sora Turbo\n",
      "Links: https://link.alphasignal.ai/6BTLWu\n",
      "Concept Text: OpenAI has recently launched Sora Turbo, an advanced video generation model that allows users to create realistic videos from text prompts. This model is particularly designed for ChatGPT Plus and Pro users, providing enhanced speed and visual quality. Sora Turbo can generate videos up to 20 seconds long and supports various aspect ratios, making it versatile for different content types. Users can utilize the storyboard tool to input images or videos, allowing for detailed scene construction and the ability to remix content. The improved generation times and user-friendly interface are significant upgrades over the initial Sora model, making it a powerful tool for creators and developers alike.\n",
      "Keywords: OpenAI, Sora Turbo, video generation, ChatGPT, AI tool\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Hume's Voice Control Tool\n",
      "Links: https://platform.hume.ai/?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=voice-control\n",
      "Concept Text: Hume has introduced a groundbreaking tool called Voice Control, enabling users to create unique AI voices instantly without the need for coding. This tool allows for real-time adjustments across ten key dimensions of voice modulation, including gender tone, density, confidence, and relaxation levels. By employing intuitive sliders, users can craft the perfect voice tailored to their specific applications, ranging from customer service bots to virtual assistants. The focus on unique voice customization rather than cloning addresses ethical concerns while providing flexibility for various use cases. Hume's Voice Control tool represents a significant advancement in voice technology for AI applications.\n",
      "Keywords: Hume, Voice Control, AI voices, voice modulation, customization\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google's Willow Quantum Chip\n",
      "Links: https://blog.google/technology/research/google-willow-quantum-chip/\n",
      "Concept Text: Google has unveiled its latest quantum computing advancement, the Willow quantum chip, which dramatically outperforms traditional supercomputers. Capable of solving complex computations in under five minutes, Willow represents a leap forward in quantum technology, promising to address computational challenges that would take classical systems an exorbitant amount of time to solve. This breakthrough places Google at the forefront of quantum research, with implications for various fields, including cryptography, optimization, and machine learning. The introduction of Willow marks a significant milestone in the race to harness quantum computing for practical applications, highlighting the transformative potential of this technology.\n",
      "Keywords: Google, Willow, quantum chip, computing, supercomputers\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: xAI's Aurora Image Generator\n",
      "Links: https://x.ai/blog/grok-image-generation-release\n",
      "Concept Text: xAI has launched Aurora, a sophisticated image generation model integrated with Grok, designed to produce high-quality images with fewer content restrictions compared to its predecessors. This multimodal input model allows users to generate images based on various inputs, thus enhancing flexibility and creativity in content creation. Aurora's capabilities position it as a competitive alternative in the image generation space, particularly against established models like Flux. By offering a more open and versatile platform, Aurora stands to benefit developers and artists looking to push the boundaries of digital content creation.\n",
      "Keywords: xAI, Aurora, image generation, Grok, AI model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: AskUI Vision Agent Framework\n",
      "Links: https://github.com/askui/vision-agent\n",
      "Concept Text: AskUI has developed the Vision Agent framework, a powerful tool designed to empower developers to create intelligent computer agents across multiple operating systems using Python and large language models (LLMs). This framework allows for seamless integration of automation features, enabling users to automate tasks on platforms such as Windows, Linux, MacOS, and Android. With support for multi-monitor setups and optical character recognition (OCR), Vision Agent provides a comprehensive solution for building versatile agents capable of handling complex workflows. This development aligns with the growing demand for automation in various sectors, making it a vital resource for developers aiming to optimize productivity.\n",
      "Keywords: AskUI, Vision Agent, computer agents, automation, Python\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: OpenAI o1 Model Release\n",
      "Links: https://link.alphasignal.ai/FOerJZ\n",
      "Concept Text: OpenAI has officially launched its newest AI model, named 'o1', marking a significant advancement in its capabilities. This model is designed to replace the previous preview version used in ChatGPT, introducing enhanced features such as advanced reasoning abilities, quicker response times, and the capacity to process images. The launch coincided with the kickoff of OpenAI's '12 Days of OpenAI' event, where the company is expected to unveil more updates and announcements. The o1 model is particularly aimed at users with demanding computational needs, thus being integrated into the new $200/month ChatGPT Pro subscription, which is tailored for complex application scenarios.\n",
      "Keywords: OpenAI, o1 model, ChatGPT Pro, AI capabilities, image processing\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: ChatGPT Pro Subscription Features\n",
      "Links: \n",
      "Concept Text: The launch of the o1 model is accompanied by the introduction of a new subscription tier for ChatGPT, known as 'ChatGPT Pro'. This subscription is priced at $200 per month and is tailored for users who require high levels of computational power and advanced features for complex tasks. Users of ChatGPT Pro will have unlimited access to several tools, including the o1 model and its advanced capabilities. One notable feature of the Pro version is the 'o1 Pro mode', which offers a significantly larger context window of 128k tokens, enhancing the model's reliability and performance on technical tasks. This subscription tier emphasizes efficiency and reliability, particularly beneficial for users engaged in high-stakes projects or requiring extended processing times for their queries.\n",
      "Keywords: ChatGPT Pro, subscription, AI tools, context window, reliability\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Microsoft's Copilot Vision\n",
      "Links: https://www.microsoft.com/en-us/microsoft-copilot/blog/2024/12/05/copilot-vision-now-in-preview-a-new-way-to-browse/\n",
      "Concept Text: Microsoft has unveiled Copilot Vision, a new feature designed to provide Pro users with real-time insights while navigating the Edge browser. This innovative tool is aimed at enhancing productivity by delivering contextual information directly on the browser page, allowing users to interact with web content more effectively. By integrating AI-driven assistance into everyday browsing tasks, Microsoft aims to empower users with insights that can streamline decision-making processes and enhance their overall web experience. This development underscores the growing trend of integrating sophisticated AI tools within standard software applications to improve user engagement and efficiency.\n",
      "Keywords: Microsoft, Copilot Vision, Edge browser, AI assistance, productivity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Google's PaliGemma 2 Model\n",
      "Links: https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/\n",
      "Concept Text: Google has introduced PaliGemma 2, an open-source vision-language model that enhances capabilities in understanding and generating visual content. This model is designed for flexibility and scalability in various tasks, including image captioning and visual question answering. The development of PaliGemma 2 reflects Google's commitment to advancing multimodal AI technologies, which combine text and visual data to improve interaction with complex information. As more organizations explore the potential of vision-language models, Google's release of PaliGemma 2 positions it as a significant player in the evolving AI landscape, offering tools that can be leveraged across a multitude of applications.\n",
      "Keywords: Google, PaliGemma 2, vision-language model, open-source, multimodal AI\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Trends in Speech Technologies\n",
      "Links: https://www.assemblyai.com/reports/2024-insights-report?utm_source=alphasignal&utm_medium=newsletter_sponsor&utm_campaign=main&utm_content=120624\n",
      "Concept Text: The 2024 AI Insights Report by Assembly AI highlights key trends in speech technology, emphasizing the increasing adoption of advanced speech recognition models and the integration of multimodal AI solutions. The report serves as a vital resource for industry professionals seeking actionable insights and data-driven strategies to enhance their products. Key findings include the importance of APIs in improving workflow efficiency and the shift towards building versus buying solutions in AI-driven product development. As companies increasingly rely on AI for competitive advantage, understanding these trends will be essential for navigating the evolving landscape of speech technologies and ensuring successful implementation of AI solutions in various applications.\n",
      "Keywords: Assembly AI, speech technology, AI Insights Report, multimodal AI, workflow efficiency\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, row in concepts_df.iterrows():\n",
    "    print('Title:', row['title'])\n",
    "    print('Links:', row['links'])\n",
    "    print('Concept Text:', row['concept_text'])\n",
    "    print('Keywords:', row['keywords'])\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" id=\"facebook\" class=\"no_js\">\n",
      "<head><meta charset=\"utf-8\" /><meta name=\"referrer\" content=\"default\" id=\"meta_referrer\" /><script nonce=\"DyPoUrmQ\">function envFlush(a){function b(b){for(var c in a)b[c]=a[c]}window.requireLazy?window.requireLazy([\"Env\"],b):(window.Env=window.Env||{},b(window.Env))}envFlush({\"useTrustedTypes\":true,\"isTrustedTypesReportOnly\":false,\"ajaxpipe_token\":\"AXjunfYKW3urRvRvOMg\",\"stack_trace_limit\":30,\"timesliceBufferSize\":5000,\"show_invariant_decoder\":false,\"compat_iframe_token\":\"AUWA6JREwR2oeFrgc-N3fJQxOl8\",\"isCQuick\":false,\"brsid\":\"7453497756665521207\"});</script><script nonce=\"DyPoUrmQ\">(function(a){function b(a){var b;a=Object.getOwnPropertyDescriptor(Document.prototype,a);if(a===void 0||a.configurable!==!0)return null;b=(b=a.set)==null?void 0:b.bind(document);a=(a=a.get)==null?void 0:a.bind(document);return b===void 0||a===void 0?null:{get:a,set:b}}function c(c){var d=b(\"cookie\");if(d==null)return;var e=!1;c.I_AM_CORE_COOKIE_INFRASTRUCTURE_AND_NEED_TO_ACCESS_COOKIES=function(){if(e)throw new Error(\"CookieStore already initialized\");e=!0;return d};Object.defineProperty(document,\"cookie\",{get:function(){throw new Error()},set:function(a){throw new Error()}})}function d(){var a=b(\"domain\");if(a==null)return;Object.defineProperty(document,\"domain\",{get:function(){var b=a.get();return b==null?null:b},set:function(a){throw new Error()}})}c(a);d()})(this);</script><script nonce=\"DyPoUrmQ\">window.openDatabase&&(window.openDatabase=function(){throw new Error()});</script><script nonce=\"DyPoUrmQ\">_btldr={};</script><script nonce=\"DyPoUrmQ\">function parentIsNotHeadNorBody(a){return a.parentElement!==document.body&&a.parentElement!==document.head}function isTagSupported(a){return a.nodeName===\"SCRIPT\"||a.nodeName===\"LINK\"&&((a=getNodeDataSet(a))==null?void 0:a.asyncCss)}function getNodeDataSet(a){return!(a.dataset instanceof window.DOMStringMap)?null:a.dataset}function addLoadEventListeners(a){var b;try{if(a.nodeType!==Node.ELEMENT_NODE)return}catch(a){return}if(parentIsNotHeadNorBody(a)||!isTagSupported(a))return;var c=(b=getNodeDataSet(a))==null?void 0:b.bootloaderHash;if(c!=null&&c!==\"\"){var d=null,e=function(){window._btldr[c]=1,d==null?void 0:d()};d=function(){a.removeEventListener(\"load\",e),a.removeEventListener(\"error\",e)};a.addEventListener(\"load\",e);a.addEventListener(\"error\",e)}}(function(){Array.from(document.querySelectorAll('script,link[data-async-css=\"1\"]')).forEach(function(a){return addLoadEventListeners(a)});var a=new MutationObserver(function(a,b){a.forEach(function(a){a.type===\"childList\"&&Array.from(a.addedNodes).forEach(function(a){addLoadEventListeners(a)})})});a.observe(document.getElementsByTagName(\"html\")[0],{attributes:!1,childList:!0,subtree:!0})})();</script><style nonce=\"DyPoUrmQ\"></style><script nonce=\"DyPoUrmQ\">__DEV__=0;</script><noscript><meta http-equiv=\"refresh\" content=\"0; URL=/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/?_fb_noscript=1\" /></noscript><title id=\"pageTitle\">Large Concept Models: Language Modeling in a Sentence Representation Space | Research - AI at Meta</title><meta name=\"bingbot\" content=\"noarchive\" /><meta name=\"description\" content=\"LLMs have revolutionized the field of artificial intelligence and have emerged as the de-facto tool for\n",
      "many tasks. The current established technology of...\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /><link rel=\"icon\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/y4/r/WUJbsVI4ruF.png\" /><link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yl/l/0,cross/U1Z-El2734z.css\" data-bootloader-hash=\"2YfEtdD\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yE/l/0,cross/0F7k9wwkBCo.css\" data-bootloader-hash=\"D4/LUJw\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yw/l/0,cross/rN4w09XutPb.css\" data-bootloader-hash=\"K1WZ7sC\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yE/l/0,cross/_h5q_3IdUeP.css\" data-bootloader-hash=\"mwiib7b\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/y-/l/0,cross/5gaZkgRfXTy.css\" data-bootloader-hash=\"cHTkugV\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yd/l/0,cross/bouCSXpqbMW.css\" data-bootloader-hash=\"ON7WAdt\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yy/l/0,cross/mUJK3Q14f_f.css\" data-bootloader-hash=\"gHx22nF\" crossorigin=\"anonymous\" />\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yR/l/0,cross/0JO_Y-PHlrV.css\" data-bootloader-hash=\"k333Q1J\" crossorigin=\"anonymous\" />\n",
      "<script src=\"https://static.xx.fbcdn.net/rsrc.php/v4/yz/r/4lZ7R6fRfCz.js\" data-bootloader-hash=\"lp6Cw4s\" crossorigin=\"anonymous\"></script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"HasteSupportData\"],function(m){m.handle({\"clpData\":{\"6476\":{\"r\":1000,\"s\":1},\"1838142\":{\"r\":1,\"s\":1},\"1848815\":{\"r\":10000,\"s\":1}},\"gkxData\":{\"20935\":{\"result\":false,\"hash\":null},\"20940\":{\"result\":false,\"hash\":null},\"21043\":{\"result\":false,\"hash\":null},\"5415\":{\"result\":false,\"hash\":null},\"7742\":{\"result\":false,\"hash\":null},\"8068\":{\"result\":false,\"hash\":null},\"20936\":{\"result\":false,\"hash\":null},\"20948\":{\"result\":true,\"hash\":null},\"25572\":{\"result\":false,\"hash\":null},\"1221\":{\"result\":false,\"hash\":null},\"25571\":{\"result\":false,\"hash\":null}},\"justknobxData\":{\"2552\":{\"r\":false},\"3323\":{\"r\":true},\"2269\":{\"r\":true}}})});requireLazy([\"TimeSliceImpl\",\"ServerJS\"],function(TimeSlice,ServerJS){(new ServerJS()).handle({\"define\":[[\"cr:310\",[\"RunWWW\"],{\"__rc\":[\"RunWWW\",null]},-1],[\"cr:1078\",[],{\"__rc\":[null,null]},-1],[\"cr:1080\",[\"unexpectedUseInComet\"],{\"__rc\":[\"unexpectedUseInComet\",null]},-1],[\"cr:1126\",[\"TimeSliceImpl\"],{\"__rc\":[\"TimeSliceImpl\",null]},-1],[\"cr:3725\",[\"clearTimeoutWWWOrMobile\"],{\"__rc\":[\"clearTimeoutWWWOrMobile\",null]},-1],[\"cr:4344\",[\"setTimeoutWWWOrMobile\"],{\"__rc\":[\"setTimeoutWWWOrMobile\",null]},-1],[\"cr:6108\",[\"CSS\"],{\"__rc\":[\"CSS\",null]},-1],[\"cr:6640\",[\"PromiseImpl\"],{\"__rc\":[\"PromiseImpl\",null]},-1],[\"cr:7385\",[\"clearIntervalWWW\"],{\"__rc\":[\"clearIntervalWWW\",null]},-1],[\"cr:7389\",[\"setIntervalAcrossTransitionsWWW\"],{\"__rc\":[\"setIntervalAcrossTransitionsWWW\",null]},-1],[\"cr:7391\",[\"setTimeoutAcrossTransitionsWWW\"],{\"__rc\":[\"setTimeoutAcrossTransitionsWWW\",null]},-1],[\"cr:8958\",[\"FBJSON\"],{\"__rc\":[\"FBJSON\",null]},-1],[\"cr:8959\",[\"DTSG\"],{\"__rc\":[\"DTSG\",null]},-1],[\"cr:8960\",[\"DTSG_ASYNC\"],{\"__rc\":[\"DTSG_ASYNC\",null]},-1],[\"cr:696703\",[],{\"__rc\":[null,null]},-1],[\"cr:708886\",[\"EventProfilerImpl\"],{\"__rc\":[\"EventProfilerImpl\",null]},-1],[\"cr:135\",[\"RunBlue\"],{\"__rc\":[\"RunBlue\",null]},-1],[\"cr:6669\",[\"DataStore\"],{\"__rc\":[\"DataStore\",null]},-1],[\"URLFragmentPreludeConfig\",[],{\"hashtagRedirect\":false,\"fragBlacklist\":[\"nonce\",\"access_token\",\"oauth_token\",\"xs\",\"checkpoint_data\",\"code\"]},137],[\"CookiePrivacySandboxConfig\",[],{\"is_affected_by_samesite_lax\":false},7723],[\"CometPersistQueryParams\",[],{\"relative\":{},\"domain\":{}},6231],[\"CookieDomain\",[],{\"domain\":\"ai.meta.com\"},6421],[\"GetAsyncParamsExtraData\",[],{\"extra_data\":{}},7511],[\"BootloaderConfig\",[],{\"deferBootloads\":false,\"jsRetries\":[200,500],\"jsRetryAbortNum\":2,\"jsRetryAbortTime\":5,\"silentDups\":false,\"timeout\":60000,\"tieredLoadingFromTier\":100,\"hypStep4\":false,\"phdOn\":false,\"phdSeparateBitmaps\":false,\"btCutoffIndex\":1897,\"fastPathForAlreadyRequired\":true,\"earlyRequireLazy\":false,\"enableTimeoutLoggingForNonComet\":false,\"deferLongTailManifest\":true,\"lazySoT\":false,\"translationRetries\":[200,500],\"translationRetryAbortNum\":3,\"translationRetryAbortTime\":50},329],[\"CSSLoaderConfig\",[],{\"timeout\":5000},619],[\"CookieCoreConfig\",[],{\"locale\":{\"t\":604800}},2104],[\"CurrentUserInitialData\",[],{\"ACCOUNT_ID\":\"0\",\"USER_ID\":\"0\",\"NAME\":\"\",\"SHORT_NAME\":null,\"IS_BUSINESS_PERSON_ACCOUNT\":false,\"HAS_SECONDARY_BUSINESS_PERSON\":false,\"IS_FACEBOOK_WORK_ACCOUNT\":false,\"IS_INSTAGRAM_BUSINESS_PERSON\":false,\"IS_MESSENGER_ONLY_USER\":false,\"IS_DEACTIVATED_ALLOWED_ON_MESSENGER\":false,\"IS_MESSENGER_CALL_GUEST_USER\":false,\"IS_WORK_MESSENGER_CALL_GUEST_USER\":false,\"IS_WORKROOMS_USER\":false,\"APP_ID\":\"256281040558\",\"IS_BUSINESS_DOMAIN\":false},270],[\"LSD\",[],{\"token\":\"AVpj3xVArF0\"},323],[\"ServerNonce\",[],{\"ServerNonce\":\"Pndbh6FDJQ9bkiiDIlfxXJ\"},141],[\"SiteData\",[],{\"server_revision\":1019093108,\"client_revision\":1019092984,\"push_phase\":\"C3\",\"pkg_cohort\":\"BP:DEFAULT\",\"haste_session\":\"20085.BP:DEFAULT.2.0.0.0.0\",\"pr\":1,\"manifest_base_uri\":\"https:\\/\\/static.xx.fbcdn.net\",\"manifest_origin\":null,\"manifest_version_prefix\":null,\"be_one_ahead\":false,\"is_rtl\":false,\"is_experimental_tier\":false,\"is_jit_warmed_up\":true,\"hsi\":\"7453497756665521207\",\"semr_host_bucket\":\"15\",\"bl_hash_version\":2,\"comet_env\":0,\"wbloks_env\":false,\"ef_page\":null,\"compose_bootloads\":false,\"spin\":4,\"__spin_r\":1019092984,\"__spin_b\":\"trunk\",\"__spin_t\":1735402680,\"vip\":\"2a03:2880:f008:1:face:b00c:0:1\"},317],[\"SprinkleConfig\",[],{\"param_name\":\"jazoest\",\"version\":2,\"should_randomize\":false},2111],[\"UserAgentData\",[],{\"browserArchitecture\":\"32\",\"browserFullVersion\":null,\"browserMinorVersion\":null,\"browserName\":\"Unknown\",\"browserVersion\":null,\"deviceName\":\"Unknown\",\"engineName\":\"Unknown\",\"engineVersion\":null,\"platformArchitecture\":\"32\",\"platformName\":\"Unknown\",\"platformVersion\":null,\"platformFullVersion\":null},527],[\"PromiseUsePolyfillSetImmediateGK\",[],{\"www_always_use_polyfill_setimmediate\":false},2190],[\"JSErrorLoggingConfig\",[],{\"appId\":256281040558,\"extra\":[],\"reportInterval\":50,\"sampleWeight\":null,\"sampleWeightKey\":\"__jssesw\",\"projectBlocklist\":[]},2776],[\"CookieCoreLoggingConfig\",[],{\"maximumIgnorableStallMs\":16.67,\"sampleRate\":9.7e-5,\"sampleRateClassic\":1.0e-10,\"sampleRateFastStale\":1.0e-8},3401],[\"ImmediateImplementationExperiments\",[],{\"prefer_message_channel\":true},3419],[\"UriNeedRawQuerySVConfig\",[],{\"uris\":[\"dms.netmng.com\",\"doubleclick.net\",\"r.msn.com\",\"watchit.sky.com\",\"graphite.instagram.com\",\"www.kfc.co.th\",\"learn.pantheon.io\",\"www.landmarkshops.in\",\"www.ncl.com\",\"s0.wp.com\",\"www.tatacliq.com\",\"bs.serving-sys.com\",\"kohls.com\",\"lazada.co.th\",\"xg4ken.com\",\"technopark.ru\",\"officedepot.com.mx\",\"bestbuy.com.mx\",\"booking.com\",\"nibio.no\",\"myworkdayjobs.com\",\"united-united.com\",\"gcc.gnu.org\"]},3871],[\"WebConnectionClassServerGuess\",[],{\"connectionClass\":\"GOOD\"},4705],[\"BootloaderEndpointConfig\",[],{\"debugNoBatching\":false,\"maxBatchSize\":-1,\"endpointURI\":\"https:\\/\\/ai.meta.com\\/ajax\\/bootloader-endpoint\\/\"},5094],[\"ServerTimeData\",[],{\"serverTime\":1735402680243,\"timeOfRequestStart\":1735402680068.7,\"timeOfResponseStart\":1735402680068.7},5943],[\"BigPipeExperiments\",[],{\"link_images_to_pagelets\":false,\"am_page_load_promise_timeout\":false},907],[\"cr:7730\",[\"getFbtResult\"],{\"__rc\":[\"getFbtResult\",null]},-1],[\"cr:8906\",[\"goURIWWW\"],{\"__rc\":[\"goURIWWW\",null]},-1],[\"cr:925100\",[\"RunBlue\"],{\"__rc\":[\"RunBlue\",null]},-1],[\"cr:7386\",[\"clearTimeoutWWW\"],{\"__rc\":[\"clearTimeoutWWW\",null]},-1],[\"cr:7390\",[\"setTimeoutWWW\"],{\"__rc\":[\"setTimeoutWWW\",null]},-1],[\"cr:1003267\",[\"clearIntervalBlue\"],{\"__rc\":[\"clearIntervalBlue\",null]},-1],[\"cr:896462\",[\"setIntervalAcrossTransitionsBlue\"],{\"__rc\":[\"setIntervalAcrossTransitionsBlue\",null]},-1],[\"cr:986633\",[\"setTimeoutAcrossTransitionsBlue\"],{\"__rc\":[\"setTimeoutAcrossTransitionsBlue\",null]},-1],[\"cr:6799\",[\"EventProfilerAdsSessionProvider\"],{\"__rc\":[\"EventProfilerAdsSessionProvider\",null]},-1],[\"IntlVariationHoldout\",[],{\"disable_variation\":false},6533],[\"IntlNumberTypeProps\",[\"IntlCLDRNumberType05\"],{\"module\":{\"__m\":\"IntlCLDRNumberType05\"}},7027],[\"AdsManagerReadRegions\",[],{\"excluded_endpoints\":[\"\\/am_tabular\"]},7950],[\"AsyncRequestConfig\",[],{\"retryOnNetworkError\":\"1\",\"useFetchStreamAjaxPipeTransport\":true},328],[\"DTSGInitialData\",[],{},258],[\"IntlPhonologicalRules\",[],{\"meta\":{},\"patterns\":{}},1496],[\"IntlViewerContext\",[],{\"GENDER\":3,\"regionalLocale\":null},772],[\"NumberFormatConfig\",[],{\"decimalSeparator\":\",\",\"numberDelimiter\":\".\",\"minDigitsForThousandsSeparator\":5,\"standardDecimalPatternInfo\":{\"primaryGroupSize\":3,\"secondaryGroupSize\":3},\"numberingSystemData\":null},54],[\"SessionNameConfig\",[],{\"seed\":\"1CE4\"},757],[\"ZeroCategoryHeader\",[],{},1127],[\"ZeroRewriteRules\",[],{\"rewrite_rules\":{},\"whitelist\":{\"\\/hr\\/r\":1,\"\\/hr\\/p\":1,\"\\/zero\\/unsupported_browser\\/\":1,\"\\/zero\\/policy\\/optin\":1,\"\\/zero\\/optin\\/write\\/\":1,\"\\/zero\\/optin\\/legal\\/\":1,\"\\/zero\\/optin\\/free\\/\":1,\"\\/about\\/privacy\\/\":1,\"\\/about\\/privacy\\/update\\/\":1,\"\\/privacy\\/explanation\\/\":1,\"\\/zero\\/toggle\\/welcome\\/\":1,\"\\/zero\\/toggle\\/nux\\/\":1,\"\\/zero\\/toggle\\/settings\\/\":1,\"\\/fup\\/interstitial\\/\":1,\"\\/work\\/landing\":1,\"\\/work\\/login\\/\":1,\"\\/work\\/email\\/\":1,\"\\/ai.php\":1,\"\\/js_dialog_resources\\/dialog_descriptions_android.json\":0,\"\\/connect\\/jsdialog\\/MPlatformAppInvitesJSDialog\\/\":0,\"\\/connect\\/jsdialog\\/MPlatformOAuthShimJSDialog\\/\":0,\"\\/connect\\/jsdialog\\/MPlatformLikeJSDialog\\/\":0,\"\\/qp\\/interstitial\\/\":1,\"\\/qp\\/action\\/redirect\\/\":1,\"\\/qp\\/action\\/close\\/\":1,\"\\/zero\\/support\\/ineligible\\/\":1,\"\\/zero_balance_redirect\\/\":1,\"\\/zero_balance_redirect\":1,\"\\/zero_balance_redirect\\/l\\/\":1,\"\\/l.php\":1,\"\\/lsr.php\":1,\"\\/ajax\\/dtsg\\/\":1,\"\\/checkpoint\\/block\\/\":1,\"\\/exitdsite\":1,\"\\/zero\\/balance\\/pixel\\/\":1,\"\\/zero\\/balance\\/\":1,\"\\/zero\\/balance\\/carrier_landing\\/\":1,\"\\/zero\\/flex\\/logging\\/\":1,\"\\/tr\":1,\"\\/tr\\/\":1,\"\\/sem_campaigns\\/sem_pixel_test\\/\":1,\"\\/bookmarks\\/flyout\\/body\\/\":1,\"\\/zero\\/subno\\/\":1,\"\\/confirmemail.php\":1,\"\\/policies\\/\":1,\"\\/mobile\\/internetdotorg\\/classifier\\/\":1,\"\\/zero\\/dogfooding\":1,\"\\/xti.php\":1,\"\\/zero\\/fblite\\/config\\/\":1,\"\\/hr\\/zsh\\/wc\\/\":1,\"\\/ajax\\/bootloader-endpoint\\/\":1,\"\\/mobile\\/zero\\/carrier_page\\/\":1,\"\\/mobile\\/zero\\/carrier_page\\/education_page\\/\":1,\"\\/mobile\\/zero\\/carrier_page\\/feature_switch\\/\":1,\"\\/mobile\\/zero\\/carrier_page\\/settings_page\\/\":1,\"\\/aloha_check_build\":1,\"\\/upsell\\/zbd\\/softnudge\\/\":1,\"\\/mobile\\/zero\\/af_transition\\/\":1,\"\\/mobile\\/zero\\/af_transition\\/action\\/\":1,\"\\/mobile\\/zero\\/freemium\\/\":1,\"\\/mobile\\/zero\\/freemium\\/redirect\\/\":1,\"\\/mobile\\/zero\\/freemium\\/zero_fup\\/\":1,\"\\/privacy\\/policy\\/\":1,\"\\/privacy\\/center\\/\":1,\"\\/data\\/manifest\\/\":1,\"\\/cmon\":1,\"\\/cmon\\/\":1,\"\\/4oh4.php\":1,\"\\/autologin.php\":1,\"\\/birthday_help.php\":1,\"\\/checkpoint\\/\":1,\"\\/contact-importer\\/\":1,\"\\/cr.php\":1,\"\\/legal\\/terms\\/\":1,\"\\/login.php\":1,\"\\/login\\/\":1,\"\\/mobile\\/account\\/\":1,\"\\/n\\/\":1,\"\\/remote_test_device\\/\":1,\"\\/upsell\\/buy\\/\":1,\"\\/upsell\\/buyconfirm\\/\":1,\"\\/upsell\\/buyresult\\/\":1,\"\\/upsell\\/promos\\/\":1,\"\\/upsell\\/continue\\/\":1,\"\\/upsell\\/h\\/promos\\/\":1,\"\\/upsell\\/loan\\/learnmore\\/\":1,\"\\/upsell\\/purchase\\/\":1,\"\\/upsell\\/promos\\/upgrade\\/\":1,\"\\/upsell\\/buy_redirect\\/\":1,\"\\/upsell\\/loan\\/buyconfirm\\/\":1,\"\\/upsell\\/loan\\/buy\\/\":1,\"\\/upsell\\/sms\\/\":1,\"\\/wap\\/a\\/channel\\/reconnect.php\":1,\"\\/wap\\/a\\/nux\\/wizard\\/nav.php\":1,\"\\/wap\\/appreg.php\":1,\"\\/wap\\/birthday_help.php\":1,\"\\/wap\\/c.php\":1,\"\\/wap\\/confirmemail.php\":1,\"\\/wap\\/cr.php\":1,\"\\/wap\\/login.php\":1,\"\\/wap\\/r.php\":1,\"\\/zero\\/datapolicy\":1,\"\\/a\\/timezone.php\":1,\"\\/a\\/bz\":1,\"\\/bz\\/reliability\":1,\"\\/r.php\":1,\"\\/mr\\/\":1,\"\\/reg\\/\":1,\"\\/registration\\/log\\/\":1,\"\\/terms\\/\":1,\"\\/f123\\/\":1,\"\\/expert\\/\":1,\"\\/experts\\/\":1,\"\\/terms\\/index.php\":1,\"\\/terms.php\":1,\"\\/srr\\/\":1,\"\\/msite\\/redirect\\/\":1,\"\\/fbs\\/pixel\\/\":1,\"\\/contactpoint\\/preconfirmation\\/\":1,\"\\/contactpoint\\/cliff\\/\":1,\"\\/contactpoint\\/confirm\\/submit\\/\":1,\"\\/contactpoint\\/confirmed\\/\":1,\"\\/contactpoint\\/login\\/\":1,\"\\/preconfirmation\\/contactpoint_change\\/\":1,\"\\/help\\/contact\\/\":1,\"\\/survey\\/\":1,\"\\/upsell\\/loyaltytopup\\/accept\\/\":1,\"\\/settings\\/\":1,\"\\/lite\\/\":1,\"\\/zero_status_update\\/\":1,\"\\/operator_store\\/\":1,\"\\/upsell\\/\":1,\"\\/wifiauth\\/login\\/\":1}},1478],[\"DTSGInitData\",[],{\"token\":\"\",\"async_get_token\":\"\"},3515],[\"WebDriverConfig\",[],{\"isTestRunning\":false,\"isJestE2ETestRun\":false,\"isXRequestConfigEnabled\":false,\"auxiliaryServiceInfo\":{},\"testPath\":null,\"originHost\":null},5332],[\"EventConfig\",[],{\"sampling\":{\"bandwidth\":0,\"play\":0,\"playing\":0,\"progress\":0,\"pause\":0,\"ended\":0,\"seeked\":0,\"seeking\":0,\"waiting\":0,\"loadedmetadata\":0,\"canplay\":0,\"selectionchange\":0,\"change\":0,\"timeupdate\":0,\"adaptation\":0,\"focus\":0,\"blur\":0,\"load\":0,\"error\":0,\"message\":0,\"abort\":0,\"storage\":0,\"scroll\":200000,\"mousemove\":20000,\"mouseover\":10000,\"mouseout\":10000,\"mousewheel\":1,\"MSPointerMove\":10000,\"keydown\":0.1,\"click\":0.02,\"mouseup\":0.02,\"__100ms\":0.001,\"__default\":5000,\"__min\":100,\"__interactionDefault\":200,\"__eventDefault\":100000},\"page_sampling_boost\":1,\"interaction_regexes\":{},\"interaction_boost\":{},\"event_types\":{},\"manual_instrumentation\":false,\"profile_eager_execution\":false,\"disable_heuristic\":true,\"disable_event_profiler\":false},1726],[\"cr:8828\",[],{\"__rc\":[null,null]},-1],[\"cr:1094907\",[],{\"__rc\":[null,null]},-1],[\"cr:1183579\",[\"InlineFbtResultImpl\"],{\"__rc\":[\"InlineFbtResultImpl\",null]},-1],[\"cr:806696\",[\"clearTimeoutBlue\"],{\"__rc\":[\"clearTimeoutBlue\",null]},-1],[\"cr:807042\",[\"setTimeoutBlue\"],{\"__rc\":[\"setTimeoutBlue\",null]},-1],[\"FbtResultGK\",[],{\"shouldReturnFbtResult\":true,\"inlineMode\":\"NO_INLINE\"},876],[\"AdsInterfacesSessionConfig\",[],{},2393],[\"DataStoreConfig\",[],{\"expandoKey\":\"__FB_STORE\",\"useExpando\":true},2915],[\"FbtQTOverrides\",[],{\"overrides\":{}},551],[\"AnalyticsCoreData\",[],{\"device_id\":\"$^|Aca1UkNtVluhDLBeNrr-55qdD3QTpTr6_M8RgOF8F3jdsOpgav54O46FWIzvGyYkid_kQMMkdVj2DpicMcpdwxqgLWqVWpsDWK9jwjdj9ERsfGEXisOL7rhVfQE13niHJ_ojEArFaAobgD2b0_YXoAk|fd.AcY4Pobr-Zb4gO-LmlWP8gDuhahVsb5jqG9dgzZl4etSwMdOWoSbaw3m3X8C8CS-Jqqa1eoP8MA9S2lQN5u4dbAc\",\"app_id\":\"256281040558\",\"enable_bladerunner\":false,\"enable_ack\":true,\"push_phase\":\"C3\",\"enable_observer\":false,\"enable_cmcd_observer\":false,\"enable_dataloss_timer\":false,\"enable_fallback_for_br\":true,\"queue_activation_experiment\":false,\"max_delay_br_queue\":60000,\"max_delay_br_queue_immediate\":3,\"max_delay_br_init_not_complete\":3000,\"consents\":{},\"app_universe\":1,\"br_stateful_migration_on\":true,\"enable_non_fb_br_stateless_by_default\":false,\"use_falco_as_mutex_key\":false,\"is_intern\":false,\"enable_session_id_bug_fix\":true},5237],[\"InitialCookieConsent\",[],{\"deferCookies\":false,\"initialConsent\":[1,2],\"noCookies\":false,\"shouldShowCookieBanner\":false,\"shouldWaitForDeferredDatrCookie\":false,\"optedInIntegrations\":[],\"hasGranularThirdPartyCookieConsent\":false,\"exemptedIntegrations\":[\"advertiser_hosted_pixel\",\"airbus_sat\",\"amazon_media\",\"apps_for_office\",\"arkose_captcha\",\"aspnet_cdn\",\"autodesk_fusion\",\"bing_maps\",\"bing_widget\",\"boku_wallet\",\"bootstrap\",\"box\",\"cardinal_centinel_api\",\"chromecast_extensions\",\"cloudflare_cdnjs\",\"cloudflare_datatables\",\"cloudflare_relay\",\"conversions_api_gateway\",\"ctrl_labs_api\",\"demandbase_api\",\"digitalglobe_maps_api\",\"dlocal\",\"dropbox\",\"esri_sat\",\"fastly_relay\",\"gmg_pulse_embed_iframe\",\"google_ads_conversions_tag\",\"google_drive\",\"google_fonts_legacy\",\"google_hosted_libraries\",\"google_oauth_api\",\"google_oauth_api_v2\",\"google_recaptcha\",\"here_map_ext\",\"hive_streaming_video\",\"isptoolbox\",\"jquery\",\"js_delivr\",\"kbank\",\"mathjax\",\"metacdn\",\"microsoft_excel\",\"microsoft_office_addin\",\"microsoft_onedrive\",\"microsoft_speech\",\"microsoft_teams\",\"mmi_tiles\",\"open_street_map\",\"paypal_billing_agreement\",\"paypal_oauth_api\",\"payu\",\"plaid\",\"platformized_adyen_checkout\",\"plotly\",\"pydata\",\"recruitics\",\"rstudio\",\"salesforce_lighting\",\"stripe\",\"team_center\",\"tripshot\",\"trustly_direct_debit_ach\",\"twilio_voice\",\"unifier\",\"unsplash_api\",\"unsplash_image_loading\",\"vega\",\"yoti_api\",\"youtube_oembed_api\"]},4328]],\"require\":[[\"markJSEnabled\"],[\"URLFragmentPrelude\"],[\"Primer\"],[\"BigPipe\"],[\"Bootloader\"],[\"TimeSlice\"],[\"AsyncRequest\"],[\"FbtLogging\"],[\"IntlQtEventFalcoEvent\"],[\"RequireDeferredReference\",\"unblock\",[],[[\"AsyncRequest\",\"FbtLogging\",\"IntlQtEventFalcoEvent\"],\"sd\"]],[\"RequireDeferredReference\",\"unblock\",[],[[\"AsyncRequest\",\"FbtLogging\",\"IntlQtEventFalcoEvent\"],\"css\"]]]});});</script></head><body class=\"x1 Locale_en_US\" dir=\"ltr\"><script type=\"text/javascript\" nonce=\"DyPoUrmQ\">requireLazy([\"bootstrapWebSession\"],function(j){j(1735402680)})</script><div class=\"_li\"><div class=\"_8xs5 _alu7\"><div class=\"_9rdv _9bie _9bif _9bhn _9kum _9o9f\"><!-- begin-react-placeholder --><div class=\"_aqmz _aqp3\" style=\"color:;\"><div class=\"_aqmc\"><a class=\"_9b0l _9b0e _aqmh\" href=\"#\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;&#125;\" role=\"button\" style=\"\"><img class=\"_aqmi _aqmj _8h4h img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/252294889_575082167077436_6034106545912333281_n.svg/meta-logo-primary_standardsize.svg?_nc_cat=1&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=q-hF1w5dzNAQ7kNvgETZYhl&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYAdLO5rfo3T4eVdjTlskSNwnFbjQoOpnPlcHL6qaLkU6Q&amp;oe=6775E279\" height=\"18\" width=\"89\" alt=\"Meta\" /></a><div class=\"_aqmn\"><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqmb\" href=\"#\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;&#125;\" role=\"button\" style=\"\">Our approach</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqmb\" href=\"#\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;&#125;\" role=\"button\" style=\"\">Research</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqmb\" href=\"#\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;&#125;\" role=\"button\" style=\"\">Product experiences</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqm7 _aqmb\" href=\"https://llama.meta.com/\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external&quot;&#125;\" target=\"_blank\" rel=\"noreferrer noopener\" data-lnfb-mode=\"ie\" id=\"u_0_0_J3\" style=\"\">Llama</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqm7 _aqmb\" href=\"/blog/\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_internal&quot;&#125;\" target=\"_self\" style=\"\">Blog</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqm7 _aqmb\" href=\"https://www.meta.ai/?utm_source=ai_meta_site&amp;utm_medium=web&amp;utm_content=AI_nav&amp;utm_campaign=April_moment\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external&quot;&#125;\" target=\"_blank\" rel=\"noreferrer noopener\" data-lnfb-mode=\"ie\" id=\"u_0_1_Jz\" style=\"\">Try Meta AI</a></li><li class=\"_aqmp\"><a class=\"_9b0l _9b0e _aqms\" href=\"/\" data-ms-clickable=\"true\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_internal&quot;&#125;\" style=\"\"><svg width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M2.545 2.546c3.349-3.35 8.746-3.4 12.031-.115 3.048 3.048 3.223 7.914.558 11.275.438.434 3.148 3.144 4.22 4.216l.41.41c.356.355.29.998-.072 1.36-.363.363-1.005.428-1.36.072-2.74-2.739-4.283-4.28-4.633-4.625-3.36 2.66-8.222 2.483-11.268-.563-3.286-3.285-3.234-8.682.114-12.03zm10.717 1.428a6.575 6.575 0 00-9.288 0 6.575 6.575 0 000 9.288 6.575 6.575 0 009.288 0 6.575 6.575 0 000-9.288z\" fill=\"CurrentColor\" fill-rule=\"evenodd\"></path></svg></a></li></div></div></div><!-- end-react-placeholder --><noscript id=\"u_0_2_kl\"></noscript></div><div><div class=\"\"><div><div class=\"_8zlh\"></div><div class=\"_8zlh\"></div><div class=\"_8zli\"></div><div class=\"_8zli\"></div><div class=\"_8zlj\"></div><div class=\"_8za3\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"></div><div class=\"_8y2o\"><div class=\"_8y2r\"><div class=\"_8y2p\"><div class=\"_8y2q\"><div class=\"_8xke _8xhs _8xkf _8xkh _8xhs _913n\"><div class=\"_8x6u\"><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">NLP</h4></div><div class=\"_8_wk\"><h1 class=\"_8w6a _8w6b _8w61\">Large Concept Models: Language Modeling in a Sentence Representation Space</h1></div><p class=\"_8w6f _8wl0 _8w6h\">December 11, 2024</p></div></div><div class=\"_8xke _8xhs _8xkf _8xkh _8xhs _8_wl\"><h2 class=\"_8w6a _8w6c _8w61\">Abstract</h2><p class=\"_8w6f _8w61 _8w6h\">LLMs have revolutionized the field of artificial intelligence and have emerged as the de-facto tool for\n",
      "many tasks. The current established technology of LLMs is to process input and generate output at\n",
      "the token level. This is in sharp contrast to humans who operate at multiple levels of abstraction, well\n",
      "beyond single words, to analyze information and to generate creative content. In this paper, we present\n",
      "an attempt at an architecture which operates on an explicit higher-level semantic representation,\n",
      "which we name a “concept”. Concepts are language- and modality-agnostic and represent a higher\n",
      "level idea or action in a flow. Hence, we build a“Large Concept Model”. In this study, as\n",
      "proof of feasibility, we assume that a concept corresponds to a sentence, and use an existing sentence\n",
      "embedding space, SONAR, which supports up to 200 languages in both text and speech modalities.\n",
      "The Large Concept Model is trained to perform autoregressive sentence prediction in an embedding\n",
      "space. We explore multiple approaches, namely MSE regression, variants of diffusion-based generation,\n",
      "and models operating in a quantized SONAR space. These explorations are performed using 1.6B\n",
      "parameter models and training data in the order of 1.3T tokens. We then scale one architecture to a\n",
      "model size of 7B parameters and training data of about 7.7T tokens. We perform an experimental\n",
      "evaluation on several generative tasks, namely summarization and a new task of summary expansion.\n",
      "Finally, we show that our model exhibits impressive zero-shot generalization performance to many\n",
      "languages, outperforming existing LLMs of the same size. The training code of our models is freely\n",
      "available.</p><div class=\"_8zli\"></div><a role=\"button\" class=\"_8x6s _8x6w _8x6x _8x76 _8x70 _8w61\" href=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.2365-6/470149925_936340665123313_5359535905316748287_n.pdf?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=nrqk_ZhDbgMQ7kNvgFLtjgB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYBGvY3r8nbbktzrtCtISVOtxZVzQwbHDLxOnHtS8GxJxw&amp;oe=6775E952\" data-ms=\"&#123;&quot;creative&quot;:&quot;button&quot;,&quot;creative_detail&quot;:&quot;button&quot;,&quot;create_type&quot;:&quot;button&quot;,&quot;create_type_detail&quot;:&quot;button&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><div class=\"_8x6z\"><svg fill=\"none\" height=\"29\" width=\"29\" viewBox=\"0 0 29 29\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"_8x6_\" d=\"M9 13.75C8.58579 13.75 8.25 14.0858 8.25 14.5C8.25 14.9142 8.58579 15.25 9 15.25V13.75ZM20.5303 15.0303C20.8232 14.7374 20.8232 14.2626 20.5303 13.9697L15.7574 9.1967C15.4645 8.90381 14.9896 8.90381 14.6967 9.1967C14.4038 9.48959 14.4038 9.96447 14.6967 10.2574L18.9393 14.5L14.6967 18.7426C14.4038 19.0355 14.4038 19.5104 14.6967 19.8033C14.9896 20.0962 15.4645 20.0962 15.7574 19.8033L20.5303 15.0303ZM9 15.25H20V13.75H9V15.25Z\" fill=\"#344854\"></path><circle cx=\"14.5\" cy=\"14.5\" r=\"14\" stroke=\"#CCD1D4\"></circle></svg></div><div class=\"_8x6- _8x32\">Download the Paper</div></a></div></div><div class=\"_8y2t\"><div class=\"_8xke _8xhs _8xkf _8xkh _8xhs _913o\"><h4 class=\"_8w6a _8w6e _8w60 _8xok\">AUTHORS</h4><div class=\"_8-f-\"></div><div class=\"_8y2n\"><p class=\"_8w6f _8xm4 _8w61 _8w6h\">Written by</p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>The LCM team</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Loic Barrault</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Paul-Ambroise Duquenne</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/875226594354961/maha-elbayad/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Maha Elbayad</span></a></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Artyom Kozhevnikov</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Belen Alastruey</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Pierre Andrews</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Mariano Coria</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Guillaume Couairon</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Marta R. Costa-jussa</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>David Dale</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Hady Elsahar</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Kevin Heffernan</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>João Maria Janeiro</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Tuan Tran</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Christophe Ropers</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Eduardo Sánchez</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Robin San Roman</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Alexandre Mourachko</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>Safiyyah Saleem</span></p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/271799079300984/holger-schwenk/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Holger Schwenk</span></a></p></div><div class=\"_8y2n\"><p class=\"_8w6f _8xm4 _8w61 _8w6h\">Publisher</p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><span>arXiv</span></p></div><div class=\"_8y2n\"><p class=\"_8w6f _8xm4 _8w61 _8w6h\">Research Topics</p><p class=\"_8w6f _8xm4 _8w61 _8w6h\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/research/nlp/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Natural Language Processing (NLP)</span></a></p></div></div></div></div></div><div class=\"_8zlh\"></div><div class=\"_8za3\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"><h3 class=\"_8w6a _8w6d _8w60 _3-98\">Related Publications</h3><div class=\"_9ni4\"><div class=\"_9nio\"><p class=\"_8w6f _8wl0 _8w6h\">December 17, 2024</p></div><div class=\"_9nil\"><div class=\"_9nim\"><div class=\"_8x6u\"><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">NLP</h4></div><div class=\"_9nid\"><h4 class=\"_8w6a _8w6e _8w61\">FLAME : Factuality-Aware Alignment for Large Language Models</h4></div><div class=\"_9rxa\"><div id=\"u_0_3_Qu\"></div></div><p class=\"_8w6f _8w61 _8w6h _9nie\"><span><span>Jack Lin</span></span>, <span><span>Luyu Gao</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/1474004249915770/barlas-oguz/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Barlas Oguz</span></a></span>, <span><span>Wenhan Xiong</span></span>, <span><span>Jimmy Lin</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/706397891415751/scott-wen-tau-yih/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Scott Yih</span></a></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/398948759518665/xilun-chen/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Xilun Chen</span></a></span></p></div><div class=\"_9nin\"><div class=\"_9nih\"><p class=\"_8w6f _8xm4 _8wl0 _8w6h\">December 17, 2024</p></div><div class=\"_9nig\"><a class=\"_8xc5 _8x97 _8w61\" href=\"/research/publications/flame-factuality-aware-alignment-for-large-language-models/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Read the Paper<i class=\"_9nik img sp_z_bv5d2YIoB sx_60edc2\"></i></span></a></div></div></div></div><div class=\"_9ni4\"><div class=\"_9nio\"><p class=\"_8w6f _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nil\"><div class=\"_9nim\"><div class=\"_8x6u\"><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">NLP</h4><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">CORE MACHINE LEARNING</h4></div><div class=\"_9nid\"><h4 class=\"_8w6a _8w6e _8w61\">Memory Layers at Scale</h4></div><div class=\"_9rxa\"><div id=\"u_0_4_EM\"></div></div><p class=\"_8w6f _8w61 _8w6h _9nie\"><span><span>Vincent-Pierre Berges</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/1474004249915770/barlas-oguz/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Barlas Oguz</span></a></span></p></div><div class=\"_9nin\"><div class=\"_9nih\"><p class=\"_8w6f _8xm4 _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nig\"><a class=\"_8xc5 _8x97 _8w61\" href=\"/research/publications/memory-layers-at-scale/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Read the Paper<i class=\"_9nik img sp_z_bv5d2YIoB sx_60edc2\"></i></span></a></div></div></div></div><div class=\"_9ni4\"><div class=\"_9nio\"><p class=\"_8w6f _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nil\"><div class=\"_9nim\"><div class=\"_8x6u\"><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">NLP</h4></div><div class=\"_9nid\"><h4 class=\"_8w6a _8w6e _8w61\">Byte Latent Transformer: Patches Scale Better Than Tokens</h4></div><div class=\"_9rxa\"><div id=\"u_0_5_hq\"></div></div><p class=\"_8w6f _8w61 _8w6h _9nie\"><span><span>Artidoro Pagnoni</span></span>, <span><span>Ram Pasunuru</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/1456066821689392/pedro-rodriguez/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Pedro Rodriguez</span></a></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/353652850999899/john-nguyen/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">John Nguyen</span></a></span>, <span><span>Benjamin Muller</span></span>, <span><span>Margaret Li</span></span>, <span><span>Chunting Zhou</span></span>, <span><span>Lili Yu</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/1163645124801199/jason-weston/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Jason Weston</span></a></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/1450721039196474/luke-zettlemoyer/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Luke Zettlemoyer</span></a></span>, <span><span>Gargi Ghosh</span></span>, <span><span>Mike Lewis</span></span>, <span><span>Ari Holtzman</span></span>, <span><span>Srini Iyer</span></span></p></div><div class=\"_9nin\"><div class=\"_9nih\"><p class=\"_8w6f _8xm4 _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nig\"><a class=\"_8xc5 _8x97 _8w61\" href=\"/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Read the Paper<i class=\"_9nik img sp_z_bv5d2YIoB sx_60edc2\"></i></span></a></div></div></div></div><div class=\"_9ni4\"><div class=\"_9nio\"><p class=\"_8w6f _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nil\"><div class=\"_9nim\"><div class=\"_8x6u\"><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">HUMAN &amp; MACHINE INTELLIGENCE</h4><h4 class=\"_8w6a _8w6e _8w60 _8xok _8x78\">NLP</h4></div><div class=\"_9nid\"><h4 class=\"_8w6a _8w6e _8w61\">Explore Theory-of-Mind: Program-Guided Adversarial Data Generation for Theory of Mind Reasoning</h4></div><div class=\"_9rxa\"><div id=\"u_0_6_aJ\"></div></div><p class=\"_8w6f _8w61 _8w6h _9nie\"><span><span>Melanie Sclar</span></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/347567754347428/jane-yu/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Jane Yu</span></a></span>, <span><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"/people/422582363688210/maryam-fazel-zarandi/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Maryam Fazel-Zarandi</span></a></span>, <span><span>Yulia Tsvetkov</span></span>, <span><span>Yonatan Bisk</span></span>, <span><span>Yejin Choi</span></span>, <span><span>Asli Celikyilmaz</span></span></p></div><div class=\"_9nin\"><div class=\"_9nih\"><p class=\"_8w6f _8xm4 _8wl0 _8w6h\">December 12, 2024</p></div><div class=\"_9nig\"><a class=\"_8xc5 _8x97 _8w61\" href=\"/research/publications/explore-theory-of-mind-program-guided-adversarial-data-generation-for-theory-of-mind-reasoning/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Read the Paper<i class=\"_9nik img sp_z_bv5d2YIoB sx_60edc2\"></i></span></a></div></div></div></div><div class=\"_9nii\"><a role=\"button\" class=\"_8x6s _8x6w _8x6y _8x76 _8x70 _8w61 _9nij\" href=\"/global_search/?content_types%5B0%5D=publication&amp;page=1\" data-ms=\"&#123;&quot;creative&quot;:&quot;button&quot;,&quot;creative_detail&quot;:&quot;button&quot;,&quot;create_type&quot;:&quot;button&quot;,&quot;create_type_detail&quot;:&quot;button&quot;&#125;\"><div class=\"_8x6z\"><svg fill=\"none\" height=\"29\" width=\"29\" viewBox=\"0 0 29 29\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"_8x6_\" d=\"M9 13.75C8.58579 13.75 8.25 14.0858 8.25 14.5C8.25 14.9142 8.58579 15.25 9 15.25V13.75ZM20.5303 15.0303C20.8232 14.7374 20.8232 14.2626 20.5303 13.9697L15.7574 9.1967C15.4645 8.90381 14.9896 8.90381 14.6967 9.1967C14.4038 9.48959 14.4038 9.96447 14.6967 10.2574L18.9393 14.5L14.6967 18.7426C14.4038 19.0355 14.4038 19.5104 14.6967 19.8033C14.9896 20.0962 15.4645 20.0962 15.7574 19.8033L20.5303 15.0303ZM9 15.25H20V13.75H9V15.25Z\" fill=\"#344854\"></path><circle cx=\"14.5\" cy=\"14.5\" r=\"14\" stroke=\"#CCD1D4\"></circle></svg></div><div class=\"_8x6- _8x32\">See All Papers</div></a></div></div><div class=\"_8zlh\"></div><div class=\"_8zlh\"></div><div class=\"_8za3\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"><div></div><div class=\"_8zlh\"></div><div class=\"_8xka _8xkd\"><div class=\"_8x7r _8x8q _8x92 _8-qp _8xjq\"><img class=\"_8zlc _7f2d _8zjt _8zjw img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.2365-6/90971213_248000486247635_8189447952712859648_n.jpg?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=QUW5wsJcz3AQ7kNvgFPOqVk&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDwLeGF5Zl7GbXUDIwK4EYfz1yaylmemynpgxvzFM28Ww&amp;oe=678A7E97\" alt=\"\" /></div><div class=\"_8x7h _8x8q _8x92\"><div class=\"_8y2u _8xjq\"><div class=\"_913l\"><h2 class=\"_8w6a _8w6b _8wmp\">Help Us Pioneer The Future of AI</h2></div><h5 class=\"_8w6a _8_w4 _8wmp\">We share our open source frameworks, tools, libraries, and models for everything from research exploration to large-scale production deployment.</h5><div class=\"_913m\"><a role=\"button\" class=\"_8x6s _8x6w _8x6y _8x76 _8x70 _8wmp\" href=\"/join-us/\" id=\"join-us_publication\" data-ms=\"&#123;&quot;creative&quot;:&quot;button&quot;,&quot;creative_detail&quot;:&quot;button&quot;,&quot;create_type&quot;:&quot;button&quot;,&quot;create_type_detail&quot;:&quot;button&quot;&#125;\"><div class=\"_8x6z\"><svg width=\"30px\" height=\"30px\" viewBox=\"0 0 30 30\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"><g transform=\"translate(1.000000, 1.000000)\"><path class=\"_8x6_\" d=\"M13.2246129,9.17898199 L17.7898922,13.0678881 C18.0700359,13.3065267 18.0700359,13.6934441 17.7898922,13.9320885 L13.2246129,17.8210167 C12.9444632,18.0596611 12.4902573,18.0596611 12.21011,17.8210167 C11.9299633,17.5823723 11.9299633,17.1954316 12.21011,16.9567872 L15.1982452,14.2960474 L16.1547297,13.4812713 L15.1982452,12.6664952 L12.21011,10.0431836 C11.9299633,9.80453921 11.9299633,9.41762464 12.21011,9.17898199 C12.4902573,8.94033934 12.9444632,8.94033934 13.2246129,9.17898199 Z\" fill=\"#FBE3DF\" fill-rule=\"nonzero\"></path><circle stroke=\"#FBE3DF\" cx=\"14\" cy=\"14\" r=\"14\"></circle></g></g></svg></div><div class=\"_8x6- _8x4y\">Join our Team</div></a></div></div></div></div></div></div></div></div><div class=\"_7f9y _8xdf\"><div class=\"_7f9z\"><div class=\"_7f9x _8xdd\"><div class=\"_8za3\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"><div class=\"_7f90\"><div class=\"_7ot8\"><div class=\"_8-bz\"><div class=\"_7f91\"><div class=\"_8xe1\"><div class=\"_7fa0 _am40\"><div class=\"_7fa1 _am3z\" id=\"u_0_7_KV\"><a class=\"_8xc5 _8x97 _8w61 _7ot6 _8-c1\" href=\"/about\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;our-approach&quot;,&quot;create_type&quot;:&quot;our-approach&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Our approach</span></a><i class=\"_am3y img sp_z_bv5d2YIoB sx_bb0616\" id=\"u_0_8_HO\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_9fa42e\" id=\"u_0_9_EV\"></i></div><div class=\"_7fa2 _am3- _am3_\" id=\"u_0_a_q5\"><div class=\"_7fa4\"><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/about\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;our-approach_about-ai-at-meta&quot;,&quot;create_type&quot;:&quot;our-approach_about-ai-at-meta&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">About AI at Meta</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/responsible-ai\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;our-approach_responsibilities&quot;,&quot;create_type&quot;:&quot;our-approach_responsibilities&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Responsibility</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/results/?content_types%5B0%5D=person&amp;sort_by=random\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;our-approach_people&quot;,&quot;create_type&quot;:&quot;our-approach_people&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">People</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"https://www.metacareers.com/jobs/?is_leadership=0&amp;sub_teams[0]=Artificial%20Intelligence&amp;is_in_page=0\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;our-approach_careers&quot;,&quot;create_type&quot;:&quot;our-approach_careers&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Careers</span></a></div></div></div></div></div><div class=\"_8xe1\"><div class=\"_7fa0 _am40\"><div class=\"_7fa1 _am3z\" id=\"u_0_b_su\"><a class=\"_8xc5 _8x97 _8w61 _7ot6 _8-c1\" href=\"/research\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;research&quot;,&quot;create_type&quot;:&quot;research&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Research</span></a><i class=\"_am3y img sp_z_bv5d2YIoB sx_bb0616\" id=\"u_0_c_Hc\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_9fa42e\" id=\"u_0_d_CT\"></i></div><div class=\"_7fa2 _am3- _am3_\" id=\"u_0_e_zP\"><div class=\"_7fa4\"><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/infrastructure\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;research_infra&quot;,&quot;create_type&quot;:&quot;research_infra&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Infrastructure</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/resources\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;research_resources&quot;,&quot;create_type&quot;:&quot;research_resources&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Resources</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"https://aidemos.meta.com/\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;research_Demos&quot;,&quot;create_type&quot;:&quot;research_Demos&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Demos</span></a></div></div></div></div></div><div class=\"_8xe1\"><div class=\"_7fa0 _am40\"><div class=\"_7fa1 _am3z\" id=\"u_0_f_R/\"><p class=\"_8w6f _8w61 _8w6h _7f93\">Product experiences</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_bb0616\" id=\"u_0_g_x9\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_9fa42e\" id=\"u_0_h_xH\"></i></div><div class=\"_7fa2 _am3- _am3_\" id=\"u_0_i_E+\"><div class=\"_7fa4\"><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/meta-ai/\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;product-experiences_meta-ai&quot;,&quot;create_type&quot;:&quot;product-experiences_meta-ai&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Meta AI</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/ai-studio/\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;product-experiences_ai_studio&quot;,&quot;create_type&quot;:&quot;product-experiences_ai_studio&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">AI Studio</span></a></div></div></div></div></div><div class=\"_8xe1\"><div class=\"_7fa0 _am40\"><div class=\"_7fa1 _am3z\" id=\"u_0_j_eR\"><a class=\"_8xc5 _8x97 _8w61 _7ot6 _8-c1\" href=\"/blog\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;latest-news&quot;,&quot;create_type&quot;:&quot;latest-news&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Latest news</span></a><i class=\"_am3y img sp_z_bv5d2YIoB sx_bb0616\" id=\"u_0_k_c8\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_9fa42e\" id=\"u_0_l_NL\"></i></div><div class=\"_7fa2 _am3- _am3_\" id=\"u_0_m_YD\"><div class=\"_7fa4\"><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/blog\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;latest-news_blog&quot;,&quot;create_type&quot;:&quot;latest-news_blog&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Blog</span></a></div><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"/subscribe\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;latest-news_newsletter&quot;,&quot;create_type&quot;:&quot;latest-news_newsletter&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Newsletter</span></a></div></div></div></div></div><div class=\"_8xe1\"><div class=\"_7fa0 _am40\"><div class=\"_7fa1 _am3z\" id=\"u_0_n_Zb\"><p class=\"_8w6f _8w61 _8w6h _7f93\">Foundational models</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_bb0616\" id=\"u_0_o_qQ\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_9fa42e\" id=\"u_0_p_oU\"></i></div><div class=\"_7fa2 _am3- _am3_\" id=\"u_0_q_bj\"><div class=\"_7fa4\"><div class=\"_7fa5\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7f94\" href=\"https://llama.meta.com/\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_footer&quot;,&quot;creative_detail&quot;:&quot;foundational-models_meta-llama&quot;,&quot;create_type&quot;:&quot;foundational-models_meta-llama&quot;,&quot;create_type_detail&quot;:&quot;click_footer&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Llama</span></a></div></div></div></div></div></div><img class=\"_8zlc _7f2d _8-b- _8-b- img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.2365-6/87524316_2677189655726266_6338721200264445952_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=6FzReS1zTEoQ7kNvgG9LHTI&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYCJaLqZN0fIUUYN23cfp1EkgwJKkBAzeBaoUfPFP3ai3A&amp;oe=678A4C38\" alt=\"\" id=\"u_0_r_ma\" /></div><div class=\"_7ot7\"><div class=\"_8z0n _am3x\"><div><noscript id=\"u_0_s_j5\"></noscript></div></div><div class=\"_7spo\"><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_facebook&quot;,&quot;create_type&quot;:&quot;footer_facebook&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://twitter.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_twitter&quot;,&quot;create_type&quot;:&quot;footer_twitter&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.linkedin.com/showcase/aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_linkedin&quot;,&quot;create_type&quot;:&quot;footer_linkedin&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.youtube.com/&#064;aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_youtube&quot;,&quot;create_type&quot;:&quot;footer_youtube&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div></div></span></a></div></div></div></div></div></div></div></div><div class=\"_7f9-\"><div class=\"_7fa7\"><div class=\"_7fbm\" style=\"\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"><div class=\"_am41\"><div><div class=\"_7fa0 _amdy\"><div class=\"_7fa1 _amdz\" id=\"u_0_t_59\"><p class=\"_8w6f _8w6h _7fa9\">Our approach</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_245e89\" id=\"u_0_u_Cm\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_f76915\" id=\"u_0_v_dW\"></i></div><div class=\"_7fa2 _FBAIExpandableItem__contentAreaDefault _am3_\" id=\"u_0_w_xm\"><div class=\"_7fab\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/about\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Our approach</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/about\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">About AI at Meta</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/responsible-ai\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Responsibility</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/results/?content_types%5B0%5D=person&amp;sort_by=random\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">People</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"https://www.metacareers.com/jobs/?is_leadership=0&amp;sub_teams[0]=Artificial%20Intelligence&amp;is_in_page=0\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Careers</span></a></div></div></div><div class=\"_7fa0 _amdy\"><div class=\"_7fa1 _amdz\" id=\"u_0_x_FI\"><p class=\"_8w6f _8w6h _7fa9\">Research</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_245e89\" id=\"u_0_y_M7\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_f76915\" id=\"u_0_z_jJ\"></i></div><div class=\"_7fa2 _FBAIExpandableItem__contentAreaDefault _am3_\" id=\"u_0_10_F/\"><div class=\"_7fab\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/research\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Research</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/infrastructure\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Infrastructure</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/resources\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Resources</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"https://aidemos.meta.com/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Demos</span></a></div></div></div><div class=\"_7fa0 _amdy\"><div class=\"_7fa1 _amdz\" id=\"u_0_11_oR\"><p class=\"_8w6f _8w6h _7fa9\">Product experiences</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_245e89\" id=\"u_0_12_Pc\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_f76915\" id=\"u_0_13_pn\"></i></div><div class=\"_7fa2 _FBAIExpandableItem__contentAreaDefault _am3_\" id=\"u_0_14_+5\"><div class=\"_7fab\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/meta-ai/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Meta AI</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/ai-studio/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">AI Studio</span></a></div></div></div><div class=\"_7fa0 _amdy\"><div class=\"_7fa1 _amdz\" id=\"u_0_15_yo\"><p class=\"_8w6f _8w6h _7fa9\">Latest news</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_245e89\" id=\"u_0_16_xg\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_f76915\" id=\"u_0_17_pf\"></i></div><div class=\"_7fa2 _FBAIExpandableItem__contentAreaDefault _am3_\" id=\"u_0_18_Ae\"><div class=\"_7fab\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/blog\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Latest news</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/blog\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Blog</span></a><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"/subscribe\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Newsletter</span></a></div></div></div><div class=\"_7fa0 _amdy\"><div class=\"_7fa1 _amdz\" id=\"u_0_19_gh\"><p class=\"_8w6f _8w6h _7fa9\">Foundational models</p><i class=\"_am3y img sp_z_bv5d2YIoB sx_245e89\" id=\"u_0_1a_kL\"></i><i class=\"_am3y hidden_elem img sp_z_bv5d2YIoB sx_f76915\" id=\"u_0_1b_+p\"></i></div><div class=\"_7fa2 _FBAIExpandableItem__contentAreaDefault _am3_\" id=\"u_0_1c_9l\"><div class=\"_7fab\"><a class=\"_8xc5 _8y8i _8x97 _8w61 _7faa\" href=\"https://llama.meta.com/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Llama</span></a></div></div></div></div></div><div class=\"_7ota\"><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_facebook&quot;,&quot;create_type&quot;:&quot;footer_facebook&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://twitter.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_twitter&quot;,&quot;create_type&quot;:&quot;footer_twitter&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.linkedin.com/showcase/aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_linkedin&quot;,&quot;create_type&quot;:&quot;footer_linkedin&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.youtube.com/&#064;aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_youtube&quot;,&quot;create_type&quot;:&quot;footer_youtube&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div></div></span></a></div></div></div></div></div><div class=\"_8za3\" data-ms=\"&#123;&quot;creative&quot;:&quot;section&quot;,&quot;creative_detail&quot;:&quot;section&quot;,&quot;create_type&quot;:&quot;section&quot;,&quot;create_type_detail&quot;:&quot;section&quot;&#125;\"><div class=\"_7es3 _8xde\"><div class=\"_7es4\"><div class=\"_7es5\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/about/privacy/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Privacy Policy</span></a></div><div class=\"_7es5\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/policies/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Terms</span></a></div><div class=\"_7es5\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/policies/cookies/\" data-ms=\"&#123;&quot;creative&quot;:&quot;link&quot;,&quot;creative_detail&quot;:&quot;link&quot;,&quot;create_type&quot;:&quot;link&quot;,&quot;create_type_detail&quot;:&quot;link&quot;&#125;\" target=\"_blank\"><span class=\"_8x6t _8x94 _8w61 _8w6h\">Cookies</span></a></div></div><div class=\"_8-b_\"><div class=\"_7es6\"><p class=\"_8w6f _8w6h\"> Meta © 2024</p></div><div class=\"_8-c0\"><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.facebook.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_facebook&quot;,&quot;create_type&quot;:&quot;footer_facebook&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=NtegxmgcyiQQ7kNvgEr7D3B&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYD0-y7HF0USFf2m_B8Adu66Eq5WuzfX04KqqKN8ZSVMPQ&amp;oe=67760AE7\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://twitter.com/aiatmeta/\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_twitter&quot;,&quot;create_type&quot;:&quot;footer_twitter&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=TMEnD9KNpZIQ7kNvgGca-X-&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYDp8Zc6XRbhFTc5bxCErcCeukUhAOvreYxPv9OlVU-mqg&amp;oe=67760322\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.linkedin.com/showcase/aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_linkedin&quot;,&quot;create_type&quot;:&quot;footer_linkedin&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esb\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div><div class=\"_7esd\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp2-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=LcJihfXeeA8Q7kNvgF5LBIW&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp2-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYA0fhKGAL8w-t6vr4PhbRmNbilxph26qPupNuXYy31p6Q&amp;oe=6775F6BB\" alt=\"\" /></div></div></span></a></div><div class=\"_7sp9\"><a class=\"_8xc5 _8y8i _8x97 _8w61\" href=\"https://www.youtube.com/&#064;aiatmeta\" rel=\"noreferrer\" target=\"_blank\" data-ms=\"&#123;&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;footer_youtube&quot;,&quot;create_type&quot;:&quot;footer_youtube&quot;,&quot;create_type_detail&quot;:&quot;click_external-link&quot;&#125;\" data-lnfb-mode=\"ie\"><span class=\"_8x6t _8x94 _8w61 _8w6h\"><div class=\"_7es8 _7sp8\"><div class=\"_7esa\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div><div class=\"_7esc\"><img class=\"_8zlc _7f2d img\" src=\"https://scontent-mxp1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=DeZxZqsKO-8Q7kNvgHx8vnB&amp;_nc_zt=14&amp;_nc_ht=scontent-mxp1-1.xx&amp;_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&amp;oh=00_AYC9XNLe3TPHS1RmP0Xlw6ewf8ZBTk6AShq5ig-_t5yOrQ&amp;oe=6776102E\" alt=\"\" /></div></div></span></a></div></div></div></div></div></div><noscript></noscript><noscript></noscript></div></div>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"HasteSupportData\"],function(m){m.handle({\"gkxData\":{\"1393\":{\"result\":true,\"hash\":null},\"3485\":{\"result\":false,\"hash\":null},\"7686\":{\"result\":false,\"hash\":null},\"7687\":{\"result\":false,\"hash\":null},\"21075\":{\"result\":false,\"hash\":null},\"23433\":{\"result\":false,\"hash\":null},\"20941\":{\"result\":false,\"hash\":null},\"21116\":{\"result\":false,\"hash\":null},\"22362\":{\"result\":true,\"hash\":null},\"3819\":{\"result\":false,\"hash\":null},\"4341\":{\"result\":false,\"hash\":null},\"6323\":{\"result\":true,\"hash\":null},\"8049\":{\"result\":false,\"hash\":null},\"8523\":{\"result\":false,\"hash\":null},\"8708\":{\"result\":false,\"hash\":null},\"8957\":{\"result\":false,\"hash\":null},\"9861\":{\"result\":false,\"hash\":null},\"21062\":{\"result\":false,\"hash\":null},\"21063\":{\"result\":false,\"hash\":null},\"21069\":{\"result\":false,\"hash\":null},\"21071\":{\"result\":false,\"hash\":null},\"21072\":{\"result\":false,\"hash\":null},\"33056\":{\"result\":false,\"hash\":null},\"8859\":{\"result\":false,\"hash\":null}},\"qexData\":{\"104\":{\"r\":null},\"128\":{\"r\":null},\"344\":{\"r\":null},\"388\":{\"r\":null}},\"justknobxData\":{\"1806\":{\"r\":true},\"2635\":{\"r\":true}}})});requireLazy([\"Bootloader\"],function(m){m.handlePayload({\"consistency\":{\"rev\":1019092984},\"rsrcMap\":{\"IjugNeq\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y9\\/r\\/qetfxZizIhM.js\"},\"79x5MJf\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yw\\/r\\/_UemLyZBbsn.js\"},\"9NiATAn\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yv\\/r\\/yRuFCzueB7p.js\"},\"7Co8YaN\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y0\\/r\\/DlS8iOPbc-U.js\"},\"X+gacmF\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yz\\/r\\/sh0B-F8cDhu.js\"},\"p5KjQo3\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yo\\/r\\/H4488S-UM6f.js\"},\"Ta11qxv\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iEEq4\\/yW\\/l\\/it_IT\\/c3Ekl6MxMgJ.js\"},\"o0Y39To\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yh\\/r\\/hPq02P8uOdr.js\"},\"HyV45JT\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yn\\/r\\/C88zhupguZ2.js\"},\"YWKcFNg\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iWTS4\\/yI\\/l\\/it_IT\\/MNpPuuBgnnJ.js\"},\"56Auvlv\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ijrz4\\/yT\\/l\\/it_IT\\/xPfr5-hC6kf.js\"},\"jLGQDLb\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ip_b4\\/y0\\/l\\/it_IT\\/ByroBupN016.js\"},\"Brrx+M7\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iajD4\\/yM\\/l\\/it_IT\\/ZSR_Nxj1Z6x.js\"},\"CQWWgPv\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yi\\/l\\/0,cross\\/0X7C457lmEI.css\"},\"Ftl2VZm\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yK\\/r\\/lNInKxOqejp.js\"},\"UlKMvP9\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y3\\/r\\/HMPzpe7rO1f.js\"},\"tSd1da+\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yG\\/r\\/cNzbDpFSV0A.js\"},\"1s\\/Toed\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yC\\/r\\/PrMHjiBuCdd.js\"},\"1I0UazQ\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yW\\/r\\/asFwh9NCKh7.js\"},\"u1+5F9n\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y-\\/r\\/TR_F0OvvNM4.js\"},\"vl9u8tK\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iYdm4\\/y6\\/l\\/it_IT\\/7eXLkVWCTA9.js\"},\"8y0KoYS\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i0-c4\\/yO\\/l\\/it_IT\\/5cPR8TxXn7u.js\"},\"8lp8wGa\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ikGL4\\/yB\\/l\\/it_IT\\/edM6zJuH729.js\"},\"UYtis7i\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yK\\/l\\/0,cross\\/SWMTfpZnEQp.css\"},\"A\\/B0RE4\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i-B84\\/yd\\/l\\/it_IT\\/NCNDaZNFLVN.js\"},\"PfStd3o\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ijVM4\\/yY\\/l\\/it_IT\\/vxwe4KRbezi.js\"},\"QqR5QSj\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iQIG4\\/yg\\/l\\/it_IT\\/7hFKD7STLNj.js\"},\"3RPbCsW\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yn\\/l\\/0,cross\\/ImQbZ5rg_Fm.css\"},\"\\/K+0Io+\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ys\\/r\\/AmqOQA0OrOl.js\"},\"tfcHFUz\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ys\\/r\\/z7HfCyH8Z2w.js\"},\"19nx6PN\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yP\\/r\\/WLONHD5eVxD.js\"},\"s\\/iDMuG\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yn\\/l\\/0,cross\\/QeHetVxRmtB.css\"},\"nsBuMtO\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yg\\/r\\/OT6PYeGUoC7.js\"},\"2RKDU\\/L\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yE\\/l\\/0,cross\\/GJifdpQDy4e.css\"},\"wgltd+W\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iffJ4\\/y7\\/l\\/it_IT\\/l5THoBv13iR.js\"},\"jGcZiJF\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yJ\\/l\\/0,cross\\/2HvbLbbk6eA.css\"},\"sF9QhVg\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yN\\/l\\/0,cross\\/Ok1B_zkU-kH.css\"},\"Dh+zsNB\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/y1\\/l\\/0,cross\\/lNTDPc2DAGJ.css\"},\"L6ciEh1\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ixLU4\\/y3\\/l\\/it_IT\\/MZsuiAjNJO8.js\"},\"RSIe7aP\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iDNK4\\/yj\\/l\\/it_IT\\/VbX_62RfPnF.js\"},\"0aFZxyL\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i0OT4\\/yJ\\/l\\/it_IT\\/52X6Z-10kv9.js\"},\"EqMigrb\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yv\\/r\\/bYx7ug41LAD.js\"},\"d8hh03I\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iIAe4\\/yN\\/l\\/it_IT\\/5bLTHDBUMlm.js\"},\"NYtrtoS\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ie954\\/yA\\/l\\/it_IT\\/7OON-fPYMdb.js\"},\"wBjshpB\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yy\\/r\\/Y0nOXjvgVtO.js\"},\"zwPbSl+\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y7\\/r\\/rUMwOcxI_sr.js\"},\"v3LJVPf\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i1MJ4\\/y_\\/l\\/it_IT\\/FpPJKs8WQeq.js\"},\"n6Ec8Ha\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i4604\\/yd\\/l\\/it_IT\\/GGNeVrQGmDw.js\"},\"sNERwdq\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4irDK4\\/ya\\/l\\/it_IT\\/UH0ne5e-HRS.js\"},\"aP0t4qu\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iZs-4\\/yu\\/l\\/it_IT\\/NbhA8hfE2Y3.js\"},\"\\/53alSP\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yH\\/r\\/s1PUox7FJqY.js\"},\"dV4Qk4t\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yK\\/r\\/WyuaBg65YLH.js\"},\"+6qGI7o\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y_\\/r\\/7p-2l4DpxpE.js\"},\"I9P25Jy\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iO0z4\\/yA\\/l\\/it_IT\\/eFwfeD4kMhp.js\"},\"5lYMau9\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yZ\\/r\\/D1z4m8C-lAG.js\"},\"fFtCSeD\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/y_\\/l\\/0,cross\\/TPmTpvIJoBh.css\"},\"SkTd\\/EX\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i1c04\\/yu\\/l\\/it_IT\\/OECdpV0MytV.js\"},\"\\/fRfucJ\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yj\\/r\\/J_2QGZXJPHT.js\"},\"l+VOICZ\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yC\\/l\\/0,cross\\/hMk0wotVPtd.css\"},\"nxj86ax\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iXYl4\\/yV\\/l\\/it_IT\\/ttpjN8XKvad.js\"},\"Xgq1Lxv\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yC\\/l\\/0,cross\\/jLF34FojLBe.css\"},\"EmxYBL+\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4id9d4\\/yg\\/l\\/it_IT\\/6_BNgJKgRsC.js\"},\"kbZ3a+o\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iosD4\\/ye\\/l\\/it_IT\\/rHcp083I3jg.js\"},\"9TmFXZ7\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iajD4\\/yq\\/l\\/it_IT\\/MrfWDjDdNPh.js\"},\"Yx7rrao\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yx\\/r\\/dRUiUPxJyka.js\"},\"STN5M4f\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4i41O4\\/yE\\/l\\/it_IT\\/WAXfy4qLpJ8.js\"},\"Zgc+X5s\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iDzB4\\/yP\\/l\\/it_IT\\/mmGS1mMXiMC.js\"},\"SxjllWY\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yO\\/r\\/3Q6KnSLbqSO.js\"},\"fbi0BbH\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yj\\/l\\/0,cross\\/tdZgvu9fsbs.css\"},\"gpkNT+D\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yb\\/l\\/0,cross\\/QlMTqKTKE4y.css\"},\"xsFg75a\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yt\\/r\\/mnLc1TS2Wp-.js\"},\"ahJN284\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yo\\/r\\/_E9yI6oelY6.js\"},\"rZxjZO8\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iB5W4\\/yj\\/l\\/it_IT\\/UVIFvZTEvY5.js\"},\"YbUEA0a\":{\"type\":\"css\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v5\\/yj\\/l\\/0,cross\\/Otn8b4FyyYp.css\"},\"SWx3yNv\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y7\\/r\\/g__eV5OXSXl.js\"},\"x22Oby4\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yZ\\/r\\/tVshp1OIV9l.js\"},\"gv7KP21\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4isw24\\/yi\\/l\\/it_IT\\/SQgagSe-faE.js\"},\"8ELCBwH\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ye\\/r\\/VRzSVH5iU-V.js\"},\"I+GHswV\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yS\\/r\\/ui2DkP-wt_7.js\"},\"1vsm6IY\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yA\\/r\\/XMGpV2NU7SG.js\"},\"H\\/5lfuF\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yF\\/r\\/iqrvM8jAXX7.js\"},\"17Grp2h\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/y-\\/r\\/HhbMrxvaW_H.js\"},\"QyoftxH\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yL\\/r\\/j-_AFWnS2kv.js\"},\"QIamfde\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yA\\/r\\/Y37sQzk-yb8.js\"},\"ZH5DRAM\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yb\\/r\\/2nNPbscwYXB.js\"},\"I8zzdEO\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yL\\/r\\/i0M9P8lkvEv.js\"},\"K1pGhOF\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ye\\/r\\/xDgm3Tqkawr.js\"},\"9Hl4kP7\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iH_T4\\/yD\\/l\\/it_IT\\/pK50bUwHSMM.js\"},\"qnlaxic\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ilY34\\/yD\\/l\\/it_IT\\/ey-oGV7j96P.js\"},\"jUx4Er3\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yO\\/r\\/i8g7jNs9VtA.js\"},\"WlWA5Yc\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4iHpu4\\/yY\\/l\\/it_IT\\/YVTDk9ExP5f.js\"},\"\\/\\/za25u\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/yM\\/r\\/YdtQ-95opMP.js\"},\"a6hDdEq\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4ign94\\/yW\\/l\\/it_IT\\/WBlJZYW9tt6.js\"},\"HLEgydM\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ys\\/r\\/19-WHn5Typd.js\"},\"vCxI9D4\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v4\\/ye\\/r\\/GcgopRl4mBW.js\"}},\"compMap\":{\"WebSpeedInteractionsTypedLogger\":{\"r\":[\"IjugNeq\",\"79x5MJf\",\"9NiATAn\",\"7Co8YaN\",\"X+gacmF\"],\"be\":1},\"AsyncRequest\":{\"r\":[\"p5KjQo3\",\"Ta11qxv\",\"79x5MJf\",\"D4\\/LUJw\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"]},\"be\":1},\"DOM\":{\"r\":[\"79x5MJf\",\"D4\\/LUJw\"],\"be\":1},\"Form\":{\"r\":[\"o0Y39To\",\"79x5MJf\",\"D4\\/LUJw\"],\"be\":1},\"FormSubmit\":{\"r\":[\"p5KjQo3\",\"Ta11qxv\",\"o0Y39To\",\"79x5MJf\",\"HyV45JT\",\"D4\\/LUJw\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"]},\"be\":1},\"Input\":{\"r\":[\"o0Y39To\"],\"be\":1},\"Toggler\":{\"r\":[\"D4\\/LUJw\",\"7Co8YaN\",\"o0Y39To\",\"YWKcFNg\",\"79x5MJf\",\"56Auvlv\"],\"be\":1},\"Tooltip\":{\"r\":[\"jLGQDLb\",\"D4\\/LUJw\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"Brrx+M7\",\"CQWWgPv\",\"YWKcFNg\",\"Ftl2VZm\",\"UlKMvP9\",\"79x5MJf\",\"tSd1da+\",\"1s\\/Toed\",\"o0Y39To\",\"56Auvlv\",\"1I0UazQ\",\"u1+5F9n\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\",\"PageTransitions\",\"Animation\"]},\"be\":1},\"URI\":{\"r\":[],\"be\":1},\"trackReferrer\":{\"r\":[],\"be\":1},\"PhotoTagApproval\":{\"r\":[\"vl9u8tK\",\"79x5MJf\",\"8y0KoYS\",\"D4\\/LUJw\"],\"be\":1},\"PhotoSnowlift\":{\"r\":[\"8lp8wGa\",\"jLGQDLb\",\"D4\\/LUJw\",\"7Co8YaN\",\"UYtis7i\",\"p5KjQo3\",\"Ta11qxv\",\"1I0UazQ\",\"A\\/B0RE4\",\"PfStd3o\",\"Brrx+M7\",\"QqR5QSj\",\"3RPbCsW\",\"\\/K+0Io+\",\"tfcHFUz\",\"19nx6PN\",\"CQWWgPv\",\"IjugNeq\",\"s\\/iDMuG\",\"o0Y39To\",\"nsBuMtO\",\"2RKDU\\/L\",\"wgltd+W\",\"jGcZiJF\",\"sF9QhVg\",\"Dh+zsNB\",\"L6ciEh1\",\"RSIe7aP\",\"0aFZxyL\",\"YWKcFNg\",\"EqMigrb\",\"d8hh03I\",\"NYtrtoS\",\"Ftl2VZm\",\"UlKMvP9\",\"wBjshpB\",\"zwPbSl+\",\"v3LJVPf\",\"n6Ec8Ha\",\"sNERwdq\",\"79x5MJf\",\"aP0t4qu\",\"\\/53alSP\",\"tSd1da+\",\"dV4Qk4t\",\"K1WZ7sC\",\"56Auvlv\",\"8y0KoYS\",\"+6qGI7o\",\"I9P25Jy\",\"5lYMau9\",\"fFtCSeD\",\"SkTd\\/EX\",\"\\/fRfucJ\",\"1s\\/Toed\",\"X+gacmF\",\"u1+5F9n\"],\"rds\":{\"m\":[\"Animation\",\"FbtLogging\",\"IntlQtEventFalcoEvent\",\"PageTransitions\"]},\"be\":1},\"PhotoTagger\":{\"r\":[\"l+VOICZ\",\"jLGQDLb\",\"nxj86ax\",\"D4\\/LUJw\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"Brrx+M7\",\"QqR5QSj\",\"Xgq1Lxv\",\"tfcHFUz\",\"EmxYBL+\",\"kbZ3a+o\",\"s\\/iDMuG\",\"o0Y39To\",\"RSIe7aP\",\"YWKcFNg\",\"Ftl2VZm\",\"UlKMvP9\",\"79x5MJf\",\"9TmFXZ7\",\"tSd1da+\",\"56Auvlv\",\"8y0KoYS\",\"1s\\/Toed\",\"X+gacmF\",\"1I0UazQ\",\"u1+5F9n\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\",\"PageTransitions\",\"Animation\"]},\"be\":1},\"PhotoTags\":{\"r\":[\"7Co8YaN\",\"vl9u8tK\",\"79x5MJf\",\"8y0KoYS\",\"D4\\/LUJw\"],\"be\":1},\"TagTokenizer\":{\"r\":[\"D4\\/LUJw\",\"Yx7rrao\",\"STN5M4f\",\"7Co8YaN\",\"vl9u8tK\",\"Xgq1Lxv\",\"o0Y39To\",\"Zgc+X5s\",\"79x5MJf\",\"SxjllWY\",\"fbi0BbH\",\"gpkNT+D\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"],\"r\":[\"Ta11qxv\"]},\"be\":1},\"AsyncDialog\":{\"r\":[\"8lp8wGa\",\"D4\\/LUJw\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"1I0UazQ\",\"3RPbCsW\",\"o0Y39To\",\"YWKcFNg\",\"d8hh03I\",\"Ftl2VZm\",\"UlKMvP9\",\"79x5MJf\",\"tSd1da+\",\"56Auvlv\",\"SkTd\\/EX\",\"1s\\/Toed\",\"u1+5F9n\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"]},\"be\":1},\"Hovercard\":{\"r\":[\"l+VOICZ\",\"jLGQDLb\",\"D4\\/LUJw\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"Brrx+M7\",\"Xgq1Lxv\",\"EmxYBL+\",\"s\\/iDMuG\",\"o0Y39To\",\"RSIe7aP\",\"YWKcFNg\",\"Ftl2VZm\",\"UlKMvP9\",\"79x5MJf\",\"9TmFXZ7\",\"tSd1da+\",\"56Auvlv\",\"1s\\/Toed\",\"X+gacmF\",\"1I0UazQ\",\"u1+5F9n\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\",\"PageTransitions\",\"Animation\"]},\"be\":1},\"XOfferController\":{\"r\":[\"o0Y39To\",\"xsFg75a\"],\"be\":1},\"PerfXSharedFields\":{\"r\":[\"ahJN284\",\"79x5MJf\"],\"be\":1},\"Dialog\":{\"r\":[\"jLGQDLb\",\"D4\\/LUJw\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"o0Y39To\",\"jGcZiJF\",\"0aFZxyL\",\"YWKcFNg\",\"UlKMvP9\",\"79x5MJf\",\"56Auvlv\",\"Ftl2VZm\",\"tSd1da+\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\",\"Animation\",\"PageTransitions\"]},\"be\":1},\"ExceptionDialog\":{\"r\":[\"8lp8wGa\",\"D4\\/LUJw\",\"7Co8YaN\",\"3RPbCsW\",\"rZxjZO8\",\"o0Y39To\",\"wgltd+W\",\"L6ciEh1\",\"RSIe7aP\",\"YWKcFNg\",\"d8hh03I\",\"Ftl2VZm\",\"UlKMvP9\",\"79x5MJf\",\"tSd1da+\",\"K1WZ7sC\",\"56Auvlv\",\"YbUEA0a\",\"SkTd\\/EX\",\"1s\\/Toed\",\"Ta11qxv\",\"p5KjQo3\",\"1I0UazQ\",\"u1+5F9n\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"]},\"be\":1},\"QuickSandSolver\":{\"r\":[\"SWx3yNv\",\"p5KjQo3\",\"Ta11qxv\",\"QqR5QSj\",\"o0Y39To\",\"x22Oby4\",\"79x5MJf\",\"gv7KP21\",\"8ELCBwH\",\"D4\\/LUJw\"],\"rds\":{\"m\":[\"FbtLogging\",\"IntlQtEventFalcoEvent\"]},\"be\":1},\"ConfirmationDialog\":{\"r\":[\"7Co8YaN\",\"I+GHswV\",\"o0Y39To\",\"1vsm6IY\",\"79x5MJf\",\"D4\\/LUJw\"],\"be\":1},\"MWADeveloperReauthBarrier\":{\"r\":[\"H\\/5lfuF\",\"17Grp2h\",\"79x5MJf\",\"QyoftxH\",\"QIamfde\"],\"be\":1},\"VultureJSSampleRatesLoader\":{\"r\":[\"K1pGhOF\"],\"be\":1},\"react\":{\"r\":[\"Ftl2VZm\",\"tSd1da+\"],\"be\":1}}})});</script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"InitialJSLoader\"], function(InitialJSLoader) {InitialJSLoader.loadOnDOMContentReady([\"ZH5DRAM\",\"Ta11qxv\",\"79x5MJf\",\"8lp8wGa\",\"o0Y39To\",\"I8zzdEO\",\"p5KjQo3\",\"YWKcFNg\",\"Ftl2VZm\",\"tSd1da+\",\"jLGQDLb\",\"7Co8YaN\",\"9Hl4kP7\",\"d8hh03I\",\"UlKMvP9\",\"qnlaxic\",\"jUx4Er3\",\"WlWA5Yc\",\"v3LJVPf\",\"\\/\\/za25u\",\"56Auvlv\",\"a6hDdEq\",\"HLEgydM\",\"1s\\/Toed\",\"1I0UazQ\",\"u1+5F9n\",\"vCxI9D4\"]);});</script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"TimeSliceImpl\",\"ServerJS\"],function(TimeSlice,ServerJS){var s=(new ServerJS());s.handle({\"define\":[[\"cr:734\",[],{\"__rc\":[null,null]},-1],[\"cr:1293\",[\"ReactDOM.classic\"],{\"__rc\":[\"ReactDOM.classic\",null]},-1],[\"cr:3473\",[\"unmountComponentOnTransition\"],{\"__rc\":[\"unmountComponentOnTransition\",null]},-1],[\"cr:3603\",[\"unmountConcurrentComponentOnTransition\"],{\"__rc\":[\"unmountConcurrentComponentOnTransition\",null]},-1],[\"cr:7162\",[\"ReactDOMCompatibilityLayer\"],{\"__rc\":[\"ReactDOMCompatibilityLayer\",null]},-1],[\"cr:1108857\",[],{\"__rc\":[null,null]},-1],[\"cr:1294158\",[\"React.classic\"],{\"__rc\":[\"React.classic\",null]},-1],[\"cr:1294159\",[\"ReactDOM.classic\"],{\"__rc\":[\"ReactDOM.classic\",null]},-1],[\"cr:755\",[\"warningWWW\"],{\"__rc\":[\"warningWWW\",null]},-1],[\"cr:757\",[\"ImageWwwCssDependency\"],{\"__rc\":[\"ImageWwwCssDependency\",null]},-1],[\"cr:4655\",[\"AbstractLinkLynxMode\"],{\"__rc\":[\"AbstractLinkLynxMode\",null]},-1],[\"cr:5662\",[\"Event\"],{\"__rc\":[\"Event\",null]},-1],[\"ClickIDURLBlocklistSVConfig\",[],{\"block_list_url\":[\"https:\\/\\/www.youtube.com\\/watch?v=f1J38FlDKxo\",\"https:\\/\\/www.youtube.com\\/watch?v=6xt7nTuO85A\"]},7631],[\"FBDomainsSVConfig\",[],{\"domains\":{\"__map\":[[\"www.facebook.com\",1],[\"tfbnw.net\",1],[\"m.beta.facebook.com\",1],[\"touch.beta.facebook.com\",1],[\"www.dev.facebook.com\",1],[\"fb.me\",1],[\"s.fb.com\",1],[\"m.fbjs.facebook.com\",1],[\"facebook.com.es\",1],[\"www.fbjs.facebook.com\",1],[\"m.facebook.com\",1],[\"facebook.fr\",1],[\"fbsbx.com\",1],[\"embed.fbsbx.com\",1],[\"attachment.fbsbx.com\",1],[\"lookaside.fbsbx.com\",1],[\"web.facebook.com\",1],[\"fb.com\",1],[\"messenger.com\",1],[\"secure.facebook.com\",1],[\"secure.my-od.facebook.com\",1],[\"www.my-od.facebook.com\",1]]}},3828],[\"ClickIDDomainBlacklistSVConfig\",[],{\"domains\":[\"craigslist\",\"tfbnw.net\",\"canadiantire.ca\",\"o2.co.uk\",\"archive.org\",\"reddit.com\",\"redd.it\",\"gmail.com\",\"cvk.gov.ua\",\"electoralsearch.in\",\"yahoo.com\",\"cve.mitre.org\",\"usenix.org\",\"ky.gov\",\"voteohio.gov\",\"vote.pa.gov\",\"oversightboard.com\",\"wi.gov\",\"pbs.twimg.com\",\"media.discordapp.net\",\"vastadeal.com\",\"theaustralian.com.au\",\"alloygator.com\",\"elsmannimmobilien.de\",\"news.com.au\",\"dennisbonnen.com\",\"stoett.com\",\"investorhour.com\",\"perspectivasur.com\",\"bonnegueule.fr\",\"firstent.org\",\"twitpic.com\",\"kollosche.com.au\",\"nau.edu\",\"arcourts.gov\",\"lomberg.de\",\"network4.hu\",\"balloonrace.com\",\"awstrack.me\",\"ic3.gov\",\"sos.wyo.gov\",\"cnpq.br\",\"0.discoverapp.com\",\"apple.com\",\"apple.co\",\"applecard.apple\",\"services.apple\",\"appletvplus.com\",\"applepay.apple\",\"wallet.apple\",\"beatsbydre.com\",\"dinn.com.mx\",\"soriana.com\",\"facebook.sso.datasite.com\",\"fycextras.com\",\"rik.parlament.gov.rs\",\"elections.delaware.gov\",\"dge.sn\"]},3829],[\"cr:5277\",[\"ReactDOM.classic.prod-or-profiling\"],{\"__rc\":[\"ReactDOM.classic.prod-or-profiling\",null]},-1],[\"cr:1292365\",[\"React-prod.classic\"],{\"__rc\":[\"React-prod.classic\",null]},-1],[\"cr:2682\",[\"warningBlueish\"],{\"__rc\":[\"warningBlueish\",null]},-1],[\"cr:11202\",[],{\"__rc\":[null,null]},-1],[\"cr:1105154\",[],{\"__rc\":[null,null]},-1],[\"cr:7736\",[\"FBLynxLogging\"],{\"__rc\":[\"FBLynxLogging\",null]},-1],[\"cr:5278\",[\"ReactDOM-prod.classic\"],{\"__rc\":[\"ReactDOM-prod.classic\",null]},-1],[\"cr:2683\",[\"warningBlue\"],{\"__rc\":[\"warningBlue\",null]},-1],[\"cr:5695\",[\"EventListenerWWW\"],{\"__rc\":[\"EventListenerWWW\",null]},-1],[\"cr:8909\",[\"ReactFiberErrorDialogWWW\"],{\"__rc\":[\"ReactFiberErrorDialogWWW\",null]},-1],[\"cr:3695\",[],{\"__rc\":[null,null]},-1],[\"cr:983844\",[],{\"__rc\":[null,null]},-1],[\"CoreWarningGK\",[],{\"forceWarning\":false},725],[\"cr:1353359\",[\"EventListenerImplForBlue\"],{\"__rc\":[\"EventListenerImplForBlue\",null]},-1],[\"LinkshimHandlerConfig\",[],{\"supports_meta_referrer\":false,\"default_meta_referrer_policy\":\"default\",\"switched_meta_referrer_policy\":\"origin\",\"non_linkshim_lnfb_mode\":\"ie\",\"link_react_default_hash\":\"AT2qvZnGVHynure614C_c4g1kin5C-4KfcrbSdaUt_1F7pfVezJebXwPCkyIzA-HiOro9kITh9qSWwn9mFRr748AfdsZjSEipcS4FtBPQL2qrQ1bF9j3K5adebF-F9uHz5oU3D9MyEy7qBbp9QelXcollw-qPr0s\",\"untrusted_link_default_hash\":\"AT1apQ6Uqsfmf6XOYx8Zgj5JDgjte779MyKoke3s1lbSxO4LY9igLtPXY-O5-pRrUoPYNNM6QnoAbraPL7WZQplZO8TS4mMDNKnYKMGLpwKDomSgtFDH40tvxBPemO4V0agmw3_LMHyaZJnyGoq-V78K10_CBD-Y\",\"linkshim_host\":\"l.facebook.com\",\"linkshim_path\":\"\\/l.php\",\"linkshim_enc_param\":\"h\",\"linkshim_url_param\":\"u\",\"use_rel_no_opener\":false,\"use_rel_no_referrer\":false,\"always_use_https\":false,\"onion_always_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null,\"ghl_param_link_shim\":false,\"click_ids\":null,\"is_linkshim_supported\":false,\"current_domain\":\"ai.meta.com\",\"blocklisted_domains\":[\"ad.doubleclick.net\",\"ads-encryption-url-example.com\",\"bs.serving-sys.com\",\"ad.atdmt.com\",\"adform.net\",\"ad13.adfarm1.adition.com\",\"ilovemyfreedoms.com\",\"secure.adnxs.com\"],\"is_mobile_device\":false},27]],\"instances\":[[\"__inst_363d94e1_0_0_q6\",[\"AIDropdownNavConfig\",\"__inst_44019d09_0_0_Ru\",\"__inst_7f4ae79a_0_0_yr\",\"__inst_7f4ae79a_0_1_b9\",\"__inst_7f4ae79a_0_2_xc\",\"__inst_24928c59_0_0_jK\",\"__inst_24928c59_0_1_Zt\",\"__inst_24928c59_0_2_IR\",\"__inst_e703d034_0_0_vH\"],[{\"__m\":\"__inst_44019d09_0_0_Ru\"},[{\"__m\":\"__inst_7f4ae79a_0_0_yr\"},{\"__m\":\"__inst_7f4ae79a_0_1_b9\"},{\"__m\":\"__inst_7f4ae79a_0_2_xc\"},{\"__m\":\"__inst_24928c59_0_0_jK\"},{\"__m\":\"__inst_24928c59_0_1_Zt\"},{\"__m\":\"__inst_24928c59_0_2_IR\"}],{\"__m\":\"__inst_e703d034_0_0_vH\"}],1],[\"__inst_7de61f26_0_0_qB\",[\"AIDropdownNavXMLTConfig\",\"__inst_44019d09_0_1_RC\",\"__inst_7f4ae79a_0_3_hs\",\"__inst_7f4ae79a_0_4_g8\",\"__inst_7f4ae79a_0_5_w5\",\"__inst_24928c59_0_3_eZ\",\"__inst_24928c59_0_4_Ej\",\"__inst_24928c59_0_5_Go\",\"__inst_e703d034_0_1_ta\"],[{\"logoLink\":{\"__m\":\"__inst_44019d09_0_1_RC\"},\"navItems\":[{\"__m\":\"__inst_7f4ae79a_0_3_hs\"},{\"__m\":\"__inst_7f4ae79a_0_4_g8\"},{\"__m\":\"__inst_7f4ae79a_0_5_w5\"},{\"__m\":\"__inst_24928c59_0_3_eZ\"},{\"__m\":\"__inst_24928c59_0_4_Ej\"},{\"__m\":\"__inst_24928c59_0_5_Go\"}],\"position\":null,\"searchLink\":{\"__m\":\"__inst_e703d034_0_1_ta\"},\"align\":\"left\"}],1],[\"__inst_f1d0759c_0_0_1F\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_0_Tj\",\"__elem_a588f507_0_1_gh\",\"__elem_94c15385_0_0_c4\",\"__elem_94c15385_0_1_tZ\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_0_Tj\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_1_gh\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_0_c4\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_1_tZ\"},\"initOpen\":false,\"variant\":\"meta-ai-footer\"}],1],[\"__inst_f1d0759c_0_1_nm\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_2_TP\",\"__elem_a588f507_0_3_zD\",\"__elem_94c15385_0_2_Py\",\"__elem_94c15385_0_3_Iv\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_2_TP\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_3_zD\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_2_Py\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_3_Iv\"},\"initOpen\":false,\"variant\":\"meta-ai-footer\"}],1],[\"__inst_f1d0759c_0_2_Hj\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_4_au\",\"__elem_a588f507_0_5_v0\",\"__elem_94c15385_0_4_uX\",\"__elem_94c15385_0_5_Jg\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_4_au\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_5_v0\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_4_uX\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_5_Jg\"},\"initOpen\":false,\"variant\":\"meta-ai-footer\"}],1],[\"__inst_f1d0759c_0_3_YR\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_6_zI\",\"__elem_a588f507_0_7_H2\",\"__elem_94c15385_0_6_QH\",\"__elem_94c15385_0_7_tT\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_6_zI\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_7_H2\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_6_QH\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_7_tT\"},\"initOpen\":false,\"variant\":\"meta-ai-footer\"}],1],[\"__inst_f1d0759c_0_4_c5\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_8_CK\",\"__elem_a588f507_0_9_bK\",\"__elem_94c15385_0_8_uh\",\"__elem_94c15385_0_9_91\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_8_CK\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_9_bK\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_8_uh\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_9_91\"},\"initOpen\":false,\"variant\":\"meta-ai-footer\"}],1],[\"__inst_f1d0759c_0_5_wl\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_a_ZF\",\"__elem_a588f507_0_b_\\/+\",\"__elem_94c15385_0_a_jG\",\"__elem_94c15385_0_b_ia\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_a_ZF\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_b_\\/+\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_a_jG\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_b_ia\"},\"initOpen\":false,\"variant\":\"default\"}],1],[\"__inst_f1d0759c_0_6_WT\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_c_8\\/\",\"__elem_a588f507_0_d_mO\",\"__elem_94c15385_0_c_CG\",\"__elem_94c15385_0_d_Vk\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_c_8\\/\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_d_mO\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_c_CG\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_d_Vk\"},\"initOpen\":false,\"variant\":\"default\"}],1],[\"__inst_f1d0759c_0_7_qF\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_e_Rl\",\"__elem_a588f507_0_f_PJ\",\"__elem_94c15385_0_e_2w\",\"__elem_94c15385_0_f_2Z\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_e_Rl\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_f_PJ\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_e_2w\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_f_2Z\"},\"initOpen\":false,\"variant\":\"default\"}],1],[\"__inst_f1d0759c_0_8_7k\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_g_C5\",\"__elem_a588f507_0_h_YA\",\"__elem_94c15385_0_g_6m\",\"__elem_94c15385_0_h_lz\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_g_C5\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_h_YA\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_g_6m\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_h_lz\"},\"initOpen\":false,\"variant\":\"default\"}],1],[\"__inst_f1d0759c_0_9_FE\",[\"FBAIExpandableItem\",\"__elem_a588f507_0_i_Ne\",\"__elem_a588f507_0_j_6f\",\"__elem_94c15385_0_i_Gh\",\"__elem_94c15385_0_j_Kr\"],[{\"title\":{\"__m\":\"__elem_a588f507_0_i_Ne\"},\"contentArea\":{\"__m\":\"__elem_a588f507_0_j_6f\"},\"expandButton\":{\"__m\":\"__elem_94c15385_0_i_Gh\"},\"collapseButton\":{\"__m\":\"__elem_94c15385_0_j_Kr\"},\"initOpen\":false,\"variant\":\"default\"}],1],[\"__inst_44019d09_0_0_Ru\",[\"AboutFBNavLogoLinkConfig\"],[\"\\/\",\"Meta\",\"link\",\"nav-bar_meta-logo\",\"https:\\/\\/scontent-mxp1-1.xx.fbcdn.net\\/v\\/t39.8562-6\\/252294889_575082167077436_6034106545912333281_n.svg\\/meta-logo-primary_standardsize.svg?_nc_cat=1&ccb=1-7&_nc_sid=e280be&_nc_ohc=q-hF1w5dzNAQ7kNvgETZYhl&_nc_zt=14&_nc_ht=scontent-mxp1-1.xx&_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&oh=00_AYAdLO5rfo3T4eVdjTlskSNwnFbjQoOpnPlcHL6qaLkU6Q&oe=6775E279\",89,18],1],[\"__inst_7f4ae79a_0_0_yr\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_0_MU\"],[\"Our approach\",{\"__m\":\"__inst_d066f191_0_0_MU\"},[\"Our approach\"],\"click_menu\",\"nav_our-approach\",null,null,null,null],1],[\"__inst_7f4ae79a_0_1_b9\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_1_PE\"],[\"Research\",{\"__m\":\"__inst_d066f191_0_1_PE\"},[\"Research\"],\"click_menu\",\"nav_research\",null,null,null,null],1],[\"__inst_7f4ae79a_0_2_xc\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_2_Mn\"],[\"Product experiences\",{\"__m\":\"__inst_d066f191_0_2_Mn\"},[\"Product experiences\"],\"click_menu\",\"nav_product_experiences\",null,null,null,null],1],[\"__inst_24928c59_0_0_jK\",[\"AIDropdownNavLinkConfig\"],[\"Llama\",\"https:\\/\\/llama.meta.com\",\"inherit\",\"open-in-new-tab\",[\"Llama\"],null,\"click_menu\",\"nav_llama-homepage\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_1_Zt\",[\"AIDropdownNavLinkConfig\"],[\"Blog\",\"\\/blog\\/\",\"inherit\",\"open-in-current-tab\",[\"Blog\"],null,\"click_menu\",\"nav_blog\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_2_IR\",[\"AIDropdownNavLinkConfig\"],[\"Try Meta AI\",\"https:\\/\\/www.meta.ai\\/?utm_source=ai_meta_site&utm_medium=web&utm_content=AI_nav&utm_campaign=April_moment\",\"inherit\",\"open-in-new-tab\",[\"Try Meta AI\"],null,\"click_menu\",\"nav_try-meta-ai\",\"blue-pill-cta-large\",\"underline\"],1],[\"__inst_e703d034_0_0_vH\",[\"AIDropdownNavSearchLinkConfig\",\"__inst_746f571f_0_0_yP\"],[\"Search\",{\"__m\":\"__inst_746f571f_0_0_yP\"},\"click_menu\",\"search\"],1],[\"__inst_44019d09_0_1_RC\",[\"AboutFBNavLogoLinkConfig\"],[\"\\/\",\"Meta\",\"link\",\"nav-bar_meta-logo\",\"https:\\/\\/scontent-mxp1-1.xx.fbcdn.net\\/v\\/t39.8562-6\\/252294889_575082167077436_6034106545912333281_n.svg\\/meta-logo-primary_standardsize.svg?_nc_cat=1&ccb=1-7&_nc_sid=e280be&_nc_ohc=q-hF1w5dzNAQ7kNvgETZYhl&_nc_zt=14&_nc_ht=scontent-mxp1-1.xx&_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&oh=00_AYAdLO5rfo3T4eVdjTlskSNwnFbjQoOpnPlcHL6qaLkU6Q&oe=6775E279\",89,18],1],[\"__inst_7f4ae79a_0_3_hs\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_3_A3\"],[\"Our approach\",{\"__m\":\"__inst_d066f191_0_3_A3\"},[\"Our approach\"],\"click_menu\",\"nav_our-approach\",null,null,null,null],1],[\"__inst_7f4ae79a_0_4_g8\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_4_w5\"],[\"Research\",{\"__m\":\"__inst_d066f191_0_4_w5\"},[\"Research\"],\"click_menu\",\"nav_research\",null,null,null,null],1],[\"__inst_7f4ae79a_0_5_w5\",[\"AIDropdownNavMenuConfig\",\"__inst_d066f191_0_5_EB\"],[\"Product experiences\",{\"__m\":\"__inst_d066f191_0_5_EB\"},[\"Product experiences\"],\"click_menu\",\"nav_product_experiences\",null,null,null,null],1],[\"__inst_24928c59_0_3_eZ\",[\"AIDropdownNavLinkConfig\"],[\"Llama\",\"https:\\/\\/llama.meta.com\",\"inherit\",\"open-in-new-tab\",[\"Llama\"],null,\"click_menu\",\"nav_llama-homepage\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_4_Ej\",[\"AIDropdownNavLinkConfig\"],[\"Blog\",\"\\/blog\\/\",\"inherit\",\"open-in-current-tab\",[\"Blog\"],null,\"click_menu\",\"nav_blog\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_5_Go\",[\"AIDropdownNavLinkConfig\"],[\"Try Meta AI\",\"https:\\/\\/www.meta.ai\\/?utm_source=ai_meta_site&utm_medium=web&utm_content=AI_nav&utm_campaign=April_moment\",\"inherit\",\"open-in-new-tab\",[\"Try Meta AI\"],null,\"click_menu\",\"nav_try-meta-ai\",\"blue-pill-cta-large\",\"underline\"],1],[\"__inst_e703d034_0_1_ta\",[\"AIDropdownNavSearchLinkConfig\",\"__inst_746f571f_0_1_PL\"],[\"Search\",{\"__m\":\"__inst_746f571f_0_1_PL\"},\"click_menu\",\"search\"],1],[\"__inst_d066f191_0_0_MU\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_6_03\",\"__inst_24928c59_0_7_4P\",\"__inst_24928c59_0_8_kU\",\"__inst_24928c59_0_9_l3\"],[null,null,[{\"__m\":\"__inst_24928c59_0_6_03\"},{\"__m\":\"__inst_24928c59_0_7_4P\"},{\"__m\":\"__inst_24928c59_0_8_kU\"},{\"__m\":\"__inst_24928c59_0_9_l3\"}],[\"Our approach\"],null],1],[\"__inst_d066f191_0_1_PE\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_a_ax\",\"__inst_24928c59_0_b_\\/p\",\"__inst_24928c59_0_c_ys\",\"__inst_24928c59_0_d_CL\"],[null,null,[{\"__m\":\"__inst_24928c59_0_a_ax\"},{\"__m\":\"__inst_24928c59_0_b_\\/p\"},{\"__m\":\"__inst_24928c59_0_c_ys\"},{\"__m\":\"__inst_24928c59_0_d_CL\"}],[\"Research\"],null],1],[\"__inst_d066f191_0_2_Mn\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_e_CL\",\"__inst_24928c59_0_f_Ke\"],[null,null,[{\"__m\":\"__inst_24928c59_0_e_CL\"},{\"__m\":\"__inst_24928c59_0_f_Ke\"}],[\"Product experiences\"],null],1],[\"__inst_746f571f_0_0_yP\",[\"AIDropdownNavMenuSearchSectionConfig\"],[\"Search AI content\",\"\\/global_search\\/\"],1],[\"__inst_d066f191_0_3_A3\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_g_Jm\",\"__inst_24928c59_0_h_D3\",\"__inst_24928c59_0_i_A\\/\",\"__inst_24928c59_0_j_Km\"],[null,null,[{\"__m\":\"__inst_24928c59_0_g_Jm\"},{\"__m\":\"__inst_24928c59_0_h_D3\"},{\"__m\":\"__inst_24928c59_0_i_A\\/\"},{\"__m\":\"__inst_24928c59_0_j_Km\"}],[\"Our approach\"],null],1],[\"__inst_d066f191_0_4_w5\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_k_X1\",\"__inst_24928c59_0_l_Rw\",\"__inst_24928c59_0_m_\\/y\",\"__inst_24928c59_0_n_Wx\"],[null,null,[{\"__m\":\"__inst_24928c59_0_k_X1\"},{\"__m\":\"__inst_24928c59_0_l_Rw\"},{\"__m\":\"__inst_24928c59_0_m_\\/y\"},{\"__m\":\"__inst_24928c59_0_n_Wx\"}],[\"Research\"],null],1],[\"__inst_d066f191_0_5_EB\",[\"AIDropdownNavMenuSectionConfig\",\"__inst_24928c59_0_o_bT\",\"__inst_24928c59_0_p_kW\"],[null,null,[{\"__m\":\"__inst_24928c59_0_o_bT\"},{\"__m\":\"__inst_24928c59_0_p_kW\"}],[\"Product experiences\"],null],1],[\"__inst_746f571f_0_1_PL\",[\"AIDropdownNavMenuSearchSectionConfig\"],[\"Search AI content\",\"\\/global_search\\/\"],1],[\"__inst_24928c59_0_6_03\",[\"AIDropdownNavLinkConfig\"],[\"About us\",\"\\/about\\/\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"About us\"],null,\"click_menu\",\"nav_about-us\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_7_4P\",[\"AIDropdownNavLinkConfig\"],[\"Responsibility\",\"\\/responsible-ai\\/\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"Responsibility\"],null,\"click_menu\",\"nav_responsible-ai\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_8_kU\",[\"AIDropdownNavLinkConfig\"],[\"People\",\"\\/results\\/?content_types\\u00255B0\\u00255D=person\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"People\"],null,\"click_menu\",\"nav_results-people\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_9_l3\",[\"AIDropdownNavLinkConfig\"],[\"Careers\",\"https:\\/\\/www.metacareers.com\\/\",\"inherit\",\"open-in-new-tab\",[\"Our approach\",\"Careers\"],null,\"click_menu\",\"nav_careers\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_a_ax\",[\"AIDropdownNavLinkConfig\"],[\"Overview\",\"\\/research\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Overview\"],null,\"click_menu\",\"nav_research-overview\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_b_\\/p\",[\"AIDropdownNavLinkConfig\"],[\"Infrastructure\",\"\\/infrastructure\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Infrastructure\"],null,\"click_menu\",\"nav_infrastructure\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_c_ys\",[\"AIDropdownNavLinkConfig\"],[\"Resources\",\"\\/resources\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Resources\"],null,\"click_menu\",\"nav_resources\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_d_CL\",[\"AIDropdownNavLinkConfig\"],[\"Demos\",\"https:\\/\\/aidemos.meta.com\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Demos\"],null,\"click_menu\",\"nav_resources-demos\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_e_CL\",[\"AIDropdownNavLinkConfig\"],[\"Meta AI\",\"\\/meta-ai\\/\",\"inherit\",\"open-in-current-tab\",[\"Product experiences\",\"Meta AI\"],null,\"click_menu\",\"nav_meta_ai\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_f_Ke\",[\"AIDropdownNavLinkConfig\"],[\"AI Studio\",\"\\/ai-studio\\/\",\"inherit\",\"open-in-current-tab\",[\"Product experiences\",\"AI Studio\"],null,\"click_menu\",\"nav_ai_studio\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_g_Jm\",[\"AIDropdownNavLinkConfig\"],[\"About us\",\"\\/about\\/\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"About us\"],null,\"click_menu\",\"nav_about-us\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_h_D3\",[\"AIDropdownNavLinkConfig\"],[\"Responsibility\",\"\\/responsible-ai\\/\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"Responsibility\"],null,\"click_menu\",\"nav_responsible-ai\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_i_A\\/\",[\"AIDropdownNavLinkConfig\"],[\"People\",\"\\/results\\/?content_types\\u00255B0\\u00255D=person\",\"inherit\",\"open-in-current-tab\",[\"Our approach\",\"People\"],null,\"click_menu\",\"nav_results-people\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_j_Km\",[\"AIDropdownNavLinkConfig\"],[\"Careers\",\"https:\\/\\/www.metacareers.com\\/\",\"inherit\",\"open-in-new-tab\",[\"Our approach\",\"Careers\"],null,\"click_menu\",\"nav_careers\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_k_X1\",[\"AIDropdownNavLinkConfig\"],[\"Overview\",\"\\/research\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Overview\"],null,\"click_menu\",\"nav_research-overview\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_l_Rw\",[\"AIDropdownNavLinkConfig\"],[\"Infrastructure\",\"\\/infrastructure\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Infrastructure\"],null,\"click_menu\",\"nav_infrastructure\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_m_\\/y\",[\"AIDropdownNavLinkConfig\"],[\"Resources\",\"\\/resources\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Resources\"],null,\"click_menu\",\"nav_resources\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_n_Wx\",[\"AIDropdownNavLinkConfig\"],[\"Demos\",\"https:\\/\\/aidemos.meta.com\\/\",\"inherit\",\"open-in-current-tab\",[\"Research\",\"Demos\"],null,\"click_menu\",\"nav_resources-demos\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_o_bT\",[\"AIDropdownNavLinkConfig\"],[\"Meta AI\",\"\\/meta-ai\\/\",\"inherit\",\"open-in-current-tab\",[\"Product experiences\",\"Meta AI\"],null,\"click_menu\",\"nav_meta_ai\",\"default\",\"underline\"],1],[\"__inst_24928c59_0_p_kW\",[\"AIDropdownNavLinkConfig\"],[\"AI Studio\",\"\\/ai-studio\\/\",\"inherit\",\"open-in-current-tab\",[\"Product experiences\",\"AI Studio\"],null,\"click_menu\",\"nav_ai_studio\",\"default\",\"underline\"],1]],\"markup\":[[\"__markup_97adea0c_0_0_Mn\",{\"__html\":\"\\u003Cp class=\\\"_8w6f _8xm4 _8w61 _8w6h\\\">Alignment is a procedure to fine-tune pre-trained large language models (LLMs) to follow natural language instructions and serve as helpful AI assistants. We have observed, however, that the conventional alignment process fails to enhance the factual accuracy of LLMs, and often leads to the generation of more false facts (i.e., hallucination). In this paper, we study how to make the LLM alignment process more factual, by first identifying factors that lead to hallucination in both alignment steps: supervised fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that training the LLM on new or unfamiliar knowledge can encourage hallucination. This makes SFT less factual as it trains on human-labeled data that may be novel to the LLM. Furthermore, reward functions used in standard RL often inadequately capture factuality and favor longer and more detailed responses, which inadvertently promote hallucination. Based on these observations, we propose FactuaLity-aware AlignMEnt, comprised of factuality-aware SFT and factuality-aware RL through direct preference optimization. Experiments show that our proposed FLAME guides LLMs to output more factual responses while maintaining their instruction-following capability.\\u003C\\/p>\"},1,\"HTML\"],[\"__markup_97adea0c_0_1_PQ\",{\"__html\":\"\\u003Cp class=\\\"_8w6f _8xm4 _8w61 _8w6h\\\">Memory layers use a trainable key-value lookup mechanism to add extra parameters to a model without increasing FLOPs. Conceptually, sparsely activated memory layers complement compute-heavy dense feed-forward layers, providing dedicated capacity to store and retrieve information cheaply. This work takes memory layers beyond proof-of-concept, proving their utility at contemporary scale. On downstream tasks, language models augmented with our improved memory layer outperform dense models with more than twice the computation budget, as well as mixture-of-expert models when matched for both compute and parameters. We find gains are especially pronounced for factual tasks. We provide a fully parallelizable memory layer implementation, demonstrating scaling laws with up to 128B memory parameters, pretrained to 1 trillion tokens, comparing to base models with up to 8B parameters.\\u003C\\/p>\"},1,\"HTML\"],[\"__markup_97adea0c_0_2_y\\/\",{\"__html\":\"\\u003Cp class=\\\"_8w6f _8xm4 _8w61 _8w6h\\\">We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented dynamically based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first flop controlled scaling study of byte-level models up to 8B parameters with 4T training bytes. Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.\\u003C\\/p>\"},1,\"HTML\"],[\"__markup_97adea0c_0_3_vu\",{\"__html\":\"\\u003Cp class=\\\"_8w6f _8xm4 _8w61 _8w6h\\\">Do large language models (LLMs) have theory of mind? A plethora of papers and benchmarks have\\nbeen introduced to evaluate if current models have been able to develop this key ability of social\\nintelligence. However, all rely on limited datasets with simple patterns that can potentially lead to\\nproblematic blind spots in evaluation and an overestimation of model capabilities. We introduce\\nExploreToM, the first framework to allow large-scale generation of diverse and challenging theory\\nof mind data for robust training and evaluation. Our approach leverages an A* search over a custom\\ndomain-specific language to produce complex story structures and novel, diverse, yet plausible scenarios\\nto stress test the limits of LLMs. Our evaluation reveals that state-of-the-art LLMs, such as Llama-\\n3.1-70B and GPT-4o, show accuracies as low as 5\\u0025 on ExploreToM-generated data, highlighting\\nthe need for more robust theory of mind evaluation. As our generations are a conceptual superset\\nof prior work, fine-tuning on our data yields a 27-point accuracy improvement on the classic ToMi\\nbenchmark (Le et al., 2019). ExploreToM also enables uncovering underlying skills and factors\\nmissing for models to show theory of mind, such as unreliable state tracking or data imbalances, which\\nmay contribute to models\\u2019 poor performance on benchmarks.\\u003C\\/p>\"},1,\"HTML\"]],\"elements\":[[\"__elem_c37bd704_0_0_xB\",\"u_0_0_J3\",1],[\"__elem_c37bd704_0_1_mS\",\"u_0_1_Jz\",1],[\"__elem_fc9f538f_0_0_ip\",\"u_0_2_kl\",1],[\"__elem_a588f507_0_k_ou\",\"u_0_3_Qu\",1],[\"__elem_a588f507_0_l_zw\",\"u_0_4_EM\",1],[\"__elem_a588f507_0_m_ew\",\"u_0_5_hq\",1],[\"__elem_a588f507_0_n_rl\",\"u_0_6_aJ\",1],[\"__elem_072b8e64_0_0_dR\",\"join-us_publication\",1],[\"__elem_a588f507_0_0_Tj\",\"u_0_7_KV\",1],[\"__elem_94c15385_0_0_c4\",\"u_0_8_HO\",1],[\"__elem_94c15385_0_1_tZ\",\"u_0_9_EV\",1],[\"__elem_a588f507_0_1_gh\",\"u_0_a_q5\",1],[\"__elem_a588f507_0_2_TP\",\"u_0_b_su\",1],[\"__elem_94c15385_0_2_Py\",\"u_0_c_Hc\",1],[\"__elem_94c15385_0_3_Iv\",\"u_0_d_CT\",1],[\"__elem_a588f507_0_3_zD\",\"u_0_e_zP\",1],[\"__elem_a588f507_0_4_au\",\"u_0_f_R\\/\",1],[\"__elem_94c15385_0_4_uX\",\"u_0_g_x9\",1],[\"__elem_94c15385_0_5_Jg\",\"u_0_h_xH\",1],[\"__elem_a588f507_0_5_v0\",\"u_0_i_E+\",1],[\"__elem_a588f507_0_6_zI\",\"u_0_j_eR\",1],[\"__elem_94c15385_0_6_QH\",\"u_0_k_c8\",1],[\"__elem_94c15385_0_7_tT\",\"u_0_l_NL\",1],[\"__elem_a588f507_0_7_H2\",\"u_0_m_YD\",1],[\"__elem_a588f507_0_8_CK\",\"u_0_n_Zb\",1],[\"__elem_94c15385_0_8_uh\",\"u_0_o_qQ\",1],[\"__elem_94c15385_0_9_91\",\"u_0_p_oU\",1],[\"__elem_a588f507_0_9_bK\",\"u_0_q_bj\",1],[\"__elem_de0251b4_0_0_AE\",\"u_0_r_ma\",1],[\"__elem_fc9f538f_0_1_wh\",\"u_0_s_j5\",1],[\"__elem_a588f507_0_a_ZF\",\"u_0_t_59\",1],[\"__elem_94c15385_0_a_jG\",\"u_0_u_Cm\",1],[\"__elem_94c15385_0_b_ia\",\"u_0_v_dW\",1],[\"__elem_a588f507_0_b_\\/+\",\"u_0_w_xm\",1],[\"__elem_a588f507_0_c_8\\/\",\"u_0_x_FI\",1],[\"__elem_94c15385_0_c_CG\",\"u_0_y_M7\",1],[\"__elem_94c15385_0_d_Vk\",\"u_0_z_jJ\",1],[\"__elem_a588f507_0_d_mO\",\"u_0_10_F\\/\",1],[\"__elem_a588f507_0_e_Rl\",\"u_0_11_oR\",1],[\"__elem_94c15385_0_e_2w\",\"u_0_12_Pc\",1],[\"__elem_94c15385_0_f_2Z\",\"u_0_13_pn\",1],[\"__elem_a588f507_0_f_PJ\",\"u_0_14_+5\",1],[\"__elem_a588f507_0_g_C5\",\"u_0_15_yo\",1],[\"__elem_94c15385_0_g_6m\",\"u_0_16_xg\",1],[\"__elem_94c15385_0_h_lz\",\"u_0_17_pf\",1],[\"__elem_a588f507_0_h_YA\",\"u_0_18_Ae\",1],[\"__elem_a588f507_0_i_Ne\",\"u_0_19_gh\",1],[\"__elem_94c15385_0_i_Gh\",\"u_0_1a_kL\",1],[\"__elem_94c15385_0_j_Kr\",\"u_0_1b_+p\",1],[\"__elem_a588f507_0_j_6f\",\"u_0_1c_9l\",1]],\"require\":[[\"FBAIDesktopView\",\"initFBAIAnchorlinkScroll\",[],[]],[\"WebPixelRatioDetector\",\"startDetecting\",[],[false]],[\"fbq\",\"init\",[],[\"765371877188948\"]],[\"fbq\",\"init\",[],[\"720048218061799\"]],[\"fbq\",\"track\",[],[\"PageView\"]],[\"ScriptPath\",\"set\",[],[\"MSXAIResearchPublicationEntController\",\"a1f3c513\",{\"imp_id\":\"0SSKVyB8GB6h8t2b8\",\"ef_page\":null,\"uri\":\"https:\\/\\/ai.meta.com\\/research\\/publications\\/large-concept-models-language-modeling-in-a-sentence-representation-space\\/\"}]],[\"react-xhp\",\"constructAndRenderComponentIntoComment_DO_NOT_USE\",[\"AIDropdownNav.react\",\"__inst_363d94e1_0_0_q6\",\"__inst_7de61f26_0_0_qB\",\"__elem_fc9f538f_0_0_ip\"],[{\"constructor\":{\"__m\":\"AIDropdownNav.react\"},\"concurrentRootOptions\":{\"unstable_useShim\":true},\"props\":{\"align\":\"left\",\"config\":{\"__m\":\"__inst_363d94e1_0_0_q6\"},\"fontColor\":null,\"locale\":\"en_US\",\"navFBTs\":{\"closeButtonARIALabel\":\"Close submenu\",\"externalLinkARIALabel\":\"opens in new tab\",\"hamburgerARIALabel\":\"Main menu\",\"prevLinkLabel\":\"BACK\",\"prevLinkARIALabel\":\"Go up one level\",\"searchARIALabel\":\"Toggle site search\",\"searchClearLabel\":\"Clear\",\"searchResultLabel\":\"See all results for a search query\"},\"position\":\"fixed\",\"xmltConfig\":{\"__m\":\"__inst_7de61f26_0_0_qB\"}},\"placeholderElement\":{\"__m\":\"__elem_fc9f538f_0_0_ip\"},\"acrossTransitions\":false,\"clobberSiblings\":false,\"preloader\":null,\"bigPipeContext\":{\"__bigPipeContext\":1},\"nonBlockingPreloaders\":null}]],[\"PaletteAboutFBLinkAria\",\"initLinkAria\",[\"__elem_c37bd704_0_0_xB\"],[{\"element\":{\"__m\":\"__elem_c37bd704_0_0_xB\"},\"newTabFragment\":\"(opens in new tab)\"}]],[\"PaletteAboutFBLinkAria\",\"initLinkAria\",[\"__elem_c37bd704_0_1_mS\"],[{\"element\":{\"__m\":\"__elem_c37bd704_0_1_mS\"},\"newTabFragment\":\"(opens in new tab)\"}]],[\"NonFBLinkReferrerProtector\",\"setupDelegation\",[],[]],[\"FBAIV2BackToTop\",\"onClick\",[\"__elem_de0251b4_0_0_AE\"],[{\"__m\":\"__elem_de0251b4_0_0_AE\"}]],[\"__inst_f1d0759c_0_0_1F\"],[\"__inst_f1d0759c_0_1_nm\"],[\"__inst_f1d0759c_0_2_Hj\"],[\"__inst_f1d0759c_0_3_YR\"],[\"__inst_f1d0759c_0_4_c5\"],[\"__inst_f1d0759c_0_5_wl\"],[\"__inst_f1d0759c_0_6_WT\"],[\"__inst_f1d0759c_0_7_qF\"],[\"__inst_f1d0759c_0_8_7k\"],[\"__inst_f1d0759c_0_9_FE\"],[\"react-xhp\",\"constructAndRenderComponentIntoComment_DO_NOT_USE\",[\"FBAIV2SearchBar.react\",\"__elem_fc9f538f_0_1_wh\"],[{\"constructor\":{\"__m\":\"FBAIV2SearchBar.react\"},\"concurrentRootOptions\":{\"unstable_useShim\":true},\"props\":{\"magnifyingGlassSrc\":\"https:\\/\\/scontent-mxp1-1.xx.fbcdn.net\\/v\\/t39.2365-6\\/85559716_2814260008668824_1992323131183726592_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=spZWCn9UmQoQ7kNvgFLe4Cc&_nc_zt=14&_nc_ht=scontent-mxp1-1.xx&_nc_gid=A3cnAEnd50xmFIpVGIn9xyf&oh=00_AYCUQ1jpvLRA91QgpcBh3bhYaBpToy7xp-fASBaiYCRcKw&oe=678A510F\",\"isFooterStyle\":true},\"placeholderElement\":{\"__m\":\"__elem_fc9f538f_0_1_wh\"},\"acrossTransitions\":false,\"clobberSiblings\":false,\"preloader\":null,\"bigPipeContext\":{\"__bigPipeContext\":1},\"nonBlockingPreloaders\":null}]],[\"FBAIPixelAnalytics\",\"logOnEvent\",[\"__elem_072b8e64_0_0_dR\"],[{\"__m\":\"__elem_072b8e64_0_0_dR\"},\"click\",\"meta-careers\"]],[\"ReactRenderer_DEPRECATED\",\"constructAndRenderComponent_LEGACY\",[\"LineClamp.react\",\"__markup_97adea0c_0_0_Mn\",\"HTML\",\"__elem_a588f507_0_k_ou\"],[{\"__m\":\"LineClamp.react\"},{\"lines\":3,\"lineHeight\":24,\"disableNative\":null,\"fitHeightToShorterText\":null,\"customEllipsis\":null,\"customEllipsisDisableGradient\":null,\"children\":{\"__m\":\"__markup_97adea0c_0_0_Mn\"},\"hasXHPChildren\":true,\"className\":null,\"enableTooltipOnOverflow\":false},{\"__m\":\"__elem_a588f507_0_k_ou\"},\"callsite_d5454955643\"]],[\"ReactRenderer_DEPRECATED\",\"constructAndRenderComponent_LEGACY\",[\"LineClamp.react\",\"__markup_97adea0c_0_1_PQ\",\"HTML\",\"__elem_a588f507_0_l_zw\"],[{\"__m\":\"LineClamp.react\"},{\"lines\":3,\"lineHeight\":24,\"disableNative\":null,\"fitHeightToShorterText\":null,\"customEllipsis\":null,\"customEllipsisDisableGradient\":null,\"children\":{\"__m\":\"__markup_97adea0c_0_1_PQ\"},\"hasXHPChildren\":true,\"className\":null,\"enableTooltipOnOverflow\":false},{\"__m\":\"__elem_a588f507_0_l_zw\"},\"callsite_d5454955643\"]],[\"ReactRenderer_DEPRECATED\",\"constructAndRenderComponent_LEGACY\",[\"LineClamp.react\",\"__markup_97adea0c_0_2_y\\/\",\"HTML\",\"__elem_a588f507_0_m_ew\"],[{\"__m\":\"LineClamp.react\"},{\"lines\":3,\"lineHeight\":24,\"disableNative\":null,\"fitHeightToShorterText\":null,\"customEllipsis\":null,\"customEllipsisDisableGradient\":null,\"children\":{\"__m\":\"__markup_97adea0c_0_2_y\\/\"},\"hasXHPChildren\":true,\"className\":null,\"enableTooltipOnOverflow\":false},{\"__m\":\"__elem_a588f507_0_m_ew\"},\"callsite_d5454955643\"]],[\"ReactRenderer_DEPRECATED\",\"constructAndRenderComponent_LEGACY\",[\"LineClamp.react\",\"__markup_97adea0c_0_3_vu\",\"HTML\",\"__elem_a588f507_0_n_rl\"],[{\"__m\":\"LineClamp.react\"},{\"lines\":3,\"lineHeight\":24,\"disableNative\":null,\"fitHeightToShorterText\":null,\"customEllipsis\":null,\"customEllipsisDisableGradient\":null,\"children\":{\"__m\":\"__markup_97adea0c_0_3_vu\"},\"hasXHPChildren\":true,\"className\":null,\"enableTooltipOnOverflow\":false},{\"__m\":\"__elem_a588f507_0_n_rl\"},\"callsite_d5454955643\"]],[\"ODS\"],[\"Animation\"],[\"RequireDeferredReference\",\"unblock\",[],[[\"FbtLogging\",\"ODS\",\"IntlQtEventFalcoEvent\",\"Animation\"],\"sd\"]],[\"RequireDeferredReference\",\"unblock\",[],[[\"FbtLogging\",\"ODS\",\"IntlQtEventFalcoEvent\",\"Animation\"],\"css\"]],[\"TimeSliceImpl\"],[\"HasteSupportData\"],[\"ServerJS\"],[\"Run\"],[\"InitialJSLoader\"]]});requireLazy([\"Run\"],function(Run){Run.onAfterLoad(function(){s.cleanup(TimeSlice)})});});\n",
      "\n",
      "</script>\n",
      "<script nonce=\"DyPoUrmQ\">now_inl=(function(){var p=window.performance;return p&&p.now&&p.timing&&p.timing.navigationStart?function(){return p.now()+p.timing.navigationStart}:function(){return new Date().getTime()};})(); window.__bigPipeFR=now_inl();</script>\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yl/l/0,cross/U1Z-El2734z.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yE/l/0,cross/0F7k9wwkBCo.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yw/l/0,cross/rN4w09XutPb.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yE/l/0,cross/_h5q_3IdUeP.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/y-/l/0,cross/5gaZkgRfXTy.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4iWTS4/yI/l/it_IT/MNpPuuBgnnJ.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yK/r/lNInKxOqejp.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yG/r/cNzbDpFSV0A.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4ip_b4/y0/l/it_IT/ByroBupN016.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/y0/r/DlS8iOPbc-U.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yo/r/H4488S-UM6f.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4iEEq4/yW/l/it_IT/c3Ekl6MxMgJ.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yh/r/hPq02P8uOdr.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4iH_T4/yD/l/it_IT/pK50bUwHSMM.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4iIAe4/yN/l/it_IT/5bLTHDBUMlm.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yd/l/0,cross/bouCSXpqbMW.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/y3/r/HMPzpe7rO1f.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4ilY34/yD/l/it_IT/ey-oGV7j96P.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yO/r/i8g7jNs9VtA.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4iHpu4/yY/l/it_IT/YVTDk9ExP5f.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4i1MJ4/y_/l/it_IT/FpPJKs8WQeq.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yw/r/_UemLyZBbsn.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yy/l/0,cross/mUJK3Q14f_f.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yM/r/YdtQ-95opMP.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4ijrz4/yT/l/it_IT/xPfr5-hC6kf.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4ign94/yW/l/it_IT/WBlJZYW9tt6.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v5/yR/l/0,cross/0JO_Y-PHlrV.css\" as=\"style\" crossorigin=\"anonymous\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yC/r/PrMHjiBuCdd.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/yW/r/asFwh9NCKh7.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<link rel=\"preload\" href=\"https://static.xx.fbcdn.net/rsrc.php/v4/y-/r/TR_F0OvvNM4.js\" as=\"script\" crossorigin=\"anonymous\" nonce=\"DyPoUrmQ\" />\n",
      "<script nonce=\"DyPoUrmQ\">window.__bigPipeCtor=now_inl();requireLazy([\"BigPipe\"],function(BigPipe){define(\"__bigPipe\",[],window.bigPipe=new BigPipe({\"forceFinish\":true,\"config\":null}));});</script>\n",
      "<script nonce=\"DyPoUrmQ\">(function(){var n=now_inl();requireLazy([\"__bigPipe\"],function(bigPipe){bigPipe.beforePageletArrive(\"first_response\",n);})})();</script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"__bigPipe\"],(function(bigPipe){bigPipe.onPageletArrive({displayResources:[\"2YfEtdD\",\"D4/LUJw\",\"K1WZ7sC\",\"mwiib7b\",\"cHTkugV\",\"YWKcFNg\",\"Ftl2VZm\",\"tSd1da+\",\"jLGQDLb\",\"7Co8YaN\",\"p5KjQo3\",\"Ta11qxv\",\"o0Y39To\",\"9Hl4kP7\",\"d8hh03I\",\"ON7WAdt\",\"UlKMvP9\",\"qnlaxic\",\"jUx4Er3\",\"WlWA5Yc\",\"v3LJVPf\",\"79x5MJf\",\"gHx22nF\",\"//za25u\",\"56Auvlv\",\"a6hDdEq\",\"k333Q1J\",\"1s/Toed\",\"1I0UazQ\",\"u1+5F9n\"],id:\"first_response\",phase:0,last_in_phase:true,tti_phase:0,hsrp:{hblp:{consistency:{rev:1019092984}}},allResources:[\"ZH5DRAM\",\"Ta11qxv\",\"79x5MJf\",\"8lp8wGa\",\"o0Y39To\",\"I8zzdEO\",\"p5KjQo3\",\"2YfEtdD\",\"D4/LUJw\",\"K1WZ7sC\",\"mwiib7b\",\"cHTkugV\",\"YWKcFNg\",\"Ftl2VZm\",\"tSd1da+\",\"jLGQDLb\",\"7Co8YaN\",\"9Hl4kP7\",\"d8hh03I\",\"ON7WAdt\",\"UlKMvP9\",\"qnlaxic\",\"jUx4Er3\",\"WlWA5Yc\",\"v3LJVPf\",\"gHx22nF\",\"//za25u\",\"56Auvlv\",\"a6hDdEq\",\"k333Q1J\",\"HLEgydM\",\"1s/Toed\",\"1I0UazQ\",\"u1+5F9n\",\"vCxI9D4\"]});}));</script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"__bigPipe\"],function(bigPipe){bigPipe.setPageID(\"7453497756665521207\")});</script><script nonce=\"DyPoUrmQ\">(function(){var n=now_inl();requireLazy([\"__bigPipe\"],function(bigPipe){bigPipe.beforePageletArrive(\"last_response\",n);})})();</script>\n",
      "<script nonce=\"DyPoUrmQ\">requireLazy([\"__bigPipe\"],(function(bigPipe){bigPipe.onPageletArrive({displayResources:[\"X+gacmF\"],id:\"last_response\",phase:1,last_in_phase:true,the_end:true,jsmods:{define:[[\"cr:6016\",[\"NavigationMetricsWWW\"],{__rc:[\"NavigationMetricsWWW\",null]},-1],[\"cr:3376\",[],{__rc:[null,null]},-1],[\"cr:7267\",[\"AdsDataAtom\"],{__rc:[\"AdsDataAtom\",null]},-1],[\"cr:1083116\",[\"XAsyncRequest\"],{__rc:[\"XAsyncRequest\",null]},-1],[\"cr:1083117\",[],{__rc:[null,null]},-1],[\"TimeSliceInteractionSV\",[],{on_demand_reference_counting:true,on_demand_profiling_counters:true,default_rate:1000,lite_default_rate:100,interaction_to_lite_coinflip:{ADS_INTERFACES_INTERACTION:0,ads_perf_scenario:0,ads_wait_time:0,Event:1},interaction_to_coinflip:{ADS_INTERFACES_INTERACTION:1,ads_perf_scenario:1,ads_wait_time:1,Event:100},enable_heartbeat:false,maxBlockMergeDuration:0,maxBlockMergeDistance:0,enable_banzai_stream:true,user_timing_coinflip:50,banzai_stream_coinflip:0,compression_enabled:true,ref_counting_fix:false,ref_counting_cont_fix:false,also_record_new_timeslice_format:false,force_async_request_tracing_on:false},2609],[\"cr:6114\",[\"DOM\"],{__rc:[\"DOM\",null]},-1],[\"cr:7225\",[],{__rc:[null,null]},-1],[\"cr:1042\",[\"XAsyncRequestWWW\"],{__rc:[\"XAsyncRequestWWW\",null]},-1],[\"cr:7383\",[\"BanzaiWWW\"],{__rc:[\"BanzaiWWW\",null]},-1],[\"cr:9985\",[\"performanceAbsoluteNow\"],{__rc:[\"performanceAbsoluteNow\",null]},-1],[\"cr:844180\",[\"TimeSpentImmediateActiveSecondsLoggerBlue\"],{__rc:[\"TimeSpentImmediateActiveSecondsLoggerBlue\",null]},-1],[\"cr:1187159\",[\"BlueCompatBroker\"],{__rc:[\"BlueCompatBroker\",null]},-1],[\"cr:1634616\",[\"UserActivityBlue\"],{__rc:[\"UserActivityBlue\",null]},-1],[\"TimeSpentConfig\",[],{delay:1000,timeout:64,\"0_delay\":0,\"0_timeout\":8},142],[\"cr:710\",[],{__rc:[null,null]},-1],[\"cr:1642797\",[\"BanzaiBase\"],{__rc:[\"BanzaiBase\",null]},-1],[\"ImmediateActiveSecondsConfig\",[],{sampling_rate:0},423],[\"CometAltpayJsSdkIframeAllowedDomains\",[],{allowed_domains:[\"https://live.adyen.com\",\"https://integration-facebook.payu.in\",\"https://facebook.payulatam.com\",\"https://secure.payu.com\",\"https://facebook.dlocal.com\",\"https://buy2.boku.com\"]},4920],[\"cr:1172\",[\"WebSession\"],{__rc:[\"WebSession\",null]},-1],[\"cr:2037\",[\"BanzaiAdapter\"],{__rc:[\"BanzaiAdapter\",null]},-1],[\"cr:3724\",[\"SetIdleTimeoutAcrossTransitions\"],{__rc:[\"SetIdleTimeoutAcrossTransitions\",null]},-1],[\"cr:9986\",[\"CurrentUser\"],{__rc:[\"CurrentUser\",null]},-1],[\"cr:9987\",[\"NavigationMetrics\"],{__rc:[\"NavigationMetrics\",null]},-1],[\"cr:9988\",[\"Visibility\"],{__rc:[\"Visibility\",null]},-1],[\"cr:5866\",[\"BanzaiAdapterWWW\"],{__rc:[\"BanzaiAdapterWWW\",null]},-1],[\"cr:7384\",[\"cancelIdleCallbackWWW\"],{__rc:[\"cancelIdleCallbackWWW\",null]},-1],[\"cr:692209\",[\"cancelIdleCallbackBlue\"],{__rc:[\"cancelIdleCallbackBlue\",null]},-1],[\"BanzaiConfig\",[],{MAX_SIZE:10000,MAX_WAIT:150000,MIN_WAIT:null,RESTORE_WAIT:150000,blacklist:[\"time_spent\"],disabled:false,gks:{boosted_pagelikes:true,platform_oauth_client_events:true,sticker_search_ranking:true},known_routes:[\"artillery_javascript_actions\",\"artillery_javascript_trace\",\"artillery_logger_data\",\"logger\",\"falco\",\"gk2_exposure\",\"js_error_logging\",\"loom_trace\",\"marauder\",\"perfx_custom_logger_endpoint\",\"qex\",\"require_cond_exposure_logging\",\"metaconfig_exposure\"],should_drop_unknown_routes:true,should_log_unknown_routes:false},7]],require:[[\"NavigationMetrics\",\"setPage\",[],[{page:\"MSXAIResearchPublicationEntController\",page_type:\"normal\",page_uri:\"https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/\",serverLID:\"7453497756665521207\"}]],[\"FalcoLoggerTransports\",\"attach\",[],[]],[\"Chromedome\",\"start\",[],[{}]],[\"DimensionTracking\"],[\"ClickRefLogger\"],[\"NavigationClickPointHandler\"],[\"CookieCore\",\"setWithoutChecksIfFirstPartyContext\",[],[\"_js_datr\",\"uCRwZ2feeslAW-_CbnUKqLaq\",34560000000,\"/\",true,\".ai.meta.com\"]],[\"Artillery\",\"disable\",[],[]],[\"ScriptPathLogger\",\"startLogging\",[],[]],[\"TimeSpentBitArrayLogger\",\"init\",[],[]],[\"TransportSelectingClientSingletonConditional\"],[\"RequireDeferredReference\",\"unblock\",[],[[\"TransportSelectingClientSingletonConditional\"],\"sd\"]],[\"RequireDeferredReference\",\"unblock\",[],[[\"TransportSelectingClientSingletonConditional\"],\"css\"]]]},hsrp:{hsdp:{clpData:{\"1829319\":{r:1},\"1829320\":{r:1},\"1843988\":{r:1}},justknobxData:{\"2233\":{r:true}}},hblp:{consistency:{rev:1019092984},rsrcMap:{\"lCYncZ+\":{type:\"js\",src:\"https://static.xx.fbcdn.net/rsrc.php/v4iEYq4/yP/l/it_IT/lQXJ_H-9oDf.js\"},ioZ2Fb1:{type:\"js\",src:\"https://static.xx.fbcdn.net/rsrc.php/v4/yw/r/gIn0tQyHe_i.js\"}}}},allResources:[\"X+gacmF\",\"1I0UazQ\",\"79x5MJf\",\"lCYncZ+\",\"UlKMvP9\",\"Ta11qxv\",\"ioZ2Fb1\",\"7Co8YaN\",\"p5KjQo3\"]});}));</script></body></html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.get('https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/')\n",
    "print(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "• On top of the efficient architecture of DeepSeek-V2, we pioneer an auxiliary-loss-free strategy for load balancing, which minimizes the performance degradation that arises from encouraging load balancing.\n",
      "• We investigate a Multi-Token Prediction (MTP) objective and prove it beneficial to model performance. It can also be used for speculative decoding for inference acceleration.\n",
      "• We design an FP8 mixed precision training framework and, for the first time, validate the feasibility and effectiveness of FP8 training on an extremely large-scale model.\n",
      "• Through co-design of algorithms, frameworks, and hardware, we overcome the communication bottleneck in cross-node MoE training, nearly achieving full computation-communication overlap.\n",
      "\n",
      " This significantly enhances our training efficiency and reduces the training costs, enabling us to further scale up the model size without additional overhead.\n",
      "• At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model. The subsequent training stages after pre-training require only 0.1M GPU hours.\n",
      "• We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.\n",
      "\n",
      "NOTE: The total size of DeepSeek-V3 models on HuggingFace is 685B, which includes 671B of the Main Model weights and 14B of the Multi-Token Prediction (MTP) Module weights.\n",
      "\n",
      "To ensure optimal performance and flexibility, we have partnered with open-source communities and hardware vendors to provide multiple ways to run the model locally. For step-by-step guidance, check out Section 6: How_to Run_Locally.\n",
      "\n",
      "For developers looking to dive deeper, we recommend exploring README_WEIGHTS.md for details on the Main Model weights and the Multi-Token Prediction (MTP) Modules. Please note that MTP support is currently under active development within the community, and we welcome your contributions and feedback.\n",
      "\n",
      "Note: Best results are shown in bold. Scores with a gap not exceeding 0.3 are considered to be at the same level. DeepSeek-V3 achieves the best performance on most benchmarks, especially on math and code tasks. For more evaluation details, please check our paper.\n",
      "\n",
      "Evaluation results on the (NIAH) tests. DeepSeek-V3 performs well across all context window lengths up to 128K.\n",
      "\n",
      "You can chat with DeepSeek-V3 on DeepSeek's official website: chat.deepseek.com\n",
      "\n",
      "We also provide OpenAI-Compatible API at DeepSeek Platform: platform.deepseek.com\n",
      "\n",
      "DeepSeek-V3 can be deployed locally using the following hardware and open-source community software:\n",
      "• DeepSeek-Infer Demo: We provide a simple and lightweight demo for FP8 and BF16 inference.\n",
      "• SGLang: Fully support the DeepSeek-V3 model in both BF16 and FP8 inference modes.\n",
      "• LMDeploy: Enables efficient FP8 and BF16 inference for local and cloud deployment.\n",
      "• TensorRT-LLM: Currently supports BF16 inference and INT4/8 quantization, with FP8 support coming soon.\n",
      "• vLLM: Support DeekSeek-V3 model with FP8 and BF16 modes for tensor parallelism and pipeline parallelism.\n",
      "• AMD GPU: Enables running the DeepSeek-V3 model on AMD GPUs via SGLang in both BF16 and FP8 modes.\n",
      "\n",
      "Since FP8 training is natively adopted in our framework, we only provide FP8 weights. If you require BF16 weights for experimentation, you can use the provided conversion script to perform the transformation.\n",
      "\n",
      "Here is an example of converting FP8 weights to BF16:\n",
      "\n",
      "NOTE: Huggingface's Transformers has not been directly supported yet.\n",
      "\n",
      "Navigate to the folder and install dependencies listed in .\n",
      "\n",
      "Download the model weights from HuggingFace, and put them into folder.\n",
      "\n",
      "Then you can chat with DeepSeek-V3:\n",
      "\n",
      "Or batch inference on a given file:\n",
      "\n",
      "SGLang currently supports MLA optimizations, FP8 (W8A8), FP8 KV Cache, and Torch Compile, delivering state-of-the-art latency and throughput performance among open-source frameworks.\n",
      "\n",
      "Notably, SGLang v0.4.1 fully supports running DeepSeek-V3 on both NVIDIA and AMD GPUs, making it a highly versatile and robust solution.\n",
      "\n",
      "Here are the launch instructions from the SGLang team: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3\n",
      "\n",
      "LMDeploy, a flexible and high-performance inference and serving framework tailored for large language models, now supports DeepSeek-V3. It offers both offline pipeline processing and online deployment capabilities, seamlessly integrating with PyTorch-based workflows.\n",
      "\n",
      "For comprehensive step-by-step instructions on running DeepSeek-V3 with LMDeploy, please refer to here: InternLM/lmdeploy#2960\n",
      "\n",
      "TensorRT-LLM now supports the DeepSeek-V3 model, offering precision options such as BF16 and INT4/INT8 weight-only. Support for FP8 is currently in progress and will be released soon. You can access the custom branch of TRTLLM specifically for DeepSeek-V3 support through the following link to experience the new features directly: https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3.\n",
      "\n",
      "vLLM v0.6.6 supports DeepSeek-V3 inference for FP8 and BF16 modes on both NVIDIA and AMD GPUs. Aside from standard techniques, vLLM offers pipeline parallelism allowing you to run this model on multiple machines connected by networks. For detailed guidance, please refer to the vLLM instructions. Please feel free to follow the enhancement plan as well.\n",
      "\n",
      "In collaboration with the AMD team, we have achieved Day-One support for AMD GPUs using SGLang, with full compatibility for both FP8 and BF16 precision. For detailed guidance, please refer to the SGLang instructions.\n",
      "\n",
      "The MindIE framework from the Huawei Ascend community has successfully adapted the BF16 version of DeepSeek-V3. For step-by-step guidance on Ascend NPUs, please follow the instructions here.\n",
      "\n",
      "This code repository is licensed under the MIT License. The use of DeepSeek-V3 Base/Chat models is subject to the Model License. DeepSeek-V3 series (including Base and Chat) supports commercial use.\n",
      "\n",
      "If you have any questions, please raise an issue or contact us at service@deepseek.com.\n",
      "deepseek-ai/DeepSeek-V3\n"
     ]
    }
   ],
   "source": [
    "from goose3 import Goose\n",
    "\n",
    "url = 'https://github.com/deepseek-ai/DeepSeek-V3'\n",
    "g = Goose()\n",
    "article = g.extract(url=url)\n",
    "print(article.cleaned_text)  # Contenuto principale\n",
    "print(article.title)         # Titolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['close', 'config', 'extract', 'fetcher', 'finalizer', 'shutdown_network']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[method for method in dir(g) if not method.startswith('_') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element div at 0x11bd45130>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article.cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.database.sql import SQLDatabase\n",
    "\n",
    "db = SQLDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 2,\n",
       "  'title': \"Qwen's Visual Reasoning Model\",\n",
       "  'concept_text': \"Qwen has introduced QVQ, a new visual reasoning model that significantly enhances deep thinking and provides step-by-step predictions. This model is designed to outperform existing competitors like GPT-4o and Claude Sonnet 3.5 in tasks requiring visual reasoning capabilities. By leveraging advanced techniques in visual processing, QVQ aims to offer more accurate and reliable outcomes when interpreting visual data. This innovation is a part of a growing trend in artificial intelligence where models are increasingly expected to reason not just in text but also in visual contexts. As visual reasoning becomes a critical skill for AI applications, Qwen's development represents a significant advancement in how machines can understand and interact with visual information.\",\n",
       "  'keywords': 'Qwen, visual reasoning, deep thinking, step-by-step predictions',\n",
       "  'links': 'https://qwenlm.github.io/blog/qvq-72b-preview/'},\n",
       " {'id': 3,\n",
       "  'title': \"Meta's Large Concept Models\",\n",
       "  'concept_text': \"Meta's FAIR team has unveiled Large Concept Models (LCM), a groundbreaking approach to AI that processes concepts rather than relying solely on traditional tokenization methods. This innovative model is trained on 7.7 trillion tokens, allowing it to better understand and generate language based on the underlying concepts rather than just sequences of tokens. By separating reasoning from language, LCM aims to enhance the AI's ability to comprehend complex ideas and relationships, leading to more nuanced and contextually relevant outputs. This development is part of a broader movement in AI research that seeks to create models capable of deeper reasoning and understanding, potentially revolutionizing how AI systems interact with human language and concepts.\",\n",
       "  'keywords': 'Meta, Large Concept Models, tokenization, reasoning, language processing',\n",
       "  'links': 'https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/'},\n",
       " {'id': 4,\n",
       "  'title': \"Cognition's Devin Update\",\n",
       "  'concept_text': 'Cognition has released an update for its AI software engineer, Devin 1.1, which now includes full API support and boasts a 10% increase in performance for code-editing tasks. This update addresses previous limitations and enhances the usability of Devin as a coding assistant, allowing developers to streamline their workflows more efficiently. With custom workflows and improved speed, Devin aims to become an indispensable tool for software engineers looking to leverage AI in their development processes. This reflects a growing trend in the industry where AI tools are being integrated into daily coding practices, helping to reduce manual effort and improve productivity for developers.',\n",
       "  'keywords': 'Cognition, Devin, AI software engineer, coding assistant, API support',\n",
       "  'links': 'https://x.com/cognition_labs/status/1872290789050712165'},\n",
       " {'id': 5,\n",
       "  'title': 'Hugging Face GGUF Integration',\n",
       "  'concept_text': \"Hugging Face has recently integrated with Ollama, facilitating the use of private GGUF models that can be run with a simple SSH setup. This integration simplifies the deployment of custom models, making it easier for developers to fine-tune and quantify their AI applications. By providing a streamlined process for utilizing GGUF models, Hugging Face continues to support the growing demand for accessible AI tools that empower developers to customize their machine learning workflows. The ability to run models privately enhances security and control over one's AI implementations, aligning with the industry's shift towards more user-centric AI solutions.\",\n",
       "  'keywords': 'Hugging Face, Ollama, GGUF models, SSH setup',\n",
       "  'links': 'https://huggingface.co/docs/hub/en/ollama'},\n",
       " {'id': 6,\n",
       "  'title': 'Microsoft AIOpsLab',\n",
       "  'concept_text': \"Microsoft Research has launched AIOpsLab, an open-source framework designed to refine AI agents for enhanced reliability in cloud systems. This tool is aimed at developers and organizations looking to optimize their AI operations within cloud environments. By providing a structured approach to testing and improving AI agents, AIOpsLab seeks to address common challenges in cloud AI deployments, such as performance consistency and scalability. This initiative reflects Microsoft's commitment to advancing AI technologies that not only improve operational efficiency but also ensure that AI systems are robust and reliable in real-world applications, paving the way for a more dependable AI infrastructure in the cloud.\",\n",
       "  'keywords': 'Microsoft Research, AIOpsLab, open-source, AI agents, cloud systems',\n",
       "  'links': 'https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/'},\n",
       " {'id': 7,\n",
       "  'title': 'Amazon Nova',\n",
       "  'concept_text': 'Amazon has launched Nova, a comprehensive suite of multimodal AI models designed to compete directly with established models like GPT and Claude. This lineup includes various models tailored for different applications, ranging from text-only processing to video generation capabilities. Nova emphasizes reduced costs and latency while catering to enterprise workloads, making it an appealing option for businesses seeking advanced AI solutions. The models can handle diverse inputs such as text, images, and video, and are accessible through the Bedrock API, allowing for extensive data processing and high-quality generative content creation. Notably, Nova Pro is priced significantly lower than its competitors while offering impressive performance metrics across various benchmarks, positioning Amazon as a formidable player in the AI landscape.',\n",
       "  'keywords': 'Amazon, Nova, AI models, multimodal, GPT, Claude',\n",
       "  'links': 'https://aws.amazon.com/ai/generative-ai/nova/'},\n",
       " {'id': 8,\n",
       "  'title': 'AI Agents by ElevenLabs',\n",
       "  'concept_text': 'ElevenLabs has introduced advanced AI agents capable of engaging in speech within minutes, showcasing low latency and full configurability. This development signifies a significant advancement in the practical application of AI agents, optimizing their scalability for various uses. These agents can be integrated into different platforms and services, allowing for seamless interactions in customer support, content creation, and other fields that benefit from quick and efficient communication. The ability to configure these agents fully means that businesses can tailor their functionalities to meet specific requirements, enhancing user experience and operational efficiency.',\n",
       "  'keywords': 'ElevenLabs, AI agents, speech, latency, configurability',\n",
       "  'links': 'https://elevenlabs.io/conversational-ai'},\n",
       " {'id': 9,\n",
       "  'title': 'SmallCon GenAI Virtual Conference',\n",
       "  'concept_text': 'The SmallCon GenAI Virtual Conference is set to take place on December 11th, featuring leading figures from major AI companies such as Meta, Mistral, and HuggingFace. This free event aims to provide attendees with in-depth discussions about the latest trends and technologies in Generative AI. The agenda includes topics on the future of small models, enterprise transformations through GenAI, and insights on deploying AI agents effectively. By attending, participants can gain valuable knowledge on building the GenAI stack of the future and learn practical strategies to implement their AI models in production settings, making it a must-attend event for AI enthusiasts and professionals alike.',\n",
       "  'keywords': 'SmallCon, GenAI, conference, Meta, HuggingFace',\n",
       "  'links': 'https://predibase.com/smallcon?utm_medium=3rdparty&utm_source=alphasignal_primaryad'},\n",
       " {'id': 10,\n",
       "  'title': 'QwQ-32B Model',\n",
       "  'concept_text': 'QwQ-32B-Preview is touted as the most intelligent open model available, excelling in complex analytical and reasoning tasks. This model has been designed to tackle challenging problems in mathematics and programming, demonstrating superior performance on various benchmarks such as GPQA and MATH-500. The capabilities of QwQ-32B make it an essential tool for developers and researchers looking to leverage advanced AI for problem-solving and data analysis. Its open-access nature allows for widespread use, fostering innovation and collaboration within the AI community as users explore its potential across numerous applications.',\n",
       "  'keywords': 'QwQ-32B, open model, AI, analytical tasks, reasoning',\n",
       "  'links': 'https://huggingface.co/Qwen/QwQ-32B-Preview'},\n",
       " {'id': 11,\n",
       "  'title': \"Google's GenAI Intensive Course\",\n",
       "  'concept_text': 'Google has launched a comprehensive 5-day GenAI Intensive Course aimed at equipping participants with essential knowledge and skills in Generative AI. This self-paced course covers a wide range of topics, including foundational models, prompt engineering, and embedding techniques. Each day focuses on different aspects of AI development, culminating in practical applications and deployment strategies. The course includes assignments, whitepapers, and code labs, providing a hands-on learning experience for individuals eager to enhance their expertise in the rapidly evolving field of AI. This initiative reflects the growing demand for skilled professionals in generative technologies and aims to empower learners with the tools needed to excel.',\n",
       "  'keywords': 'Google, GenAI, course, Generative AI, training',\n",
       "  'links': 'https://www.kaggle.com/learn-guide/5-day-genai#GenAI'},\n",
       " {'id': 12,\n",
       "  'title': \"DeepMind's Genie 2 Model\",\n",
       "  'concept_text': 'DeepMind has unveiled Genie 2, a groundbreaking foundation world model that excels in generating an extensive range of playable 3D environments. This innovative model allows users to create diverse worlds from a single text or image prompt, seamlessly integrating user inputs such as keyboard and mouse controls. Notably, Genie 2 maintains the consistency of these generated environments for up to one minute, providing a stable platform for interaction and exploration. The model operates through an autoregressive latent diffusion framework, trained on a vast video dataset, which enables it to produce new frames dynamically through a transformer model. This capability makes it a powerful tool for training embodied agents in various AI applications, allowing researchers to simulate a variety of scenarios and tasks within the generated environments.',\n",
       "  'keywords': 'DeepMind, Genie 2, 3D environments, AI training, autoregressive model',\n",
       "  'links': 'https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/'},\n",
       " {'id': 13,\n",
       "  'title': 'NVIDIA GH200 and Cost Efficiency',\n",
       "  'concept_text': 'The introduction of the NVIDIA GH200 Grace Hopper Superchip marks a significant advancement in AI model inference, particularly for large language models (LLMs). This cutting-edge hardware is designed to enhance throughput and reduce costs associated with running large models that typically struggle to fit within the memory constraints of a single GPU. With a reported 7.6 times higher throughput compared to the previous generation H100 SXM and an impressive 8 times lower cost per token, the GH200 eliminates the need for costly multi-GPU instances and mitigates performance issues caused by CPU offloading. This technology provides a unified memory architecture that allows for seamless model loading, enabling developers to focus on deploying their models without facing the usual bottlenecks. The GH200 is now available on-demand through Lambda’s Public Cloud, making it an accessible option for AI developers aiming to optimize their workflows and reduce operational costs.',\n",
       "  'keywords': 'NVIDIA GH200, cost efficiency, LLM inference, AI hardware, Lambda Cloud',\n",
       "  'links': 'https://lambdalabs.com/blog/putting-the-nvidia-gh200-grace-hopper-superchip-to-good-use-superior-inference-performance-and-economics?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=2024-11-gh200-larger-model-inference&utm_content=ad-3'},\n",
       " {'id': 14,\n",
       "  'title': \"OpenAI's Livestream Launch\",\n",
       "  'concept_text': \"OpenAI has initiated an exciting series titled '12 Days of OpenAI,' where the company will host livestream events showcasing various product launches and demonstrations over a span of 12 weekdays. This initiative, announced by Sam Altman, aims to engage the AI community by providing real-time insights into the latest advancements and offerings from OpenAI. Each session is designed to highlight new features, capabilities, and applications of OpenAI’s technologies, fostering a deeper understanding of how these tools can be leveraged in various fields. By inviting developers and enthusiasts to participate in this interactive experience, OpenAI is reinforcing its commitment to transparency and collaboration within the AI landscape, encouraging feedback and discussions that can shape future developments.\",\n",
       "  'keywords': 'OpenAI, livestream, product launch, Sam Altman, AI community',\n",
       "  'links': 'https://x.com/sama/status/1864335461268754712'},\n",
       " {'id': 15,\n",
       "  'title': \"Liquid AI's STAR Model Architecture\",\n",
       "  'concept_text': \"Liquid AI has introduced its new STAR model architecture, which has been highlighted for its superior performance compared to traditional Transformer models. This innovative architecture aims to address some of the limitations observed in existing models, particularly in terms of efficiency and scalability. By leveraging advanced techniques and a reimagined structure, the STAR model is designed to deliver enhanced processing capabilities while maintaining flexibility for a variety of AI applications. This development signifies a pivotal shift in model design, promising improved results for tasks such as natural language processing, computer vision, and more. As AI developers continue to seek more effective solutions, Liquid AI's STAR model stands out as a promising alternative in the rapidly evolving landscape of machine learning architectures, paving the way for future innovations.\",\n",
       "  'keywords': 'Liquid AI, STAR model, Transformer architecture, AI efficiency, machine learning',\n",
       "  'links': 'https://venturebeat.com/ai/liquid-ais-new-star-model-architecture-outshines-transformer-efficiency/#:~:text=In%20tests%20conducted%20during%20their,Transformer%2B%2B%20and%20hybrid%20models.'},\n",
       " {'id': 16,\n",
       "  'title': 'Generative AI and Video Models',\n",
       "  'concept_text': 'Google has broadened access to its generative video model, Veo, alongside the launch of Imagen 3 on Vertex AI. This move represents a significant step forward in the field of generative AI, enabling users to create high-quality video content from textual descriptions or other prompts. The advancements in these models not only enhance creative possibilities for developers but also open new avenues for applications in media, entertainment, and beyond. By providing tools that simplify the video creation process, Google is empowering creators to experiment with generative techniques, potentially revolutionizing the way content is produced and consumed. With the increasing demand for dynamic and engaging media, the integration of such generative models into workflows is likely to become a norm, further solidifying the role of AI in content production.',\n",
       "  'keywords': 'Google, Veo, generative video, Imagen 3, AI content creation',\n",
       "  'links': 'https://cloud.google.com/blog/products/ai-machine-learning/introducing-veo-and-imagen-3-on-vertex-ai'},\n",
       " {'id': 17,\n",
       "  'title': 'AWS Bedrock Updates',\n",
       "  'concept_text': 'AWS has recently unveiled significant updates to its Bedrock platform during the re:Invent 2024 conference. These enhancements are primarily designed to improve efficiency and reduce latency in AI model deployment. Key features include Intelligent Prompt Routing, which can lower inference latency by up to 85%, and Prompt Caching, which helps to cut costs dramatically by storing common queries. Additionally, the platform supports advanced Retrieval-Augmented Generation (RAG) workflows, allowing users to handle both structured and unstructured data seamlessly without the need for extensive custom coding. These updates position AWS Bedrock as a robust solution for enterprises looking to enhance their AI capabilities while managing costs effectively.',\n",
       "  'keywords': 'AWS, Bedrock, Latency, AI, Updates',\n",
       "  'links': ''},\n",
       " {'id': 18,\n",
       "  'title': 'AWS SageMaker Enhancements',\n",
       "  'concept_text': 'AWS SageMaker has introduced a series of enhancements aimed at unifying data and AI capabilities into a single platform. This update allows users to connect various data sources—both structured and unstructured—streamlining the development of AI applications. It boasts over 140 features that facilitate seamless workflows and accelerate model deployment. A notable addition is the HyperPod task governance system, which prioritizes workloads for training, inference, and fine-tuning, significantly boosting GPU utilization by reducing idle time. These improvements are expected to streamline the AI development process, making it more efficient and cost-effective for enterprises looking to scale their operations.',\n",
       "  'keywords': 'AWS, SageMaker, AI, Data Hub, Enhancements',\n",
       "  'links': ''},\n",
       " {'id': 19,\n",
       "  'title': 'OpenAI Usage API',\n",
       "  'concept_text': \"OpenAI has launched a new Usage API that allows users to track their API usage and costs in real-time. This tool provides detailed insights and filtering options, enabling better management of resources for developers and enterprises utilizing OpenAI's services. By offering a transparent view of API consumption, the Usage API helps users make informed decisions about their usage patterns and budgeting. This is particularly valuable for businesses that rely on OpenAI's capabilities for various applications, as it ensures they can optimize their expenses and enhance their operational efficiency.\",\n",
       "  'keywords': 'OpenAI, API, Usage Tracking, Cost Management, Insights',\n",
       "  'links': ''},\n",
       " {'id': 20,\n",
       "  'title': 'AI-Powered Weather Forecasting',\n",
       "  'concept_text': 'DeepMind has introduced GenCast, an AI-driven weather forecasting model that promises significant advancements in predictive analysis. This system is capable of delivering 15-day weather forecasts in a matter of minutes, outperforming traditional forecasting methods on 97% of metrics. By leveraging advanced machine learning techniques, GenCast aims to provide more accurate and timely weather information, which can be crucial for various sectors, including agriculture, disaster management, and everyday decision-making. The launch of GenCast reflects the growing trend of utilizing AI to enhance predictive analytics across different domains.',\n",
       "  'keywords': 'DeepMind, GenCast, Weather Forecasting, AI, Predictive Analysis',\n",
       "  'links': ''},\n",
       " {'id': 21,\n",
       "  'title': 'RAG Enhancements in AI Workflows',\n",
       "  'concept_text': 'Retrieval-Augmented Generation (RAG) is becoming increasingly important in the development of large language models and AI applications. The recent advancements in RAG tools, particularly with AWS Bedrock, allow for the integration of knowledge bases and automated SQL query generation. This streamlines complex data tasks and enhances the accuracy of AI models by enabling them to access and utilize vast amounts of information effectively. The ability to work with both structured and unstructured data without extensive coding requirements is a significant leap forward for developers, as it simplifies the integration of advanced AI capabilities into their applications.',\n",
       "  'keywords': 'RAG, AI Workflows, Data Integration, Knowledge Bases, AWS',\n",
       "  'links': ''},\n",
       " {'id': 22,\n",
       "  'title': 'OpenAI o3 Launch',\n",
       "  'concept_text': \"OpenAI has recently unveiled its latest reasoning model, dubbed o3, marking a significant advancement in artificial intelligence. This model has achieved a remarkable score of 87.5% on the ARC-AGI benchmark, which is designed to assess reasoning and generalization capabilities. The o3 model is built on a hybrid neural-symbolic framework, enabling it to move beyond traditional pattern matching. This allows o3 to generate solutions dynamically, thereby showcasing its ability to tackle complex and unseen problems effectively. The introduction of o3 represents a major step forward in AI development, highlighting OpenAI's commitment to pushing the boundaries of what AI can achieve in reasoning tasks.\",\n",
       "  'keywords': 'OpenAI, o3, reasoning model, ARC-AGI',\n",
       "  'links': 'https://link.alphasignal.ai/Jyqtx6'},\n",
       " {'id': 23,\n",
       "  'title': \"ByteDance's Monolith Framework\",\n",
       "  'concept_text': \"ByteDance has launched Monolith, an innovative open-source framework aimed at enhancing the scalability of recommender systems. This framework is designed to assist developers in building robust systems that can efficiently handle vast amounts of data and user interactions. By providing a scalable architecture, Monolith enables organizations to optimize their recommendation algorithms, ensuring that users receive personalized content that meets their needs. The release of Monolith underscores ByteDance's commitment to advancing AI technologies and making them accessible to developers, facilitating the creation of intelligent systems that can adapt and evolve with user preferences.\",\n",
       "  'keywords': 'ByteDance, Monolith, recommender systems, open-source',\n",
       "  'links': 'https://github.com/bytedance/monolith'},\n",
       " {'id': 24,\n",
       "  'title': 'Genesis Physics Engine',\n",
       "  'concept_text': 'A team of researchers has introduced Genesis, an open-source physics engine that allows for the rapid creation of 4D environments specifically tailored for robotics and AI applications. This groundbreaking technology is capable of generating environments at an astonishing speed, operating 430,000 times faster than real-time. Genesis provides developers with the tools needed to simulate complex physical interactions in a highly efficient manner, thereby facilitating advancements in robotic training and AI-driven simulations. The availability of Genesis as an open-source project represents a significant contribution to the field, empowering other researchers and developers to leverage this technology in their own projects.',\n",
       "  'keywords': 'Genesis, physics engine, 4D environments, robotics, AI',\n",
       "  'links': 'https://genesis-embodied-ai.github.io/'},\n",
       " {'id': 25,\n",
       "  'title': \"Google's Gemini 2.0 Flash Thinking Model\",\n",
       "  'concept_text': \"Google has unveiled Gemini 2.0 Flash Thinking, a new reasoning model that demonstrates advanced problem-solving capabilities. This model excels in providing insights into its thought process while solving problems, making it a unique tool for developers and researchers alike. Gemini 2.0 is designed to be user-friendly and accessible, allowing for real-time interactions and dynamic responses. By prioritizing transparency in its reasoning processes, Gemini 2.0 sets a new standard for AI models, paving the way for further innovations in the field of artificial intelligence. This model's capabilities have positioned it as a leading tool for those looking to enhance their AI applications.\",\n",
       "  'keywords': 'Google, Gemini 2.0, reasoning model, AI',\n",
       "  'links': 'https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Faistudio.google.com%2Fprompts%2Fnew_chat%3Fmodel%3Dgemini-2.0-flash-thinking-exp-1219&followup=https%3A%2F%2Faistudio.google.com%2Fprompts%2Fnew_chat%3Fmodel%3Dgemini-2.0-flash-thinking-exp-1219&ifkv=AeZLP99LSRyaKSjsx6Q6RlQT1l0o_AtWvs5GlrQ9Yiz6LOLAZwYW-XARETVOX14c8ErSWM2P8YNC&passive=1209600&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1647826217%3A1735399482185467'},\n",
       " {'id': 26,\n",
       "  'title': 'Qwen 2.5 Technical Report',\n",
       "  'concept_text': \"The Qwen team has published a technical report detailing the Qwen 2.5 model, which includes a series of open-weight large language models (LLMs). This report outlines the capabilities of Qwen 2.5, emphasizing its general-purpose functionality as well as its applications in coding and vision-language modeling (VLM). The release of this report is significant for developers and researchers interested in leveraging open-weight models for their projects, as it provides critical insights into the model's architecture and performance. The transparency offered by the Qwen team aims to foster collaboration and innovation within the AI community.\",\n",
       "  'keywords': 'Qwen, Qwen 2.5, technical report, LLMs',\n",
       "  'links': 'https://arxiv.org/abs/2412.15115'},\n",
       " {'id': 27,\n",
       "  'title': 'OpenAI o1 API',\n",
       "  'concept_text': 'OpenAI has launched the o1 API, a reasoning model designed for complex, multi-step problem-solving tasks. This model is particularly noteworthy for its advanced capabilities, including function calling that connects to external data and APIs, structured outputs that comply with custom JSON schemas, and vision capabilities that allow it to process visual inputs. The o1 API is optimized for efficiency, achieving a 60% reduction in reasoning token usage, which translates to significant cost savings and improved latency. Developers can utilize the model for a variety of applications, including science, manufacturing, and coding, making it a versatile tool in the AI ecosystem.',\n",
       "  'keywords': 'OpenAI, API, reasoning model, complex problem-solving, cost-efficiency',\n",
       "  'links': 'https://link.alphasignal.ai/vKAZzV'},\n",
       " {'id': 28,\n",
       "  'title': 'Lambda Inference API',\n",
       "  'concept_text': 'Lambda has introduced its Inference API, which promises low-cost and scalable AI processing capabilities. This API is designed to run AI inference without limits, providing access to top-tier models while maintaining cost transparency. Users can expect costs as low as $0.02 per million tokens, and the service is built specifically for high-performance AI workloads. The infrastructure is optimized to support seamless scaling, making it an ideal choice for developers looking to prototype, test, and deploy AI applications without facing rate limits. This service significantly simplifies the process of scaling AI projects, allowing developers to focus on innovation rather than infrastructure concerns.',\n",
       "  'keywords': 'Lambda, Inference API, scalability, cost-efficiency, AI processing',\n",
       "  'links': 'https://lambdalabs.com/inference?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=2024-12-inference&utm_content=ad-1-main'},\n",
       " {'id': 29,\n",
       "  'title': 'GitHub Copilot Free Tier',\n",
       "  'concept_text': 'GitHub has announced a free tier for its Copilot service, which provides developers with access to advanced coding assistance tools powered by AI. This initiative includes access to models like GPT-4o and Claude 3.5, allowing users to receive up to 2,000 code completions per month at no cost. The introduction of this free tier is a significant step toward democratizing access to AI coding tools, enabling a broader range of developers to leverage AI for enhancing their coding efficiency and productivity. This move reflects a growing trend of making advanced AI tools more accessible to developers, fostering innovation and collaboration in the coding community.',\n",
       "  'keywords': 'GitHub, Copilot, free tier, coding assistance, AI tools',\n",
       "  'links': 'https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot'},\n",
       " {'id': 30,\n",
       "  'title': 'Google DeepMind FACTS Benchmark',\n",
       "  'concept_text': 'Google DeepMind has released the FACTS Grounding benchmark, an important tool for assessing the factual accuracy and grounding of large language models (LLMs) in real-world contexts. This benchmark aims to evaluate how effectively LLMs can understand and process factual information, thereby addressing some of the challenges associated with AI-generated content. The introduction of this benchmark is a critical step in the ongoing efforts to improve the reliability and accountability of AI systems, ensuring that models provide accurate information. With the FACTS benchmark, researchers and developers can better assess and enhance the performance of their models in real-world applications, ultimately contributing to the advancement of trustworthy AI.',\n",
       "  'keywords': 'Google DeepMind, FACTS benchmark, LLMs, factual accuracy, AI reliability',\n",
       "  'links': 'https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/'},\n",
       " {'id': 31,\n",
       "  'title': 'NVIDIA Jetson Orin Nano',\n",
       "  'concept_text': \"NVIDIA has upgraded its Jetson Orin Nano platform, a significant enhancement for edge AI applications, particularly those involving generative AI. The upgraded version boasts a 70% performance boost, providing developers with more powerful capabilities for deploying AI solutions at the edge. This development is crucial as it allows for more efficient processing of AI tasks in environments where resources may be limited, such as in robotics or IoT devices. The Jetson Orin Nano's improvements are tailored to meet the growing demand for efficient, powerful computing solutions in the AI landscape, making it a valuable tool for developers looking to harness the power of AI in real-time applications.\",\n",
       "  'keywords': 'NVIDIA, Jetson Orin Nano, edge AI, generative AI, performance boost',\n",
       "  'links': 'https://developer.nvidia.com/blog/nvidia-jetson-orin-nano-developer-kit-gets-a-super-boost/'},\n",
       " {'id': 32,\n",
       "  'title': 'Dynamiq Low-Code Platform',\n",
       "  'concept_text': \"Dynamiq's low-code platform allows users to prototype, test, and maintain Generative AI applications seamlessly within their own infrastructure. This platform is designed to empower developers by enabling rapid deployment of applications in under an hour using an intuitive interface. With features that support single or multi-agent systems, Dynamiq ensures that organizations can automate tasks efficiently while also providing enterprise-grade security for data management across various environments, whether on-premise or in the cloud.\",\n",
       "  'keywords': 'Dynamiq, low-code platform, Generative AI, application development, automation',\n",
       "  'links': 'https://www.getdynamiq.ai/?utm_source=AlphaSignal&utm_medium=mainAd&utm_campaign=agents'},\n",
       " {'id': 33,\n",
       "  'title': 'AI Integration in Apple Ecosystem',\n",
       "  'concept_text': \"OpenAI has successfully integrated ChatGPT into Apple's ecosystem, enhancing various OS-native applications with advanced writing and vision capabilities. This integration signifies a major step towards embedding AI tools into everyday applications, providing users with enhanced functionalities that leverage natural language processing and image recognition. By bringing sophisticated AI features directly into Apple's products, OpenAI aims to improve user experience and productivity, showcasing the potential of AI to transform how users interact with technology.\",\n",
       "  'keywords': 'OpenAI, ChatGPT, Apple, AI integration, OS-native apps',\n",
       "  'links': 'https://link.alphasignal.ai/KRQ3Ao'},\n",
       " {'id': 34,\n",
       "  'title': 'Midjourney Patchwork',\n",
       "  'concept_text': 'Midjourney has unveiled Patchwork, a multiplayer worldbuilding tool that allows users to collaboratively create stories in a shared canvas environment. This innovative tool is designed for storytellers and creators, enabling them to brainstorm, visualize, and construct narratives together in real-time. With its interactive interface, Patchwork fosters creativity and collaboration, making it an exciting addition to the toolkit of writers and game designers looking to craft immersive worlds and narratives collaboratively.',\n",
       "  'keywords': 'Midjourney, Patchwork, multiplayer, worldbuilding, story creation',\n",
       "  'links': 'https://updates.midjourney.com/patchwork-user-guide/'},\n",
       " {'id': 35,\n",
       "  'title': 'OpenAI Canvas',\n",
       "  'concept_text': 'OpenAI Canvas is an innovative tool designed to streamline the writing and coding process, allowing users to edit text and code side-by-side with the assistance of AI. This hands-on course, led by experts from DeepLearning.ai, teaches users how to leverage the Canvas interface for efficient brainstorming, drafting, and iterating. The platform supports various functionalities, from adjusting tone and enhancing code to generating Python code from images, thus providing a comprehensive workspace for creative and technical tasks alike.',\n",
       "  'keywords': 'OpenAI, Canvas, writing, coding, AI tools',\n",
       "  'links': 'https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/'},\n",
       " {'id': 36,\n",
       "  'title': \"Encord's Multimodal Data Pipelines\",\n",
       "  'concept_text': \"Encord is hosting a webinar on December 16th to discuss the use of agents in building scalable multimodal data pipelines, focusing on automation in data preparation. As generative AI increasingly shifts towards multimodal frameworks, the need for high-quality datasets becomes paramount. Encord's Data Agents are positioned as essential tools that assist machine learning practitioners in automating the curation and annotation processes required for multimodal AI systems. Participants will learn about best practices for utilizing foundational models like PaliGemma 2 and GPT-4o, thereby streamlining workflows and enhancing the quality of data preparation efforts.\",\n",
       "  'keywords': 'Encord, multimodal data, automation, webinar, data agents',\n",
       "  'links': 'https://lu.ma/jwj3apvn?utm_medium=affiliate&utm_source=newsletter&utm_campaign=alpha-signal'},\n",
       " {'id': 37,\n",
       "  'title': \"DeepSeek's LLM Upgrade\",\n",
       "  'concept_text': 'DeepSeek has announced an upgrade to its open-source large language model, DeepSeek-V2.5, which now incorporates real-time internet search capabilities. This enhancement has resulted in an impressive 8% improvement in performance across various tasks, including mathematics, coding, and writing. By leveraging real-time data, DeepSeek aims to provide users with more accurate and contextually relevant responses, enhancing the overall utility of the model. This upgrade is indicative of the ongoing trend in AI towards integrating real-time information to bolster the effectiveness of language models in practical applications.',\n",
       "  'keywords': 'DeepSeek, LLM upgrade, real-time search, performance improvement, open-source',\n",
       "  'links': 'https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210'},\n",
       " {'id': 38,\n",
       "  'title': 'Nous Research Simulators',\n",
       "  'concept_text': 'Nous Research has launched a series of simulators designed to explore human behaviors and interactions with artificial intelligence within digital environments. These simulators aim to understand the dynamics of human-AI interaction, providing valuable insights that could inform the development of more intuitive and effective AI systems. By analyzing how users engage with AI, Nous Research seeks to identify best practices for designing AI tools that enhance user experience and foster more productive collaborations between humans and machines. This initiative highlights the growing importance of human-centric approaches in AI development.',\n",
       "  'keywords': 'Nous Research, simulators, human-AI interaction, digital environments, user experience',\n",
       "  'links': 'https://sims.nousresearch.com/'},\n",
       " {'id': 39,\n",
       "  'title': \"Google's Gemini Flash API\",\n",
       "  'concept_text': \"Google has rolled out the Gemini Flash API, a lightweight and rapid multimodal model that offers lower rate limits for testing purposes. This new API is designed to facilitate developers' access to advanced AI capabilities while enabling them to experiment with various use cases without incurring high costs. With up to 1 million tokens of free caching, Gemini Flash aims to accelerate the integration of multimodal functionalities across applications. This move reflects Google’s commitment to making AI technologies more accessible to developers and encouraging innovation in the use of AI across different sectors.\",\n",
       "  'keywords': 'Google, Gemini Flash API, multimodal model, testing, free caching',\n",
       "  'links': 'https://ai.google.dev/pricing#1_5flash'},\n",
       " {'id': 40,\n",
       "  'title': \"Hugging Face's TGI 3.0\",\n",
       "  'concept_text': 'Hugging Face has introduced TGI 3.0, a new inference engine that significantly enhances the handling of long prompts and increases token capacity. This upgrade provides a 13 times faster processing speed for long prompts and a three times higher token capacity, making it easier for developers to work with larger datasets and more complex queries. TGI 3.0 represents a substantial advancement in AI performance optimization, streamlining workflows for developers and researchers who rely on efficient processing of large volumes of text data. This improvement is particularly beneficial for applications that involve extensive language model interactions, such as chatbots and automated content generation.',\n",
       "  'keywords': 'Hugging Face, TGI 3.0, inference engine, performance optimization, token capacity',\n",
       "  'links': 'https://huggingface.co/docs/text-generation-inference/conceptual/chunking'},\n",
       " {'id': 41,\n",
       "  'title': \"OpenAI's Sora Turbo\",\n",
       "  'concept_text': 'OpenAI has recently launched Sora Turbo, an advanced video generation model that allows users to create realistic videos from text prompts. This model is particularly designed for ChatGPT Plus and Pro users, providing enhanced speed and visual quality. Sora Turbo can generate videos up to 20 seconds long and supports various aspect ratios, making it versatile for different content types. Users can utilize the storyboard tool to input images or videos, allowing for detailed scene construction and the ability to remix content. The improved generation times and user-friendly interface are significant upgrades over the initial Sora model, making it a powerful tool for creators and developers alike.',\n",
       "  'keywords': 'OpenAI, Sora Turbo, video generation, ChatGPT, AI tool',\n",
       "  'links': 'https://link.alphasignal.ai/6BTLWu'},\n",
       " {'id': 42,\n",
       "  'title': \"Hume's Voice Control Tool\",\n",
       "  'concept_text': \"Hume has introduced a groundbreaking tool called Voice Control, enabling users to create unique AI voices instantly without the need for coding. This tool allows for real-time adjustments across ten key dimensions of voice modulation, including gender tone, density, confidence, and relaxation levels. By employing intuitive sliders, users can craft the perfect voice tailored to their specific applications, ranging from customer service bots to virtual assistants. The focus on unique voice customization rather than cloning addresses ethical concerns while providing flexibility for various use cases. Hume's Voice Control tool represents a significant advancement in voice technology for AI applications.\",\n",
       "  'keywords': 'Hume, Voice Control, AI voices, voice modulation, customization',\n",
       "  'links': 'https://platform.hume.ai/?utm_source=alphasignal&utm_medium=newsletter&utm_campaign=voice-control'},\n",
       " {'id': 43,\n",
       "  'title': \"Google's Willow Quantum Chip\",\n",
       "  'concept_text': 'Google has unveiled its latest quantum computing advancement, the Willow quantum chip, which dramatically outperforms traditional supercomputers. Capable of solving complex computations in under five minutes, Willow represents a leap forward in quantum technology, promising to address computational challenges that would take classical systems an exorbitant amount of time to solve. This breakthrough places Google at the forefront of quantum research, with implications for various fields, including cryptography, optimization, and machine learning. The introduction of Willow marks a significant milestone in the race to harness quantum computing for practical applications, highlighting the transformative potential of this technology.',\n",
       "  'keywords': 'Google, Willow, quantum chip, computing, supercomputers',\n",
       "  'links': 'https://blog.google/technology/research/google-willow-quantum-chip/'},\n",
       " {'id': 44,\n",
       "  'title': \"xAI's Aurora Image Generator\",\n",
       "  'concept_text': \"xAI has launched Aurora, a sophisticated image generation model integrated with Grok, designed to produce high-quality images with fewer content restrictions compared to its predecessors. This multimodal input model allows users to generate images based on various inputs, thus enhancing flexibility and creativity in content creation. Aurora's capabilities position it as a competitive alternative in the image generation space, particularly against established models like Flux. By offering a more open and versatile platform, Aurora stands to benefit developers and artists looking to push the boundaries of digital content creation.\",\n",
       "  'keywords': 'xAI, Aurora, image generation, Grok, AI model',\n",
       "  'links': 'https://x.ai/blog/grok-image-generation-release'},\n",
       " {'id': 45,\n",
       "  'title': 'AskUI Vision Agent Framework',\n",
       "  'concept_text': 'AskUI has developed the Vision Agent framework, a powerful tool designed to empower developers to create intelligent computer agents across multiple operating systems using Python and large language models (LLMs). This framework allows for seamless integration of automation features, enabling users to automate tasks on platforms such as Windows, Linux, MacOS, and Android. With support for multi-monitor setups and optical character recognition (OCR), Vision Agent provides a comprehensive solution for building versatile agents capable of handling complex workflows. This development aligns with the growing demand for automation in various sectors, making it a vital resource for developers aiming to optimize productivity.',\n",
       "  'keywords': 'AskUI, Vision Agent, computer agents, automation, Python',\n",
       "  'links': 'https://github.com/askui/vision-agent'},\n",
       " {'id': 46,\n",
       "  'title': 'OpenAI o1 Model Release',\n",
       "  'concept_text': \"OpenAI has officially launched its newest AI model, named 'o1', marking a significant advancement in its capabilities. This model is designed to replace the previous preview version used in ChatGPT, introducing enhanced features such as advanced reasoning abilities, quicker response times, and the capacity to process images. The launch coincided with the kickoff of OpenAI's '12 Days of OpenAI' event, where the company is expected to unveil more updates and announcements. The o1 model is particularly aimed at users with demanding computational needs, thus being integrated into the new $200/month ChatGPT Pro subscription, which is tailored for complex application scenarios.\",\n",
       "  'keywords': 'OpenAI, o1 model, ChatGPT Pro, AI capabilities, image processing',\n",
       "  'links': 'https://link.alphasignal.ai/FOerJZ'},\n",
       " {'id': 47,\n",
       "  'title': 'ChatGPT Pro Subscription Features',\n",
       "  'concept_text': \"The launch of the o1 model is accompanied by the introduction of a new subscription tier for ChatGPT, known as 'ChatGPT Pro'. This subscription is priced at $200 per month and is tailored for users who require high levels of computational power and advanced features for complex tasks. Users of ChatGPT Pro will have unlimited access to several tools, including the o1 model and its advanced capabilities. One notable feature of the Pro version is the 'o1 Pro mode', which offers a significantly larger context window of 128k tokens, enhancing the model's reliability and performance on technical tasks. This subscription tier emphasizes efficiency and reliability, particularly beneficial for users engaged in high-stakes projects or requiring extended processing times for their queries.\",\n",
       "  'keywords': 'ChatGPT Pro, subscription, AI tools, context window, reliability',\n",
       "  'links': ''},\n",
       " {'id': 48,\n",
       "  'title': \"Microsoft's Copilot Vision\",\n",
       "  'concept_text': 'Microsoft has unveiled Copilot Vision, a new feature designed to provide Pro users with real-time insights while navigating the Edge browser. This innovative tool is aimed at enhancing productivity by delivering contextual information directly on the browser page, allowing users to interact with web content more effectively. By integrating AI-driven assistance into everyday browsing tasks, Microsoft aims to empower users with insights that can streamline decision-making processes and enhance their overall web experience. This development underscores the growing trend of integrating sophisticated AI tools within standard software applications to improve user engagement and efficiency.',\n",
       "  'keywords': 'Microsoft, Copilot Vision, Edge browser, AI assistance, productivity',\n",
       "  'links': 'https://www.microsoft.com/en-us/microsoft-copilot/blog/2024/12/05/copilot-vision-now-in-preview-a-new-way-to-browse/'},\n",
       " {'id': 49,\n",
       "  'title': \"Google's PaliGemma 2 Model\",\n",
       "  'concept_text': \"Google has introduced PaliGemma 2, an open-source vision-language model that enhances capabilities in understanding and generating visual content. This model is designed for flexibility and scalability in various tasks, including image captioning and visual question answering. The development of PaliGemma 2 reflects Google's commitment to advancing multimodal AI technologies, which combine text and visual data to improve interaction with complex information. As more organizations explore the potential of vision-language models, Google's release of PaliGemma 2 positions it as a significant player in the evolving AI landscape, offering tools that can be leveraged across a multitude of applications.\",\n",
       "  'keywords': 'Google, PaliGemma 2, vision-language model, open-source, multimodal AI',\n",
       "  'links': 'https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/'},\n",
       " {'id': 50,\n",
       "  'title': 'Trends in Speech Technologies',\n",
       "  'concept_text': 'The 2024 AI Insights Report by Assembly AI highlights key trends in speech technology, emphasizing the increasing adoption of advanced speech recognition models and the integration of multimodal AI solutions. The report serves as a vital resource for industry professionals seeking actionable insights and data-driven strategies to enhance their products. Key findings include the importance of APIs in improving workflow efficiency and the shift towards building versus buying solutions in AI-driven product development. As companies increasingly rely on AI for competitive advantage, understanding these trends will be essential for navigating the evolving landscape of speech technologies and ensuring successful implementation of AI solutions in various applications.',\n",
       "  'keywords': 'Assembly AI, speech technology, AI Insights Report, multimodal AI, workflow efficiency',\n",
       "  'links': 'https://www.assemblyai.com/reports/2024-insights-report?utm_source=alphasignal&utm_medium=newsletter_sponsor&utm_campaign=main&utm_content=120624'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_unused_concepts_for_tweets(days_before=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tweets.creator import TweetCreator\n",
    "from src.database.sql import SQLDatabase\n",
    "\n",
    "db = SQLDatabase()\n",
    "creator = TweetCreator(db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = creator._extract_article_from_link('https://fliki.ai/blog/twitter-ad-revenue-sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you a Twitter creator looking to turn your passion into a rewarding endeavor? Well, get ready to witness a transformative shift in social media earnings!\\n\\nIn a surprising and exciting move, Twitter, now known as \"X,\" has unleashed a groundbreaking ad revenue-sharing program, sending curiosity and enthusiasm through the social media community. Gone are the days of merely tweeting for likes and retweets; with \"X\\'s\" revolutionary program, you can monetize your content like never before.\\n\\nThis blog delves deep into the heart of Twitter\\'s bold rebranding and the fascinating concept of ad revenue sharing. Don\\'t miss this opportunity to be at the forefront of Twitter\\'s evolution – it\\'s time to reap the rewards of your passion and become a part of the X community driving the future of social media engagement. Let\\'s dive in and unlock the secrets of Twitter\\'s ad revenue sharing together!\\n\\nIf you\\'ve ever wondered how to turn your Twitter prowess into a lucrative endeavor, the answer lies in Twitter\\'s Ad Revenue Sharing Program. This revolutionary initiative empowers creators by rewarding them for their exceptional content and engagement. Here\\'s everything you need to know about this game-changing program:\\n\\n- The driving force behind the program is to encourage and support creators in their journey to monetize their Twitter presence.\\n\\n- Twitter, now known as \"X,\" seeks to foster a thriving community of content creators by offering a tangible incentive for their efforts.\\n\\n- By joining the program, creators can access a new revenue stream which is based on their content\\'s performance.\\n\\n- This revenue share opens up exciting possibilities, allowing creators to turn their passion into a genuine income stream.\\n\\nTo participate in the Ad Revenue Sharing Program, you must meet specific criteria:\\n\\n2. Accumulate at least 5 million impressions on cumulative posts within the last three months.\\n\\n- Creators can join and set up payments through the Monetization section of the app, accessible via the side menu on iOS and Android or the overflow menu on the web.\\n\\n- Stripe account setup is essential for receiving revenue share, and creators can transfer funds to their external bank account through this platform.\\n\\n- Payouts are made regularly, provided creators have generated more than $50 in earnings.\\n\\n- Creators can expect payouts consistently, depending on their monthly earnings from ad revenue sharing.\\n\\n- Earnings exceeding the minimum threshold of $50 trigger a payout, ensuring that creators see tangible returns on their efforts.\\n\\nIn the next section, we\\'ll delve into inspiring stories of creators who have benefited from this program, offering insights into its endless potential for content creators across the Twitter community. Get inspired and motivated by real-life examples of success in Twitter\\'s Ad Revenue Sharing Program!\\n\\nPrepare to be inspired as we unveil real-life success stories of creators who have already harnessed the power of Twitter\\'s Ad Revenue Sharing Program. These early adopters have demonstrated the program\\'s true potential, showing us what\\'s possible when passion and engagement get rewarded. Let\\'s take a closer look at their stories:\\n\\n- With an impressive 2.1 million followers, Shibetoshi Nakamoto is no stranger to captivating his audience with engaging content.\\n\\n- His consistent efforts and viral tweets have led to millions of impressions per tweet, making him a prime candidate for the program.\\n\\n- From February to July, Nakamoto revealed that he would receive a remarkable $37,050 in earnings through Twitter\\'s Ad Revenue Sharing Program.\\n\\n- Nakamoto\\'s success story proves that dedication and a loyal following can lead to substantial financial rewards on the platform.\\n\\n- As a content creator with a flair for captivating tweets, Ashley St. Clair has accumulated an astounding 840 million impressions from February to July 2023.\\n\\n- Twitter\\'s Ad Revenue Sharing Program recognized St. Clair\\'s remarkable engagement and rewarded her with earnings amounting to $7,153 during the same period.\\n\\n- This story showcases the significant revenue potential that creators can unlock who consistently generate good impressions and engage with their audience.\\n\\n- While the success stories are undoubtedly encouraging, it\\'s essential to delve deeper into the numbers to understand the true impact of each impression.\\n\\n- Based on Ashley St. Clair\\'s earnings and 840 million impressions, each impression\\'s average value is approximately .\\n\\n- It\\'s important to note that this figure includes earnings from verified and non-verified users, making the exact earning rate per impression more variable.\\n\\n- The earning rate per impression can be influenced by the number of verified users viewing ads in tweet replies and threads.\\n\\n- As Twitter has not disclosed the exact amount per impression, the revenue share from verified users remains a critical factor in determining creators\\' earnings.\\n\\nAs more creators unlock their earnings and share their experiences, Twitter\\'s rebranding as \"X\" is proving to be a game-changer in social media engagement. Join us in the next section as we explore expert tips and strategies to help you maximize your ad revenue potential on Twitter\\'s innovative platform.\\n\\nSpeculation on the Sustainability of the Program and Its Long-Term Impact\\n\\nAs Twitter\\'s Ad Revenue Sharing Program gains momentum and creators start reaping the rewards, questions arise about the program\\'s sustainability in the long run. As we peer into the crystal ball, several factors come into play:\\n\\n- The program\\'s success depends on creators\\' ongoing engagement and ability to maintain a loyal following.\\n\\n- If creators continue to produce compelling content and attract new audiences, the program will likely remain a valuable source of income.\\n\\n- Twitter, now X, has a track record of adapting and evolving to meet user demands and market trends.\\n\\n- As the program matures, its structure and payout mechanisms might change to optimize creator and platform benefits.\\n\\nConsideration of Elon Musk\\'s Involvement and Previous Company-Wide Changes\\n\\nElon Musk\\'s dynamic leadership has played a pivotal role in shaping Twitter\\'s transformation into X. Considering his penchant for bold moves and innovative strategies, his involvement raises exciting prospects for the program\\'s future:\\n\\n- Musk has expressed ambitions to make X an \"everything\" app, elevating it beyond its microblogging roots.\\n\\n- The Ad Revenue Sharing Program could be a cornerstone of Musk\\'s vision to empower creators and incentivize content diversity on the platform.\\n\\n- Musk\\'s tenure as the driving force behind Twitter\\'s transformation has seen significant changes, from rebranding to introducing new features.\\n\\n- Understanding the broader context of these changes can provide insights into how the Ad Revenue Sharing Program fits into Musk\\'s overarching strategy.\\n\\nAnalyzing the Potential for the Program to Continue Benefiting Creators and the Platform\\n\\nThe Ad Revenue Sharing Program has demonstrated early promise, but its long-term impact remains an intriguing topic of discussion:\\n\\n- Creators\\' continued participation largely depends on the program\\'s ability to offer sustainable earnings over time.\\n\\n- Consistent revenue incentives will encourage creators to invest in their content and remain actively engaged on the platform.\\n\\n- As Twitter vies for the spotlight in the ever-evolving social media landscape, the program\\'s success can be vital in attracting and retaining creators.\\n\\n- Sustained growth and competitiveness in the market will be essential for the program\\'s longevity.\\n\\nAs we peer into the horizon, the future of Twitter\\'s Ad Revenue Sharing Program remains a captivating mystery. While speculation and analysis provide glimpses of what lies ahead, the collective efforts of creators will determine the actual trajectory, Twitter\\'s visionary leadership, and the evolving landscape of social media monetization.\\n\\nAs we draw the curtains on our journey through the captivating world of Twitter\\'s Ad Revenue Sharing Program, we can\\'t help but feel a sense of excitement and possibility. Twitter\\'s transformation into X has brought with it a vision beyond mere tweets and hashtags – it\\'s a vision of empowerment, turning your passion into tangible earnings, and being a part of a thriving community of creators.\\n\\nRemember, your journey as a Twitter creator is not limited – it\\'s an open canvas for innovation, growth, and financial reward. As the wise man says, \"If you can dream it, you can achieve it,\" Twitter\\'s Ad Revenue Sharing Program is your gateway to making that dream a reality.\\n\\nSo, seize this moment to be part of the X community, which champions creators and celebrates their endeavors. With determination, a sprinkle of Musk-like audacity, and the support of fellow creators, you can embark on a thrilling adventure toward making your mark on the digital stage.\\n\\nEmbrace the power of Twitter\\'s Ad Revenue Sharing Program, and let your voice get heard in the digital symphony that is X. Together, you can shape a new era of content creation, one tweet at a time. The world is watching, and the stage is yours to conquer. Happy tweeting, and may your earnings soar to heights never imagined!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_echo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
